{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This library of documentation is dedicated to technical topics related to Granite WMS. We cover setups, configurations, and various other technical aspects.</p> <p>To continue enhancing the value of this resource, we kindly ask the community for their support and feedback. Please be aware that the documentation reflects the latest version of the software. Keep this in mind as you refer to the content.</p> <p>Other resources: Stack Overflow Teams - Granite WMS Questions</p>"},{"location":"android-application/manual/","title":"Granite Scanner Application","text":"<p>The Granite Scanner Application (Android) acts as a browser replacement for the ProcessApp allowing the scanner functionality to be configured with restricted access.</p>"},{"location":"android-application/manual/#setup","title":"Setup","text":"<p>To install you will need the apk from the dropbox folder \"Software Installs &gt; Granite Android App &gt; Granite.apk\"</p> <p>You can either use the QR code from in the same folder to download the APK directly from dropbox onto the scanner or you could send the file via bluetooth to each of the scanners. </p> <p>Once the APK is on the device, simply select it to begin the install process. If this is the first APK install you may need to update the permissions to allow to install from a folder as below (it may look different depending on the version of android). </p> <p>Note</p> <pre><code>Some scanners may prevent you from installing the app if the apk is in the downloads folder.\n\nMove to DCIM or similar to resolve the issue.\n</code></pre> <p></p>"},{"location":"android-application/manual/#using-the-app","title":"Using the App","text":""},{"location":"android-application/manual/#add-a-website","title":"Add a Website","text":"<p>There are two options for adding websites:</p> <ul> <li>Manual</li> <li>Scan QR</li> </ul> Manual <p>Select Add &gt; Manual. You will be prompted to enter a Website Name and a URL. </p> <p>The name must be unique. If you have a website called \"Live\" and create a new website with the same name the old website will be overwritten.  The url needs to include \"https://\" or \"http://\".</p> <p></p> Scan QR <p>Select Add &gt; Manual. You will be prompted to scan a QR code. (create a Config QR code)</p> <p>In the example below I post from the clipboard, but on a scanner, scanning the Config QR will populate the input field.</p> <p></p>"},{"location":"android-application/manual/#delete-a-website","title":"Delete a Website","text":"<p>To delete a website select the website in the list and then press Delete. You will be prompted to confirm that you would like to delete the selected site. </p> <p></p>"},{"location":"android-application/manual/#launch-a-website","title":"Launch a Website","text":"<p>To launch a website select the website and press launch. </p> <p>If only website is set up, when launching the app, it will browse directly to the website skipping the home screen. Pressing back take you back to the home screen. </p> <p>Note</p> <pre><code>Only granite websites can be browsed to.\n\nAn error will display if you try launch any other website.\n</code></pre> <p></p>"},{"location":"android-application/manual/#config-qr","title":"Config QR","text":"<p>To create a QR code that can be used to add websites to the scanner you will need to create a QR code that contains json text with your website details.</p> <p>Below is an example of the json code. You can add as many websites as needed. Remember to change the names and urls.</p> <pre><code>[{\"name\":\"Test\",\"url\":\"https://10.0.0.1:40186\"},{\"name\":\"Live\",\"url\":\"https://10.0.0.1:40086\"}]\n</code></pre> <p>To create the Qr code you can use QR.io and then grab the QR code using the windows snipping tool. </p> <p></p>"},{"location":"custodian-api/best-practice/","title":"Best Practices Process Templates","text":"<p>The aim of a template is to encapsulate a single business use-case in a self-deployable unit. It should be easy to understand, clear in its intention, and simple to deploy. Below are some guidelines on how you would achieve this. These guidelines do not state that you should avoid certain things, but rather aim to provide context and explain some of the trade-offs of your design decisions.</p>"},{"location":"custodian-api/best-practice/#simplicity","title":"Simplicity","text":"<p><code>Always aim for simplicity over any other motivation.</code></p> <p>Simplicity in templates refers to how easily colleagues can deploy, modify, comprehend, and upkeep processes.  Your process behavior should consistently yield predefined outcomes.</p>"},{"location":"custodian-api/best-practice/#low-ceremony","title":"Low Ceremony","text":"<p><code>Ready to use</code></p> <p>Processes often rely on predefined, hardcoded, or static data. Ensure these are minimized, and thorough documentation is provided to highlight any required setup data, such as types, categories, locations, etc.</p>"},{"location":"custodian-api/best-practice/#abstraction-and-decoupling","title":"Abstraction and Decoupling","text":"<p><code>Less moving parts</code></p> <p>Keep to a single stored procedure per prescript and try to avoid further decoupling.</p> <p>Decoupling and Abstraction often used for re-use can increase complexity, ensure the re-use value is justified.</p>"},{"location":"custodian-api/best-practice/#explicit-over-generic","title":"Explicit over Generic","text":"<p><code>Be Explicit</code></p> <p>While Generic (multipurpose) processes have their value, simplicity is often compromised in their favor.  However, it's preferable to develop Explicit (single-use) processes for the sake of simplicity.</p>"},{"location":"custodian-api/manual/","title":"Custodian API","text":"<p>The primary responsibility of the Custodian API is to manage Process Templates, which encapsulate Granite Processes along with Process Steps, web templates, and pre-scripts. Each template consists of both metadata and artifact files. Metadata serves to document the process and provide additional information, while artifacts encompass all the data, scripts, views, lookups, and static data necessary for deploying the process. Ultimately, each deployment is self-contained, facilitating seamless sharing and deployment processes through the WebDesktop.</p>"},{"location":"custodian-api/manual/#setup","title":"Setup","text":""},{"location":"custodian-api/manual/#requirements","title":"Requirements","text":"<ul> <li>ASP.NET Core 8 Hosting Bundle</li> <li>IIS</li> <li>Sufficient permissions for folder and file access and IIS application creation</li> </ul>"},{"location":"custodian-api/manual/#application-settings","title":"Application Settings","text":"<p>The settings below are configured in the <code>appsettings.json</code>.</p>"},{"location":"custodian-api/manual/#connectionstrings","title":"ConnectionStrings","text":"<p>Configuring multiple connection strings allow you to deploy to any instance of Granite. The name of the connection string will be used in the Webdesktop to identify the connection. Example CONNECTION and TEST.</p> <pre><code>\"ConnectionStrings\": {\n    \"CONNECTION\": \"Data Source=.;Initial Catalog=GraniteLive;Persist Security Info=True;User ID=;TrustServerCertificate=True;\",\n    \"TEST\": \"Data Source=.;Initial Catalog=GraniteTest;Persist Security Info=True;User ID=;TrustServerCertificate=True;\"\n  }\n</code></pre>"},{"location":"custodian-api/manual/#allowedorigins","title":"AllowedOrigins","text":"<p>The 'allowed origins' is a list of addresses for applications requiring access to the API.  By default, the only address that requires configuration is the Granite WebDesktop address.</p> <pre><code>\"AllowedOrigins\": [ \"https://192.168.1.10:8081\" ]\n</code></pre> <p>Note</p> <p>You cannot use wildcards like <code>*</code> in the <code>AllowedOrigins</code> setting for Custodian.</p>"},{"location":"custodian-api/manual/#systemsettings","title":"SystemSettings","text":"<pre><code>INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\nVALUES \n('GRANITECUSTODIAN', 'Repo_id', '676912773', '', 0, 1, GETDATE(), 'AUTOMATION'),\n('GRANITECUSTODIAN', 'Token', '******', '', 0, 1, GETDATE(), 'AUTOMATION'),\n('GRANITECUSTODIAN', 'Stores', 'Approved,Draft', '', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre> <ul> <li><code>Take Note</code> Ensure that the Token is Encrypted. After 90 days reset the token. We will issue a new token prior to expiry.</li> <li>New stores could be introduced and added to this setting. The stores available will be communicated to the team; you cannot add names that do not exist.</li> </ul>"},{"location":"custodian-api/manual/#troubleshoot","title":"Troubleshoot","text":"<p>The most common issues will arise with the connection to the cloud store, ensuring that the token is correct and not expired. Run <code>\\config</code> operation to verify connections, authentication and setup.</p>"},{"location":"database/release-notes/","title":"Release notes","text":""},{"location":"database/release-notes/#unreleased-500","title":"Unreleased (5.0.0)","text":""},{"location":"database/release-notes/#granitedatabase","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#changed-views","title":"Changed Views","text":""},{"location":"database/release-notes/#api_querydocuments","title":"API_QueryDocuments","text":"<pre><code>ALTER VIEW [dbo].[API_QueryDocuments]\nAS\nSELECT        TOP 100 PERCENT dbo.[Document].ID, dbo.[Document].Number, dbo.[Document].TradingPartnerCode, dbo.[Document].TradingPartnerDescription, dbo.[Document].CreateDate, dbo.[Document].Priority, \n                         dbo.[Document].ERPLocation, dbo.[Document].Site, dbo.Document.ExpectedDate, dbo.Document.RouteName, dbo.Document.StopName, dbo.[Document].Status, dbo.[Document].AuditDate, dbo.[Document].AuditUser, dbo.[Document].Type, dbo.[Document].Description, (STUFF\n                             ((SELECT        CAST(', ' + IntegrationReference AS VARCHAR(MAX))\n                                 FROM            [Transaction]\n                                 WHERE        (Document_id = [Document].ID)\n                                 GROUP BY [Transaction].IntegrationReference FOR XML PATH('')), 1, 2, '')) AS IntegrationReference\nFROM            dbo.[Document]\nWHERE  ([Status] &lt;&gt; 'COMPLETE' OR AuditDate &gt; getdate() - 30)\nORDER BY dbo.[Document].ID DESC\n\nGO\n</code></pre>"},{"location":"database/release-notes/#integration_transactions","title":"Integration_Transactions","text":"<pre><code>ALTER VIEW [dbo].[Integration_Transactions]\nAS\nSELECT * FROM \n(SELECT DISTINCT \n                         dbo.[Transaction].ID, dbo.[Transaction].Date, dbo.Users.Name AS [User], dbo.[Transaction].IntegrationStatus, dbo.[Transaction].IntegrationReady, dbo.MasterItem.Code, ISNULL(dbo.[Transaction].UOM, dbo.MasterItem.UOM) \n                         AS UOM, dbo.[Transaction].UOMConversion, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, dbo.[Transaction].ActionQty, dbo.Location.ERPLocation AS FromLocationERPLocation, \n                         Location_1.ERPLocation AS ToLocationERPLocation, dbo.[Document].Number AS [Document], dbo.DocumentDetail.LineNumber, MasterItem_1.Code AS FromCode, MasterItem_2.Code AS ToCode, dbo.TrackingEntity.Batch, \n                         dbo.[Transaction].Comment, dbo.[Transaction].Type, dbo.[Transaction].Process, dbo.TrackingEntity.SerialNumber, dbo.[Document].Type AS DocumentType, dbo.[Transaction].IntegrationReference, \n                         dbo.[Document].Description AS DocumentDescription, dbo.TrackingEntity.ExpiryDate, [log].Message, dbo.DocumentDetail.Cancelled AS DocumentLineCancelled, Location_1.Site AS ToSite, dbo.Location.Site AS FromSite, \n                         Process.Name,\n                         CASE \n                         WHEN dbo.[Transaction].Process ='PICKING' AND dbo.Process.IntegrationIsActive = 0  THEN \n                            (SELECT IntegrationIsActive FROM dbo.Process WHERE [Name] = 'PICKINGPOST')\n                         WHEN dbo.[Transaction].Process ='RECEIVING' AND dbo.Process.IntegrationIsActive = 0  THEN \n                            (SELECT IntegrationIsActive FROM dbo.Process WHERE [Name] = 'RECEIVINGPOST')\n                         ELSE dbo.Process.IntegrationIsActive END\n                         as IntegrationIsActive, \n\n                         dbo.[Document].TradingPartnerCode AS DocumentTradingPartnerCode, dbo.[Transaction].DocumentReference AS TransactionDocumentReference, dbo.[Transaction].ReversalTransaction_id\nFROM            dbo.[Transaction] INNER JOIN\n                         dbo.TrackingEntity ON dbo.[Transaction].TrackingEntity_id = dbo.TrackingEntity.ID INNER JOIN\n                         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID INNER JOIN\n                         dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID LEFT OUTER JOIN\n                         dbo.Process ON dbo.[Transaction].Process = dbo.Process.Name LEFT OUTER JOIN\n                         dbo.Location AS Location_1 ON dbo.[Transaction].ToLocation_id = Location_1.ID LEFT OUTER JOIN\n                         dbo.Location ON dbo.[Transaction].FromLocation_id = dbo.Location.ID LEFT OUTER JOIN\n                         dbo.[Document] ON dbo.[Transaction].Document_id = dbo.[Document].ID LEFT OUTER JOIN\n                         dbo.MasterItem AS MasterItem_1 ON dbo.[Transaction].FromMasterItem_id = MasterItem_1.ID LEFT OUTER JOIN\n                         dbo.MasterItem AS MasterItem_2 ON dbo.[Transaction].ToMasterItem_id = MasterItem_2.ID LEFT OUTER JOIN\n                         dbo.DocumentDetail ON dbo.[Transaction].DocumentLine_id = dbo.DocumentDetail.ID OUTER APPLY\n                         (\n                             SELECT TOP(1) [Message]\n                             FROM dbo.IntegrationLog\n                             WHERE GraniteTransaction_id = [Transaction].ID\n                             ORDER BY [Date] DESC\n                         ) [log]\nWHERE       dbo.[Transaction].Type NOT IN ('SPLIT','QCHOLD', 'QCRELEASE', 'STOCKTAKE', 'STOCKTAKEHOLD', 'STOCKTAKERELEASE')  AND \n            IntegrationStatus = 0 AND ISNULL(ReversalTransaction_id, 0) = 0\n) AS table_1\nWHERE table_1.IntegrationIsActive = 1\n</code></pre>"},{"location":"database/release-notes/#api_querytransactionsreceivereversal","title":"API_QueryTransactionsReceiveReversal","text":"<pre><code>ALTER VIEW [dbo].[API_QueryTransactionsReceiveReversal]\n    AS\nSELECT dbo.[Transaction].ID, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, dbo.[Transaction].Date, dbo.TrackingEntity.Batch, dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, dbo.[Transaction].ActionQty, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS [Document], dbo.[Transaction].IntegrationStatus, \n         dbo.CarryingEntity.Barcode AS Pallet, dbo.[Transaction].Comment, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, dbo.[Transaction].Type, dbo.[Transaction].IntegrationReference, dbo.[Transaction].ReversalTransaction_id, dbo.[Document].TradingPartnerCode, dbo.[Document].TradingPartnerDescription, dbo.[Document].Status, dbo.DocumentDetail.LineNumber\nFROM  dbo.[Transaction] INNER JOIN\n         dbo.DocumentDetail ON dbo.[Transaction].DocumentLine_id = dbo.DocumentDetail.ID INNER JOIN\n         dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id LEFT OUTER JOIN\n         dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n         dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n         dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID INNER JOIN\n         dbo.Users ON dbo.[Transaction].[User_id] = dbo.Users.ID INNER JOIN\n         dbo.TrackingEntity ON [Transaction].TrackingEntity_id = TrackingEntity.ID INNER JOIN\n         dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID INNER JOIN\n         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID CROSS APPLY\n         (\n             SELECT TOP 1 ID\n             FROM [Transaction] \n             WHERE TrackingEntity_id = TrackingEntity.ID\n             ORDER BY [Date] DESC\n         ) lastTransaction\nWHERE (dbo.[Transaction].Type = 'RECEIVE') AND ISNULL(dbo.[Transaction].ReversalTransaction_id, 0) = 0 AND ISNULL(dbo.[Transaction].IntegrationStatus, 0) = 0 AND lastTransaction.ID = [Transaction].ID\nGO\n</code></pre>"},{"location":"database/release-notes/#datagrid_stockavailable","title":"DataGrid_StockAvailable","text":"<pre><code>CREATE VIEW [dbo].[DataGrid_StockAvailable]\nAS\nSELECT DISTINCT MasterItem.ID AS MasterItemId, \n       Code AS MasterItemCode, \n       Description AS MasterItemDescription,\n       MasterItem.Type,\n       MasterItem.Category,\n       UOM, \n       CASE WHEN (SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000) + ISNULL(PurchaseOrderQty, 0.000)) &gt; 0\n            THEN 'InStock'\n            WHEN (SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000) + ISNULL(PurchaseOrderQty, 0.000)) &lt;= 0\n            THEN 'NoStock'\n            ELSE 'NoStock'\n            END AS Status\n       ,\n       ISNULL(SUM(Qty) OVER(PARTITION BY MasterItem.ID), 0.0000) AS QtyInWarehouse, \n       ISNULL(SalesOrderQty, 0.000) AS QtyOnSalesOrders,\n       ISNULL(PurchaseOrderQty, 0.000) AS QtyOnPurchaceOrders,\n       ISNULL((SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000)), 0.0000) AS QtyAfterSales,\n       ISNULL((SUM(Qty) OVER(PARTITION BY MasterItem.ID) + ISNULL(PurchaseOrderQty, 0.000)), 0.0000) AS QtyAfterPurchaces,\n       ISNULL((SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000) + ISNULL(PurchaseOrderQty, 0.000)), 0.0000) AS TotalQtyAvailable\nFROM MasterItem LEFT JOIN \n     TrackingEntity ON MasterItem.ID = TrackingEntity.MasterItem_id OUTER APPLY\n     (SELECT (SUM(Qty) - SUM(ActionQty)) AS SalesOrderQty\n      FROM DocumentDetail LEFT JOIN \n           Document ON DocumentDetail.Document_id = Document.ID\n      WHERE Completed &lt;&gt; 1 AND\n            Cancelled &lt;&gt; 1 AND\n            Document.Status in ('ENTERED', 'RELEASED') AND \n            DocumentDetail.Item_id = MasterItem.ID AND \n            Document.Type = 'ORDER'\n      GROUP BY Item_id) AS SalesOrders\n      OUTER APPLY\n     (SELECT (SUM(Qty) - SUM(ActionQty)) AS PurchaseOrderQty\n      FROM DocumentDetail LEFT JOIN \n           Document ON DocumentDetail.Document_id = Document.ID\n      WHERE Completed &lt;&gt; 1 AND\n            Cancelled &lt;&gt; 1 AND\n            Document.Status in ('ENTERED', 'RELEASED') AND \n            DocumentDetail.Item_id = MasterItem.ID AND \n            Document.Type = 'RECEIVING'\n      GROUP BY Item_id) AS PurchaseOrders\nWHERE MasterItem.isActive = 1 \nGO\n</code></pre>"},{"location":"database/release-notes/#new-tables","title":"New tables","text":""},{"location":"database/release-notes/#migration","title":"Migration","text":"<pre><code>CREATE TABLE [dbo].[Migration](\n    [Id] [bigint] IDENTITY(1,1) NOT NULL,\n    [Name] [varchar](8000) NULL,\n    [Description] [varchar](8000) NULL,\n    [CreatedDate] [datetime] NOT NULL,\n    [CompletedDate] [datetime] NULL,\n    [ConnectionString] [varchar](8000) NULL,\n    [NamedConnection] [varchar](8000) NULL,\n    [Log] [varchar](max) NULL,\n    [ErrorCode] [varchar](8000) NULL,\n    [ErrorMessage] [varchar](8000) NULL,\n    [ErrorStackTrace] [varchar](max) NULL,\n    [Meta] [varchar](max) NULL,\nPRIMARY KEY CLUSTERED \n(\n    [Id] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]\n) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]\n</code></pre>"},{"location":"database/release-notes/#optionalfieldvalues_location","title":"OptionalFieldValues_Location","text":"<pre><code>CREATE TABLE [dbo].[OptionalFieldValues_Location](\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Value] [nvarchar](255) NULL,\n    [OptionalField_id] [bigint] NULL,\n    [BelongsTo_id] [bigint] NULL,\nPRIMARY KEY CLUSTERED \n(\n    [ID] ASC\n)WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Location]  WITH CHECK ADD  CONSTRAINT [FK1C630FA95BD9E8FA] FOREIGN KEY([OptionalField_id])\nREFERENCES [dbo].[OptionalFields] ([ID])\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Location] CHECK CONSTRAINT [FK1C630FA95BD9E8FA]\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Location]  WITH CHECK ADD  CONSTRAINT [FK1C630FA96509605E] FOREIGN KEY([BelongsTo_id])\nREFERENCES [dbo].[Location] ([ID])\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Location] CHECK CONSTRAINT [FK1C630FA96509605E]\nGO\n</code></pre>"},{"location":"database/release-notes/#optionalfieldvalues_document","title":"OptionalFieldValues_Document","text":"<pre><code>CREATE TABLE [dbo].[OptionalFieldValues_Document](\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Value] [nvarchar](255) NULL,\n    [OptionalField_id] [bigint] NULL,\n    [BelongsTo_id] [bigint] NULL,\nPRIMARY KEY CLUSTERED \n(\n    [ID] ASC\n)WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Document]  WITH CHECK ADD  CONSTRAINT [FK1C630FA95BD9E1FA] FOREIGN KEY([OptionalField_id])\nREFERENCES [dbo].[OptionalFields] ([ID])\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Document] CHECK CONSTRAINT [FK1C630FA95BD9E1FA]\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Document]  WITH CHECK ADD  CONSTRAINT [FK1C630FA96509601E] FOREIGN KEY([BelongsTo_id])\nREFERENCES [dbo].[Document] ([ID])\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_Document] CHECK CONSTRAINT [FK1C630FA96509601E]\nGO\n</code></pre>"},{"location":"database/release-notes/#optionalfieldvalues_documentdetail","title":"OptionalFieldValues_DocumentDetail","text":"<pre><code>CREATE TABLE [dbo].[OptionalFieldValues_DocumentDetail](\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Value] [nvarchar](255) NULL,\n    [OptionalField_id] [bigint] NULL,\n    [BelongsTo_id] [bigint] NULL,\nPRIMARY KEY CLUSTERED \n(\n    [ID] ASC\n)WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_DocumentDetail]  WITH CHECK ADD  CONSTRAINT [FK1C630FA95BD9E1FB] FOREIGN KEY([OptionalField_id])\nREFERENCES [dbo].[OptionalFields] ([ID])\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_DocumentDetail] CHECK CONSTRAINT [FK1C630FA95BD9E1FB]\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_DocumentDetail]  WITH CHECK ADD  CONSTRAINT [FK1C630FA96509601A] FOREIGN KEY([BelongsTo_id])\nREFERENCES [dbo].[DocumentDetail] ([ID])\nGO\n\nALTER TABLE [dbo].[OptionalFieldValues_DocumentDetail] CHECK CONSTRAINT [FK1C630FA96509601A]\nGO\n</code></pre>"},{"location":"database/release-notes/#systemtransientdata","title":"SystemTransientData","text":"<pre><code>CREATE TABLE [dbo].[SystemTransientData]\n(\n    [ID] INT NOT NULL PRIMARY KEY, \n    [Group] VARCHAR(50) NULL, \n    [Key] VARCHAR(100) NULL, \n    [Description] VARCHAR(MAX) NULL, \n    [Value] VARCHAR(MAX) NULL, \n    [Value_id] BIGINT NULL, \n    [User] VARCHAR(50) NULL, \n    [Process] VARCHAR(50) NULL, \n    [ProcessStep] VARCHAR(50) NULL, \n    [DataExpiry] DATETIME NULL\n)\n</code></pre>"},{"location":"database/release-notes/#email","title":"Email","text":"<pre><code>CREATE TABLE [dbo].[Email](\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Subject] [varchar](150) NOT NULL,\n    [Body] [varchar](max) NOT NULL,\n    [ToEmailAddresses] [varchar](max) NULL,\n    [CcEmailAddresses] [varchar](max) NULL,\n    [BccEmailAddresses] [varchar](max) NULL,\n    [TemplateName] [varchar](50) NULL,\n    [TemplateParameters] [varchar](max) NULL,\n    [AttachmentPaths] [varchar](max) NULL,\n    [ReportAttachments] [varchar](max) NULL,\n    [ExcelAttachments] [varchar](max) NULL,\n    [FileAttachments] [varchar](max) NULL,\n    [CreateDate] [datetime] NULL,\n    [RequestDate] [datetime] NULL,\n    [RequestApplication] [varchar](50) NULL,\n    [SendDate] [datetime] NULL,\n    [NumberOfRetries] [int] NULL,\n    [Status] [varchar](50) NOT NULL,    \n CONSTRAINT [PK_Emails] PRIMARY KEY CLUSTERED \n(\n    [ID] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]\n) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]\n</code></pre>"},{"location":"database/release-notes/#emaillog","title":"EmailLog","text":"<pre><code>CREATE TABLE [dbo].[EmailLog](\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Email_id] [bigint] NOT NULL FOREIGN KEY REFERENCES Email(ID),\n    [Date] [datetime] NOT NULL,\n    [Message] [varchar](max) NOT NULL,  \n CONSTRAINT [PK_EmailLog] PRIMARY KEY CLUSTERED \n(\n    [ID] ASC\n)\nWITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]\n) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]\n</code></pre>"},{"location":"database/release-notes/#emailtemplate","title":"EmailTemplate","text":"<pre><code>CREATE TABLE [dbo].[EmailTemplate](\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Name] [varchar](50) NOT NULL,\n    [Description] [varchar](150) NULL,\n    [Definition] [varchar](max) NOT NULL,\n    [Format] [varchar](50) NOT NULL,\n    [AuditDate] [datetime] NULL,\n    [AuditUser] [varchar](50) NULL,\n    [Version] [int] NOT NULL,\n CONSTRAINT [PK_EmailTemplate] PRIMARY KEY CLUSTERED \n(\n    [ID] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY],\n CONSTRAINT [IX_EmailTemplate] UNIQUE NONCLUSTERED \n(\n    [Name] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]\n) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]\n</code></pre>"},{"location":"database/release-notes/#changed-tables","title":"Changed tables","text":""},{"location":"database/release-notes/#users","title":"Users","text":"<p>Add column AllowProcessCatalog <pre><code>[AllowProcessCatalog] BIT NOT NULL,\n</code></pre></p>"},{"location":"database/release-notes/#systemsettings","title":"SystemSettings","text":"<p>Add column EncryptionKey <pre><code>[EncryptionKey] VARCHAR(64) NULL,\n</code></pre></p>"},{"location":"database/release-notes/#process","title":"Process","text":"<p>Increase size of Process Name and Description, add Template_version and Template_id <pre><code>[Name] [varchar](50) NOT NULL,\n[Description] [varchar](50) NOT NULL,\n[Template_version] INT NULL, \n[Template_id] VARCHAR(50) NULL, \n</code></pre></p>"},{"location":"database/release-notes/#processmembers","title":"ProcessMembers","text":"<p>Increase size of Process column <pre><code>[Process] VARCHAR(50) NOT NULL,\n</code></pre></p>"},{"location":"database/release-notes/#processstep","title":"ProcessStep","text":"<p>Increase size of Process column <pre><code>[Process] VARCHAR(50) NOT NULL,\n</code></pre></p>"},{"location":"database/release-notes/#transaction","title":"Transaction","text":"<p>Increase size of Process column <pre><code>[Process] VARCHAR(50) NULL,\n</code></pre></p>"},{"location":"database/release-notes/#processsteplookup","title":"ProcessStepLookup","text":"<p>Increase size of Process column <pre><code>[Process] VARCHAR(50) NULL,\n</code></pre></p>"},{"location":"database/release-notes/#processsteplookupdynamic","title":"ProcessStepLookupDynamic","text":"<p>Increase size of Process column <pre><code>[Process] VARCHAR(50) NULL,\n</code></pre></p>"},{"location":"database/release-notes/#removed-stored-procedures","title":"Removed Stored Procedures","text":""},{"location":"database/release-notes/#emailtemplate_1","title":"EmailTemplate","text":"<p>Removed as Scheduler no longer sends emails using stored procedures</p>"},{"location":"database/release-notes/#new-data","title":"New Data","text":""},{"location":"database/release-notes/#migration-data","title":"Migration Data","text":"<pre><code>INSERT INTO Migration ([Name], [Description], [Log], [CreatedDate], [CompletedDate])\nVALUES  ('SCHEMA_500', 'Schema Version 5.0.0', 'Initialised by database create script', GETDATE(), GETDATE()),\n        ('DATA_500', 'Data Version 5.0.0', 'Initialised by database create script', GETDATE(), GETDATE()),\n        ('CLR_500', 'CLR Version 5.0.0', 'Initialised by database create script', GETDATE(), GETDATE())\n</code></pre>"},{"location":"database/release-notes/#emailtemplate-data","title":"EmailTemplate Data","text":"<pre><code>INSERT [dbo].[EmailTemplate] ( [Name], [Description], [Definition], [Format], [AuditDate], [AuditUser], [Version]) \nVALUES ( N'IntegrationError', N'This template is used by Scheduler injected jobs to notify of a failed document sync', N'{{\n  headerImage({\n    imageUrl:''https://www.granitewms.com/wp-content/uploads/2020/07/GraniteWMS-1.png'',\n    backgroundColor:''#182026''\n  })\n}}\n\n# Document {{documentNumber}} failed to sync\n\n{{#if documentLogs}}\n### Document header failed to sync:\n{{documentLogs}}\n{{/if}}\n\n{{#if documentDetailLogs}}\n### Document details failed to sync:\n{{documentDetailLogs}}\n{{/if}}', N'markdown', GETDATE(), N'AUTOMATION', 1)\n</code></pre>"},{"location":"database/release-notes/#systemsettings_1","title":"SystemSettings","text":"<ul> <li>Add SQLCLR UtilityApi setting</li> </ul> <pre><code>INSERT [dbo].[SystemSettings] ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser])\n('SQLCLR', 'UtilityApi', '' , 'Utility API Address', 'string', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre> <ul> <li> <p>Add Custodian SystemSettings: <pre><code>INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser, EncryptionKey)\nVALUES \n('GRANITECUSTODIAN', 'Repo_id', 'gVYmRwrftflB7Ffr3FCq2cv2555odnaHqww9lmtAv+w=', '', 1, 1, GETDATE(), 'AUTOMATION', '3SsPIaHkYgQdiMhgeRsMpA=='),\n('GRANITECUSTODIAN', 'Token', 'qlL0OC2DjetOxQWFfaVHomADvFcjHqJsmRwCDly5SjArj7JRpAV5r3mAwPSBbn21ZpOtvv75Ht388lYtkTQJe3AYb6XrSPU7w26SB+TU9230WeCGpBouYdMSiZbva3v7E3DU4TVpFDn5o8vxKtDLh8NLnyfNS4X0aY9hGWBoR0Wqsn1xuAm7bWQwtzT74sl1XVM69BQYYyglDLD10sZykvCC9aJOdkMUGWKNVY+7Ra1YznwLJskxqU4WR6dxo2y6', '', 1, 1, GETDATE(), 'AUTOMATION', '3SsPIaHkYgQdiMhgeRsMpA=='),\n('GRANITECUSTODIAN', 'Stores', 'Approved,Draft', '', 0, 1, GETDATE(), 'AUTOMATION', null)\n</code></pre></p> </li> <li> <p>Add GraniteScheduler UtilityApiUrl setting: <pre><code>INSERT [dbo].[SystemSettings] ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser])\nVALUES  ('GraniteScheduler', 'UtilityApiUrl', '', 'The UtilityAPI URL', 'string', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></p> </li> <li> <p>Add Utility API System Settings: <pre><code>INSERT [dbo].[SystemSettings] ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser]) \nVALUES  ('Granite.Utility', 'UserName', '', 'Username for the SMTP server', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'Password', '', 'Password for the SMTP server', 'string', 1, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'Host', '', 'The address of the SMTP server', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'Port', '', 'Port number to be used when accessing the SMTP server', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'EnableSsl', 'true', 'Use SSL when accessing the SMTP server. True or False', 'bool', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'From', '', 'Email address that will be used to send mail', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'FromName', '', 'The sender name that will display to users who receive emails', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'RetryInterval', '15', 'Number of seconds to wait before retrying processing an email', 'int', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'MaxNumberOfRetries', '3', 'Maximum number of times to retry processing an email', 'int', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'EmailAttachmentFolder', '', 'Full filepath to folder to export email attachments to. Leave empty to use the Utility API install folder', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('Granite.Utility', 'SSRSWebServiceUrl', '', 'URL for SSRS Report Server', 'string', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></p> </li> <li> <p>QuickBooks Integration <pre><code>INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser]) \nVALUES  \n(N'IntegrationQuickBooks', N'QuickBooksCompanyFile', N'', N'File path to the QuickBooks company file', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'MasterItemSyncEnable', N'false', N'Enables syncing MasterItems from QuickBooks to Granite', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'MasterItemSyncInterval', N'300', N'Interval to sync MasterItems at. Measured in seconds', N'int', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'MasterItemSyncInventoryItems', N'true', N'Enable or disable syncing Inventory Items', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'MasterItemSyncAssemblyItems', N'true', N'Enable or disable syncing Assembly Items', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'MasterItemSyncServiceItems', N'true', N'Enable or disable syncing Service Items', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'SalesOrderSyncEnable', N'false', N'Enables syncing Sales Orders from QuickBooks to Granite', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'SalesOrderSyncInterval', N'300', N'Interval to sync Sales Orders at. Measured in seconds', N'int', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'SalesOrderPrefix', N'', N'Prefix that will be applied to Sales Order numbers when they are synced to Granite.', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'SalesOrderAfterHeaderSyncProcedure', N'', N'Name of stored procedure that will run after each SalesOrder header is synced to Granite', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'InvoiceSyncEnable', N'false', N'Enables syncing Invoices from QuickBooks to Granite', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'InvoiceSyncInterval', N'300', N'Interval to sync Invoices at. Measured in seconds', N'int', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'InvoicePrefix', N'', N'Prefix that will be applied to Invoice numbers when they are synced to Granite.', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'InvoiceAfterHeaderSyncProcedure', N'', N'Name of stored procedure that will run after each Invoice header is synced to Granite', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'PurchaseOrderSyncEnable', N'false', N'Enables syncing Purchase Orders from QuickBooks to Granite', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'PurchaseOrderSyncInterval', N'300', N'Interval to sync Purchase Orders at. Measured in seconds', N'int', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'PurchaseOrderPrefix', N'', N'Prefix that will be applied to Purchase Order numbers when they are synced to Granite.', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'PurchaseOrderAfterHeaderSyncProcedure', N'', N'Name of stored procedure that will run after each PurchaseOrder header is synced to Granite', N'string', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'TradingPartnerSyncEnable', N'false', N'Enables syncing TradingPartners from QuickBooks to Granite', N'bool', 0, 1, GETDATE(), N'AUTOMATION'),\n(N'IntegrationQuickBooks', N'TradingPartnerSyncInterval', N'300', N'Interval to sync TradingPartners at. Measured in seconds', N'int', 0, 1, GETDATE(), N'AUTOMATION')\n</code></pre></p> </li> </ul>"},{"location":"database/release-notes/#changed-data","title":"Changed Data","text":""},{"location":"database/release-notes/#users_1","title":"Users","text":"<ul> <li>Add AllowProcessCatalog permission</li> </ul>"},{"location":"database/release-notes/#defaultreplenishprocess","title":"DefaultReplenishProcess","text":"<ul> <li>Add NoEntities step</li> </ul>"},{"location":"database/release-notes/#systemsettings_2","title":"SystemSettings","text":"<ul> <li>Removed GraniteScheduler settings:<ul> <li>Host</li> <li>Port</li> <li>EnableSsl</li> <li>EmailAddress</li> <li>Username</li> <li>Password</li> <li>DisplayName</li> <li>TimeZone</li> </ul> </li> <li>All password settings isEncrypted = true</li> </ul>"},{"location":"database/release-notes/#applicationgrids","title":"ApplicationGrids","text":"<ul> <li>Added missing document fields to grids</li> <li>Remove SystemSettings grid</li> </ul>"},{"location":"database/release-notes/#accpacintegration","title":"AccpacIntegration","text":""},{"location":"database/release-notes/#changed-views_1","title":"Changed Views","text":""},{"location":"database/release-notes/#integration_accpac_autosimplymodetail","title":"Integration_Accpac_AutoSimplyMODetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_AutoSimplyMODetail] AS\nSELECT  MOUNIQ Document_ERPIdentification,\n        [ITEMNO] MasterItem_ERPIdentification, \n        0 ERPIdentification,\n        0 LineNumber, \n        [ORDQTYUM] UOMQty, \n        [ORDQTY] Qty, \n        [STKUOM] UOM, \n        1 UOMConversion,\n        RTRIM(LTRIM(AREACD)) ToLocation,\n        '' FromLocation,\n        0 Completed,\n        'OUTPUT' [Type],\n        [COMMENTS] as Instruction,\n        [ITEMDESC] as Comment\nFROM [$(AccpacDatabase)].dbo.[MFORDH] WITH (NOLOCK)\nUNION ALL\nSELECT  MOUNIQ Document_ERPIdentification,\n        [COMPID] MasterItem_ERPIdentification, \n        LINENUM ERPIdentification,\n        LINENUM LineNumber, \n        [REQQTY] UOMQty, \n        [REQQTY] Qty, \n        [COMPUOM] UOM, \n        1 UOMConversion,\n        '' ToLocation,\n        RTRIM(LTRIM([LOCATION])) FromLocation,      \n        0 Completed,\n        'INPUT' as [Type],\n        '' as Instruction,\n        [COMPDESC] as Comment\nFROM [$(AccpacDatabase)].dbo.[MFORDD] WITH (NOLOCK)\n</code></pre>"},{"location":"database/release-notes/#integration_accpac_internalusagedetail","title":"Integration_Accpac_InternalUsageDetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_InternalUsageDetail] AS\nSELECT  [SEQUENCENO] Document_ERPIdentification,\n        [LINENO] ERPIdentification, \n        [LINENO] LineNumber,\n        [LOCATION] FromLocation, \n        QUANTITY Qty, \n        ITEMNO MasterItem_ERPIdentification,\n        SUBSTRING(COMMENTS, 1, 50) Comment\nFROM [$(AccpacDatabase)].dbo.[ICICED] \n</code></pre>"},{"location":"database/release-notes/#integration_accpac_intransitdetail","title":"Integration_Accpac_IntransitDetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_IntransitDetail] as\nSELECT  [LINENO] LineNumber,\n        [LINENO] ERPIdentification, \n        RTRIM(FROMLOC) FromLocation, \n        RTRIM(TOLOC) ToLocation, \n        RTRIM(GITLOC) IntransitLocation, \n        QTYREQ Qty, \n        RTRIM(ITEMNO) MasterItem_ERPIdentification, \n        RTRIM(COMMENTS) Comment,\n        [ICTREH].[TRANFENSEQ] Document_ERPIdentification\nFROM [$(AccpacDatabase)].dbo.[ICTRED] with (nolock) INNER JOIN \n[$(AccpacDatabase)].dbo.[ICTREH] with (NOLOCK) ON [ICTRED].[TRANFENSEQ] = [ICTREH].[TRANFENSEQ]\nWHERE [ICTREH].DOCTYPE = 2\n</code></pre>"},{"location":"database/release-notes/#integration_accpac_purchaseorderdetail","title":"Integration_Accpac_PurchaseOrderDetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_PurchaseOrderDetail] as\nSELECT  PORLREV LineNumber, \n        [SQORDERED] Qty, \n        RTRIM([ORDERUNIT]) UOM, \n        [ORDERCONV] UOMConversion,\n        [OQORDERED] UOMQty, \n        RTRIM([LOCATION]) ToLocation,\n        CASE WHEN [COMPLETION] &lt; 2 THEN 0 ELSE 1 END Completed, \n        RTRIM([ITEMNO]) MasterItem_ERPIdentification, \n        ROUND(UNITCOST,2) UnitValue,\n        PORHSEQ Document_ERPIdentification,\n        PORLREV ERPIdentification\nFROM [$(AccpacDatabase)].dbo.[POPORL] WITH (NOLOCK)\nWHERE STOCKITEM = 1\n</code></pre>"},{"location":"database/release-notes/#integration_accpac_receiptdetail","title":"Integration_Accpac_ReceiptDetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_ReceiptDetail] as\nSELECT  [LINENO] LineNumber,\n        [LINENO] ERPIdentification, \n        RTRIM(FROMLOC) FromLocation, \n        RTRIM(TOLOC) ToLocation, \n        RTRIM(GITLOC) IntransitLocation, \n        QTYTRA Qty, \n        RTRIM(ITEMNO) MasterItem_ERPIdentification, \n        RTRIM(COMMENTS) Comment,\n        [ICTREH].[TRANFENSEQ] Document_ERPIdentification\nFROM [$(AccpacDatabase)].dbo.[ICTRED] with (nolock) INNER JOIN \n[$(AccpacDatabase)].dbo.[ICTREH] with (NOLOCK) ON [ICTRED].[TRANFENSEQ] = [ICTREH].[TRANFENSEQ] LEFT JOIN\n[$(AccpacDatabase)].dbo.[ICTRID] with (nolock) ON [ICTRED].DETAILNUM = [ICTRID].DETAILNUM AND [ICTREH].FROMNUM = [ICTRID].DOCNUM\nWHERE [ICTREH].DOCTYPE = 3\n</code></pre>"},{"location":"database/release-notes/#integration_accpac_salesorderdetail","title":"Integration_Accpac_SalesOrderDetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_SalesOrderDetail] as\nSELECT  ORDUNIQ Document_ERPIdentification,\n        LINENUM [LineNumber], \n        LINENUM ERPIdentification, \n        ([UNITCONV] * ([QTYORDERED]+[QTYSHPTODT])) UOMQty, \n        [QTYORDERED]+[QTYSHPTODT] Qty, \n        RTRIM([ORDUNIT]) UOM, \n        [UNITCONV] UOMConversion,\n        RTRIM([LOCATION]) FromLocation, \n        RTRIM([ITEM]) MasterItem_ERPIdentification, \n        CASE WHEN [COMPLETE] &lt; 2 THEN 0 ELSE 1 END  Completed\nFROM [$(AccpacDatabase)].dbo.[OEORDD] WITH (NOLOCK)\nWHERE STOCKITEM = 1\n</code></pre>"},{"location":"database/release-notes/#integration_accpac_transferdetail","title":"Integration_Accpac_TransferDetail","text":"<pre><code>CREATE VIEW [dbo].[Integration_Accpac_TransferDetail] as\nSELECT  [LINENO] LineNumber, \n        RTRIM(FROMLOC) FromLocation, \n        RTRIM(TOLOC) ToLocation, \n        RTRIM(GITLOC) IntransitLocation, \n        QTYREQ Qty, \n        RTRIM(ITEMNO) MasterItem_ERPIdentification, \n        RTRIM(COMMENTS) Comment,\n        [ICTREH].[TRANFENSEQ] Document_ERPIdentification,\n        [LINENO] ERPIdentification\nFROM [$(AccpacDatabase)].dbo.[ICTRED] with (nolock) INNER JOIN \n[$(AccpacDatabase)].dbo.[ICTREH] with (NOLOCK) ON [ICTRED].[TRANFENSEQ] = [ICTREH].[TRANFENSEQ]\nWHERE [ICTREH].DOCTYPE = 1\n</code></pre>"},{"location":"database/release-notes/#masteritemalias_view","title":"MasterItemAlias_View","text":"<pre><code>ALTER VIEW [dbo].[MasterItemAlias_View]\n\n    AS \nSELECT ROW_NUMBER() OVER (ORDER BY [$(GraniteDatabase)].dbo.MasterItem.ID) AS ID, \nCAST([$(AccpacDatabase)].dbo.ICIOTH.MANITEMNO as varchar(16)) COLLATE SQL_Latin1_General_CP1_CI_AS AS Code, \nCAST([$(AccpacDatabase)].dbo.ICUNIT.UNIT as varchar(16)) COLLATE SQL_Latin1_General_CP1_CI_AS AS UOM, \n[$(AccpacDatabase)].dbo.ICUNIT.CONVERSION AS Conversion, CAST(1 as bit)as IsActive, \nGETDATE() as AuditDate, '' as AuditUser, \n[$(GraniteDatabase)].dbo.MasterItem.ID AS MasterItem_id,NULL as ERPIdentification,0 as Version\nFROM         [$(AccpacDatabase)].dbo.ICIOTH RIGHT OUTER JOIN\n                      [$(AccpacDatabase)].dbo.ICUNIT ON [$(AccpacDatabase)].dbo.ICIOTH.UNIT COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICUNIT.UNIT AND \n                      [$(AccpacDatabase)].dbo.ICIOTH.ITEMNO COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICUNIT.ITEMNO RIGHT OUTER JOIN\n                      [$(GraniteDatabase)].dbo.MasterItem RIGHT OUTER JOIN\n                      [$(AccpacDatabase)].dbo.ICITEM ON [$(GraniteDatabase)].dbo.MasterItem.Code COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICITEM.ITEMNO ON \n                      [$(AccpacDatabase)].dbo.ICUNIT.ITEMNO COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICITEM.ITEMNO\nWHERE     ([$(GraniteDatabase)].dbo.MasterItem.ID IS NOT NULL) AND ([$(AccpacDatabase)].dbo.ICIOTH.MANITEMNO IS NOT NULL)\nUNION\nSELECT  * FROM [$(GraniteDatabase)].dbo.MasterItemAlias\nGO\n</code></pre>"},{"location":"database/release-notes/#changed-stored-procedures","title":"Changed Stored Procedures","text":""},{"location":"database/release-notes/#integrationprocesstransfer","title":"IntegrationProcessTransfer","text":"<pre><code>ALTER PROCEDURE [dbo].[IntegrationProcessTransfer]\n    -- Add the parameters for the stored procedure here\n\nAS\nBEGIN\n    SET NOCOUNT ON;\n    DECLARE @Debug Bit = 0\n    DECLARE @DocumentNumber varchar(30)\n    DECLARE @Document_id bigint\n    DECLARE @TradingPartner_id bigint\n    DECLARE @TradingPartnerCode varchar(20)\n    DECLARE @TradingPartnerDescription varchar(60)\n    DECLARE @AccpacReference varchar(60) = ''\n    DECLARE @TradingPartnerReferenceNumber varchar(30) = ''\n    DECLARE @ToLocation varchar(50) = ''\n    DECLARE @Description varchar(60)\n    DECLARE @Priority int\n    DECLARE @ERPLocation varchar(15)\n    DECLARE @Site varchar(30) = ''  --Code required to determine the SITE\n    DECLARE @User varchar(20) = 'INTEGRATION'\n    DECLARE @Date datetime = GETDATE()\n    DECLARE @DocumentType varchar(30) = 'TRANSFER'\n    DECLARE @AccpacType int\n    DECLARE @Status varchar(30)\n    DECLARE @ErrorMessage NVARCHAR(4000) = NULL\n    DECLARE @ErrorSeverity INT\n    DECLARE @ErrorState INT\n    DECLARE @ExpectedShipDate DateTime\n    DECLARE @ORDUNIQ DECIMAL(19,0)\n    DECLARE @GraniteOrderStatus varchar(20)\n    DECLARE @GraniteDocumentType varchar(20)\n    DECLARE @ACCPAC_FROMNUM VARCHAR(250)\n    DECLARE @COMMENTS VARCHAR(250)\n    DECLARE @LINE VARCHAR(250)\n    DECLARE @DETAILNUM VARCHAR(250)\n    DECLARE @FROMLOC VARCHAR(250)\n    DECLARE @TOLOC VARCHAR(250)\n    DECLARE @GITLOC VARCHAR(250)\n    DECLARE @ACCPAC_QTYREC DECIMAL(9,4)\n    DECLARE @ACCPAC_QUANTITY DECIMAL (9,4)\n    DECLARE @ACCPAC_QTYTRA DECIMAL (9,4)\n    DECLARE @ITEMNO VARCHAR(250)\n    DECLARE @ITEMID bigint\n    DECLARE @GRANITELINEID bigint\n\n    --Declare cursor for all Documents to be integrated.\n\n    DECLARE IntegrationQueueCursor CURSOR FOR\n    SELECT   ERP_id , [DocumentType] FROM [$(GraniteDatabase)].dbo.IntegrationDocumentQueue \n    WHERE [Status] = 'ENTERED' AND [DocumentType] IN ('TRANSFER','INTRANSIT','RECEIPT')\n\n    OPEN IntegrationQueueCursor\n    FETCH NEXT FROM IntegrationQueueCursor\n    INTO @ORDUNIQ, @DocumentType\n\n    WHILE @@FETCH_STATUS = 0\n    BEGIN\n\n        UPDATE [$(GraniteDatabase)].dbo.IntegrationDocumentQueue \n        SET [Status] = 'POSTING', IntegrationDateTime = getdate()\n        WHERE [Status] = 'ENTERED' AND [DocumentType] IN ('TRANSFER','INTRANSIT','RECEIPT') and ERP_id = @ORDUNIQ\n\n\n        SELECT @DocumentNumber = RTRIM(LTRIM([DOCNUM])) collate Latin1_General_CI_AS, \n        @Description = HDRDESC collate Latin1_General_CI_AS, \n        @AccpacReference = REFERENCE  collate Latin1_General_CI_AS,\n        @ACCPAC_FROMNUM = FROMNUM collate Latin1_General_CI_AS,\n        @ExpectedShipDate = CASE WHEN EXPARDATE = 0 THEN '' ELSE CONVERT(DateTime,CONVERT(varchar(10),EXPARDATE)) END,\n        @Status = 'ENTERED'\n        FROM [$(AccpacDatabase)].dbo.[ICTREH] with (NOLOCK)\n        WHERE TRANFENSEQ = @ORDUNIQ\n\n        IF @Debug = 1\n            PRINT 'IN Cursor -Record found:' + @DocumentNumber\n\n                BEGIN TRY\n                    BEGIN TRANSACTION\n                    IF @Debug = 1\n                        PRINT 'In Try and Transaction block'\n\n                    SELECT TOP 1  @ERPLocation = [FROMLOC], @ToLocation = [TOLOC] \n                    FROM [$(AccpacDatabase)].dbo.[ICTRED] with (Nolock) \n                    WHERE [TRANFENSEQ] = @ORDUNIQ\n\n                    IF @DocumentType = 'RECEIPT'        --If the Document is a Receipt then set the ERPLocation to the TOLocation\n                        SELECT @ERPLocation = @ToLocation\n\n\n                    SELECT @TradingPartnerCode = @ERPLocation\n                    SELECT @TradingPartnerDescription = 'TRANSFER TO WHSE:' + isnull(@TradingPartnerCode,'') + ' TO WHSE:' + isnull(@ToLocation,'')\n\n                    -- Insert TradingPartner\n                    SELECT @TradingPartner_id = ID FROM [$(GraniteDatabase)].dbo.TradingPartner WHERE Code = @TradingPartnerCode AND DocumentType = @DocumentType\n                    IF ISNULL(@TradingPartner_id,'') = ''\n                    BEGIN\n                        INSERT INTO [$(GraniteDatabase)].dbo.TradingPartner\n                        (Code, Description, DocumentType, isActive, AuditDate, AuditUser)\n                        VALUES\n                        (@TradingPartnerCode, @TradingPartnerDescription, @GraniteDocumentType, 1, GETDATE(), @User)\n                    END\n\n                    --======Update the Document Header table or insert the Document Header accordingly\n                    IF EXISTS(SELECT ID FROM [$(GraniteDatabase)].dbo.Document WHERE Number = @DocumentNumber)\n                    BEGIN\n\n                        UPDATE [$(GraniteDatabase)].dbo.Document SET ERPLocation = @ERPLocation, [Site] = @Site, \n                        TradingPartnerCode = @TradingPartnerCode, TradingPartnerDescription = @TradingPartnerDescription,\n                        AuditDate = @Date, AuditUser = @User ,[Description] =  @ACCPAC_FROMNUM + '--'+ @Description\n                        WHERE Number = @DocumentNumber\n\n                        SELECT @Document_id = ID , @GraniteOrderStatus = [Status] FROM [$(GraniteDatabase)].dbo.Document \n                        WHERE Number = @DocumentNumber\n\n                        IF @Status IN ('ONHOLD','COMPLETE','CANCELLED')\n                            UPDATE [$(GraniteDatabase)].dbo.Document SET [Status] = @Status,ExpectedDate = @ExpectedShipDate\n                            WHERE ID = @Document_id\n                        IF @Status = 'ENTERED' and @GraniteOrderStatus NOT IN ('RELEASED','COMPLETE')\n                            UPDATE [$(GraniteDatabase)].dbo.Document SET [Status] = @Status, ExpectedDate = @ExpectedShipDate\n                            WHERE ID = @Document_id\n\n                    END\n                    ELSE\n                    BEGIN\n                        INSERT INTO [$(GraniteDatabase)].dbo.Document (Number,[Description],CreateDate,TradingPartnerCode, TradingPartnerDescription, ERPLocation,[Site],\n                        AuditDate,AuditUser,[Type],[Status],ExpectedDate,isActive)\n                        SELECT @DocumentNumber,  @ACCPAC_FROMNUM + '--'+ @Description, @Date, @TradingPartnerCode, @TradingPartnerDescription, @ERPLocation, @Site, \n                        @Date, @User, @DocumentType, @Status ,@ExpectedShipDate,1\n\n                        SELECT  @Document_id = (SELECT ID FROM [$(GraniteDatabase)].dbo.Document WHERE Number = @DocumentNumber)\n                        IF @Debug = 1\n                            PRINT @Document_id\n\n                    END\n                    --=======End DOcument Header Section=============================================== \n\n                    --=====Start Inserting or Updaing the items depending on whether they exists or not\n\n                    IF ISNULL(@Document_id,'') &lt;&gt; ''\n                    BEGIN\n                        --Update Existing Granite Lines\n                        --We know these Lines Exist Because of the Inner Join\n                        DECLARE detail CURSOR FOR\n                        SELECT [LINENO], DETAILNUM, FROMLOC, TOLOC, GITLOC, QTYREQ, QUANTITY, ITEMNO,COMMENTS  \n                        FROM [$(AccpacDatabase)].dbo.[ICTRED] with (nolock) \n                        WHERE  [TRANFENSEQ] = @ORDUNIQ\n                        OPEN detail;\n\n                        FETCH NEXT FROM detail \n                        INTO @LINE, @DETAILNUM, @FROMLOC, @TOLOC, @GITLOC, @ACCPAC_QTYREC, @ACCPAC_QUANTITY, @ITEMNO, @COMMENTS;\n                        WHILE @@FETCH_STATUS = 0\n                        BEGIN\n\n                        /*GET GRANITE ITEM ID*/\n                        SELECT @ITEMID = ID FROM [$(GraniteDatabase)].dbo.MasterItem WHERE FORMATTEDCODE = @ITEMNO\n\n                        SELECT @GRANITELINEID = ID FROM [$(GraniteDatabase)].dbo.[DocumentDetail] \n                        WHERE DOCUMENT_ID = @Document_id AND ITEM_ID = @ITEMID AND LineNumber = @LINE\n\n                        IF ISNULL(@GRANITELINEID, 0) = 0\n                        BEGIN\n                            IF @DocumentType = 'RECEIPT'\n                            BEGIN\n                                -- Fetch qty from Table ICTRID, based on TRANSFER (FROMNUM = @ACCPAC_FROMNUM)\n                                -- QTYTRA = Quantity Transfer to Date\n\n                                SELECT @ACCPAC_QTYTRA = QTYTRA\n                                FROM  [$(AccpacDatabase)].dbo.ICTRID with (nolock)\n                                WHERE (DOCNUM = @ACCPAC_FROMNUM) AND (DETAILNUM = @DETAILNUM)\n\n                                --RECEIPT use QUANTITY this is the transfer qty instead of the requested original qty, can only receipt what was actual transfer\n                                --The from location becomes the transit location, I leave the transit no need in granite\n                                --@ACCPAC_QUANTITY\n                                INSERT INTO [$(GraniteDatabase)].dbo.[DocumentDetail] \n                                    (ITEM_ID, [COMMENT], LINENUMBER, FROMLOCATION, TOLOCATION, IntransitLocation, QTY, \n                                    DOCUMENT_ID, ActionQty, Completed, AuditDate, AuditUser)\n                                        values (@ITEMID, SUBSTRING(@COMMENTS,1,50), @LINE, @FROMLOC, @TOLOC, @GITLOC, \n                                        @ACCPAC_QTYTRA, @Document_id, 0, 0,  GETDATE(),@User)\n                            END\n                            ELSE\n                            BEGIN\n                                --@ACCPAC_QTYREC\n                                INSERT INTO [$(GraniteDatabase)].dbo.[DocumentDetail] \n                                (ITEM_ID, [COMMENT], LINENUMBER, FROMLOCATION, TOLOCATION, IntransitLocation, QTY, \n                                DOCUMENT_ID, ActionQty, Completed, AuditDate, AuditUser)\n                                    values (@ITEMID, SUBSTRING(@COMMENTS,1,50), @LINE, RTRIM(@FROMLOC), RTRIM(@TOLOC), RTRIM(@GITLOC), \n                                    @ACCPAC_QTYREC, @Document_id, 0, 0,  GETDATE(), @User)\n                            END\n                        END\n                        ELSE\n                        BEGIN\n                            UPDATE [$(GraniteDatabase)].dbo.[DocumentDetail] SET\n                            [Qty] = @ACCPAC_QTYREC, Completed = 0, ToLocation = RTRIM(@TOLOC), IntransitLocation = RTRIM(@GITLOC),\n                            [FromLocation] = RTRIM(@FROMLOC), AuditDate = GETDATE(), AuditUser = @User\n                            WHERE [$(GraniteDatabase)].dbo.[DocumentDetail].[ID] = @GRANITELINEID\n                        END\n                        FETCH NEXT FROM detail \n                        INTO @LINE, @DETAILNUM, @FROMLOC, @TOLOC, @GITLOC, @ACCPAC_QTYREC, @ACCPAC_QUANTITY, @ITEMNO,@COMMENTS;\n                        END\n                        CLOSE detail;\n                        DEALLOCATE detail;\n\n                        UPDATE [$(GraniteDatabase)].dbo.DocumentDetail SET MultipleEntries = 1 \n                        WHERE Document_id = @Document_id AND Item_id IN (SELECT DISTINCT Item_id FROM [$(GraniteDatabase)].dbo.DocumentDetail GROUP BY Document_id, Item_id HAVING Document_id = @Document_id AND COUNT(ID) &gt; 1)\n\n                    END\n                    UPDATE [$(GraniteDatabase)].dbo.IntegrationDocumentQueue \n                    SET [Status] = 'POSTED', IntegrationDateTime = getdate()\n                    WHERE [Status] = 'POSTING' and ERP_id = @ORDUNIQ\n\n            END TRY\n\n            BEGIN CATCH\n                SELECT @ErrorMessage = ERROR_MESSAGE(), @ErrorSeverity = ERROR_SEVERITY(), @ErrorState = ERROR_STATE();\n                RAISERROR (@ErrorMessage, @ErrorSeverity, @ErrorState);\n                IF @Debug = 1\n                    PRINT @ErrorMessage\n\n                IF @@TRANCOUNT &gt; 0\n                    ROLLBACK TRANSACTION;\n\n            END CATCH\n\n            IF @@TRANCOUNT &gt; 0\n                COMMIT TRANSACTION;\n\n        FETCH NEXT FROM IntegrationQueueCursor\n        INTO @ORDUNIQ, @DocumentType\n    END\n    CLOSE IntegrationQueueCursor\n    DEALLOCATE IntegrationQueueCursor\n\nEND  --Stored Procedure\n\nGO\n</code></pre>"},{"location":"database/release-notes/#pastelevointegration","title":"PastelEvoIntegration","text":""},{"location":"database/release-notes/#new-views","title":"New Views","text":""},{"location":"database/release-notes/#integration_evolution_interbranchrequisitionheader","title":"Integration_Evolution_InterBranchRequisitionHeader","text":"<pre><code>CREATE VIEW [Integration_Evolution_InterBranchRequisitionHeader] AS\nSELECT  CAST(IDWhseIBT as varchar) ERPIdentification, \n        [cIBTNumber] Number, \n        [cIBTDescription] [Description], \n        CASE iIBTStatus \n            WHEN 3 THEN 'ENTERED' \n            WHEN 4 THEN 'RELEASED'\n            ELSE 'COMPLETE' \n        END [Status], \n        WhseMst.Code ERPLocation,\n        'INTRANSIT' [Type], \n        '' as [Site], \n        GETDATE() as CreateDate\nFROM [$(PastelEvoDatabase)].dbo._etblWhseIBT INNER JOIN\n[$(PastelEvoDatabase)].dbo.WhseMst ON _etblWhseIBT.iWhseIDFrom = WhseMst.WhseLink\nWHERE iIBTStatus IN (3, 4, 5)\n</code></pre>"},{"location":"database/release-notes/#integration_evolution_interbranchrequisitiondetail","title":"Integration_Evolution_InterBranchRequisitionDetail","text":"<pre><code>CREATE VIEW [Integration_Evolution_InterBranchRequisitionDetail] as\nSELECT  CAST(IDWhseIBTLines as varchar) ERPIdentification, \n        CAST(ROW_NUMBER() OVER (PARTITION BY iWhseIBTID ORDER BY IDWhseIBTLines ASC) as varchar) LineNumber,  \n        CAST(iWhseIBTID as varchar) Document_ERPIdentification, \n        fQtyRequired Qty, \n        WhseMst.Code FromLocation, \n        WhseMst_2.Code IntransitLocation, \n        WhseMst_3.Code ToLocation, \n        cLotNumber Batch, \n        CAST(iStockID as varchar) MasterItem_ERPIdentification\nFROM [$(PastelEvoDatabase)].dbo.[_etblWhseIBTLines] WITH (NOLOCK) INNER JOIN\n[$(PastelEvoDatabase)].dbo.StkItem ON iStockID = StkItem.StockLink INNER JOIN\n[$(PastelEvoDatabase)].dbo.[_etblWhseIBT] ON iWhseIBTID = _etblWhseIBT.IDWhseIBT LEFT JOIN \n[$(PastelEvoDatabase)].dbo.WhseMst ON _etblWhseIBT.iWhseIDFrom = WhseMst.WhseLink LEFT JOIN\n[$(PastelEvoDatabase)].dbo.WhseMst WhseMst_2 ON _etblWhseIBT.iWhseIDIntransit = WhseMst_2.WhseLink LEFT JOIN\n[$(PastelEvoDatabase)].dbo.WhseMst WhseMst_3 ON _etblWhseIBT.iWhseIDTo = WhseMst_3.WhseLink \nWHERE iIBTStatus IN (3, 4, 5)\n</code></pre>"},{"location":"database/release-notes/#new-trigger","title":"New trigger","text":""},{"location":"database/release-notes/#triggergraniteinterbranchrequisition","title":"TriggerGraniteInterBranchRequisition","text":"<pre><code>GO\nUSE [$(PastelEVODatabase)]\nGO\n\nCREATE TRIGGER [dbo].[TriggerGraniteInterBranchRequisition]\n   ON  [$(PastelEVODatabase)].[dbo].[_etblWhseIBT]\n   AFTER INSERT, UPDATE\nAS\nBEGIN\n    SET NOCOUNT ON;\n\n    DECLARE @Site varchar(30) = ''  \n    DECLARE @ErrorMessage NVARCHAR(4000) = NULL\n    DECLARE @ErrorSeverity INT\n    DECLARE @ErrorState INT\n\n\n    BEGIN TRY\n    BEGIN TRANSACTION   \n        INSERT INTO [$(GraniteDatabase)].dbo.IntegrationDocumentQueue (ERP_id,DocumentNumber,DocumentType,[Status],LastUpdateDateTime)\n        SELECT IDWhseIBT, RTRIM(LTRIM([cIBTNumber])) collate Latin1_General_CI_AS, 'REQUISITION','ENTERED',getdate()\n        FROM Inserted\n        WHERE iIBTStatus IN (3,4,5)\n        AND NOT EXISTS(SELECT ID FROM [$(GraniteDatabase)].dbo.IntegrationDocumentQueue \n        WHERE DocumentNumber = RTRIM(LTRIM([cIBTNumber])) collate Latin1_General_CI_AS \n        AND IntegrationDocumentQueue.[Status] = 'ENTERED' AND ERP_id = IDWhseIBT)\n    END TRY\n\n    BEGIN CATCH\n        SELECT @ErrorMessage = ERROR_MESSAGE(), @ErrorSeverity = ERROR_SEVERITY(), @ErrorState = ERROR_STATE();\n        RAISERROR (@ErrorMessage, @ErrorSeverity, @ErrorState);\n\n        IF @@TRANCOUNT &gt; 0\n        BEGIN \n            ROLLBACK TRANSACTION;\n        END\n    END CATCH\n\n    IF @@TRANCOUNT &gt; 0\n    BEGIN \n        COMMIT TRANSACTION;\n    END\n\n\nEND \n</code></pre>"},{"location":"database/release-notes/#august-4510","title":"August (4.5.1.0)","text":""},{"location":"database/release-notes/#granitedatabase_1","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#new-views_1","title":"New Views","text":""},{"location":"database/release-notes/#datagrid_stockavailable_1","title":"Datagrid_StockAvailable","text":"<pre><code>CREATE VIEW [dbo].[DataGrid_StockAvailable]\nAS\nSELECT DISTINCT MasterItem.ID AS MasterItemId, \n       Code AS MasterItemCode, \n       Description AS MasterItemDescription,\n       MasterItem.Type,\n       MasterItem.Category,\n       UOM, \n       CASE WHEN (SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000) + ISNULL(PurchaseOrderQty, 0.000)) &gt; 0\n            THEN 'InStock'\n            WHEN (SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000) + ISNULL(PurchaseOrderQty, 0.000)) &lt;= 0\n            THEN 'NoStock'\n            END AS Status\n       ,\n       SUM(Qty) OVER(PARTITION BY MasterItem.ID) AS QtyInWarehouse, \n       ISNULL(SalesOrderQty, 0.000) AS QtyOnSalesOrders,\n       ISNULL(PurchaseOrderQty, 0.000) AS QtyOnPurchaceOrders,\n       (SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000)) AS QtyAfterSales,\n       (SUM(Qty) OVER(PARTITION BY MasterItem.ID) + ISNULL(PurchaseOrderQty, 0.000)) AS QtyAfterPurchaces,\n       (SUM(Qty) OVER(PARTITION BY MasterItem.ID) - ISNULL(SalesOrderQty, 0.000) + ISNULL(PurchaseOrderQty, 0.000)) AS TotalQtyAvailable\nFROM MasterItem LEFT JOIN \n     TrackingEntity ON MasterItem.ID = TrackingEntity.MasterItem_id OUTER APPLY\n     (SELECT (SUM(Qty) - SUM(ActionQty)) AS SalesOrderQty\n      FROM DocumentDetail LEFT JOIN \n           Document ON DocumentDetail.Document_id = Document.ID\n      WHERE Completed &lt;&gt; 1 AND\n            Cancelled &lt;&gt; 1 AND\n            Document.Status in ('ENTERED', 'RELEASED') AND \n            DocumentDetail.Item_id = MasterItem.ID AND \n            Document.Type = 'ORDER'\n      GROUP BY Item_id) AS SalesOrders\n      OUTER APPLY\n     (SELECT (SUM(Qty) - SUM(ActionQty)) AS PurchaseOrderQty\n      FROM DocumentDetail LEFT JOIN \n           Document ON DocumentDetail.Document_id = Document.ID\n      WHERE Completed &lt;&gt; 1 AND\n            Cancelled &lt;&gt; 1 AND\n            Document.Status in ('ENTERED', 'RELEASED') AND \n            DocumentDetail.Item_id = MasterItem.ID AND \n            Document.Type = 'RECEIVING'\n      GROUP BY Item_id) AS PurchaseOrders\nWHERE MasterItem.isActive = 1 AND\n      Qty &lt;&gt; 0 AND \n      TrackingEntity.InStock = 1\n</code></pre>"},{"location":"database/release-notes/#changed-views_2","title":"Changed Views","text":""},{"location":"database/release-notes/#api_querytransactionspickreversal","title":"API_QueryTransactionsPickReversal","text":"<ul> <li>Exclude packed items <pre><code>ALTER VIEW [dbo].[API_QueryTransactionsPickReversal]\nAS\nSELECT dbo.[Transaction].ID, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, dbo.[Transaction].ActionQty, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS [Document], dbo.[Transaction].IntegrationStatus, \n         dbo.CarryingEntity.Barcode AS Pallet, dbo.[Transaction].Comment, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, dbo.[Transaction].Type, dbo.[Transaction].IntegrationReference, dbo.[Transaction].ReversalTransaction_id, dbo.[Document].TradingPartnerCode, dbo.[Document].TradingPartnerDescription, dbo.[Document].Status, dbo.DocumentDetail.LineNumber\nFROM  dbo.[Transaction] INNER JOIN\n         dbo.DocumentDetail ON dbo.[Transaction].DocumentLine_id = dbo.DocumentDetail.ID LEFT OUTER JOIN\n         dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id LEFT OUTER JOIN\n         dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n         dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n         dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n         dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID FULL OUTER JOIN\n         dbo.TrackingEntity LEFT OUTER JOIN\n         dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID ON dbo.TrackingEntity.ID = dbo.[Transaction].TrackingEntity_id FULL OUTER JOIN\n         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID LEFT JOIN\n         dbo.[Transaction] T2 ON DocumentDetail.ID = T2.DocumentLine_id AND T2.[Type] = 'PACK'\nWHERE (dbo.[Transaction].Type = 'PICK') AND ISNULL(dbo.[Transaction].ReversalTransaction_id, 0) = 0 AND ISNULL(dbo.[Transaction].IntegrationStatus, 0) = 0 AND T2.ID IS NULL\nGO\n</code></pre></li> </ul>"},{"location":"database/release-notes/#api_querydocumentprogress","title":"API_QueryDocumentProgress","text":"<ul> <li>Added Document.ID column <pre><code>ALTER VIEW [dbo].[API_QueryDocumentProgress]\n    AS \nSELECT DISTINCT  \n         dbo.[Document].ID, dbo.[Document].Priority, dbo.[Document].ExpectedDate, dbo.[Document].Number, dbo.[Document].TradingPartnerCode AS TradingPartnerCode,dbo.[Document].TradingPartnerDescription AS TradingPartnerDescription, dbo.[Document].Description,dbo.[Document].ActionDate AS ActionDate, \n         TSQL.DateStart AS Started, TSQL.DateStop AS Stopped, DATEDIFF(MI, TSQL.DateStart, TSQL.DateStop) AS Duration, \n         TSQL3.Qty AS DocumentQty, \n         TSQL3.ActionQty AS ActionQty, ISNULL(TSQL3.ActionQty / CAST(CASE WHEN TSQL3.Qty = 0 THEN 1 ELSE TSQL3.Qty END AS DECIMAL(38, 3)) * 100, 0.1) AS Progress, \n         TSQL.[User] AS [User], \n         dbo.[Document].ERPLocation AS Location, dbo.[Document].Site, dbo.[Document].Status, dbo.[Document].Type\nFROM  dbo.[Document]  OUTER APPLY\n             (SELECT MIN(dbo.[Transaction].Date) AS DateStart, MAX(dbo.[Transaction].Date) AS DateStop, MAX(dbo.Users.Name) [USER]\n               FROM   dbo.[Transaction]  INNER JOIN\n               Users ON [Transaction].User_id = Users.ID\n               WHERE Document_id = dbo.[Document].ID) AS TSQL CROSS APPLY\n             (SELECT ISNULL(SUM(DocumentDetail.Qty), 0) as Qty, ISNULL(SUM(DocumentDetail.ActionQty), 0) as ActionQty\n                FROM DocumentDetail\n                WHERE Document_id = Document.ID) TSQL3\nWHERE (dbo.[Document].Status &lt;&gt; 'COMPLETE' OR AuditDate &gt; getdate() - 14)\n</code></pre></li> </ul>"},{"location":"database/release-notes/#changed-data_1","title":"Changed Data","text":""},{"location":"database/release-notes/#applicationgrids_1","title":"ApplicationGrids","text":"<ul> <li>Add ID column to all Document Progress grids</li> <li>Fix Document / PickslipDocument grid</li> <li>Fix ImportTrackingEntity</li> </ul>"},{"location":"database/release-notes/#enquiry-grids","title":"Enquiry Grids","text":"<ul> <li>Add StockAvailable grid</li> </ul>"},{"location":"database/release-notes/#systemsnippets","title":"SystemSnippets","text":"<ul> <li>Added snippets for all default Process templates</li> </ul>"},{"location":"database/release-notes/#accpaccintegration","title":"AccpaccIntegration","text":""},{"location":"database/release-notes/#changed-views_3","title":"Changed Views","text":""},{"location":"database/release-notes/#masteritemalias_view_1","title":"MasterItemAlias_View","text":"<ul> <li>Add columns<ul> <li>AuditDate</li> <li>AuditUser</li> <li>Version</li> <li>ERPIdentification</li> </ul> </li> <li>Add UNION to return results from MasterItemAlias table</li> </ul> <pre><code>ALTER VIEW [dbo].[MasterItemAlias_View]\n\n    AS \nSELECT ROW_NUMBER() OVER (ORDER BY [$(GraniteDatabase)].dbo.MasterItem.ID) AS ID, \nCAST([$(AccpacDatabase)].dbo.ICIOTH.MANITEMNO as varchar(16)) COLLATE SQL_Latin1_General_CP1_CI_AS AS Code, \nCAST([$(AccpacDatabase)].dbo.ICUNIT.UNIT as varchar(16)) COLLATE SQL_Latin1_General_CP1_CI_AS AS UOM, \n[$(AccpacDatabase)].dbo.ICUNIT.CONVERSION AS Conversion, CAST(1 as bit)as IsActive, \nGETDATE() as AuditDate, '' as AuditUser, \n[$(GraniteDatabase)].dbo.MasterItem.ID AS MasterItem_id,NULL as ERPIdentification,0 as Version\nFROM         [$(AccpacDatabase)].dbo.ICIOTH RIGHT OUTER JOIN\n                      [$(AccpacDatabase)].dbo.ICUNIT ON [$(AccpacDatabase)].dbo.ICIOTH.UNIT COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICUNIT.UNIT AND \n                      [$(AccpacDatabase)].dbo.ICIOTH.ITEMNO COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICUNIT.ITEMNO RIGHT OUTER JOIN\n                      [$(GraniteDatabase)].dbo.MasterItem RIGHT OUTER JOIN\n                      [$(AccpacDatabase)].dbo.ICITEM ON [$(GraniteDatabase)].dbo.MasterItem.Code COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICITEM.ITEMNO ON \n                      [$(AccpacDatabase)].dbo.ICUNIT.ITEMNO COLLATE SQL_Latin1_General_CP1_CI_AS = [$(AccpacDatabase)].dbo.ICITEM.ITEMNO\nWHERE     ([$(GraniteDatabase)].dbo.MasterItem.ID IS NOT NULL) AND ([$(AccpacDatabase)].dbo.ICIOTH.MANITEMNO IS NOT NULL)\nUNION\nSELECT  * FROM ([$(GraniteDatabase)].dbo.MasterItemAlias\n</code></pre>"},{"location":"database/release-notes/#changed-stored-procedures_1","title":"Changed Stored Procedures","text":""},{"location":"database/release-notes/#integrationprocesspurchaseorder","title":"IntegrationProcessPurchaseOrder","text":"<ul> <li>Map ExpectedArrivalDate to ExpectedDate instead of ActionDate</li> </ul>"},{"location":"database/release-notes/#integrationprocesssalesorder","title":"IntegrationProcessSalesOrder","text":"<ul> <li>Map ExpectedShipDate to ExpectedDate instead of ActionDate</li> </ul>"},{"location":"database/release-notes/#integrationprocesstransfer_1","title":"IntegrationProcessTransfer","text":"<ul> <li>Map ExpectedShipDate to ExpectedDate instead of ActionDate</li> </ul>"},{"location":"database/release-notes/#evolutionintegration","title":"EvolutionIntegration","text":""},{"location":"database/release-notes/#changed-views_4","title":"Changed Views","text":""},{"location":"database/release-notes/#masteritemalias_view_2","title":"MasterItemAlias_View","text":"<ul> <li>Add columns<ul> <li>AuditDate</li> <li>AuditUser</li> <li>Version</li> <li>ERPIdentification</li> </ul> </li> <li>Add UNION to return results from MasterItemAlias table</li> </ul> <pre><code>ALTER VIEW [dbo].[MasterItemAlias_View]\n    AS \nSELECT  ROW_NUMBER() OVER (ORDER BY [$(GraniteDatabase)].dbo.MasterItem.ID) AS ID,\n        [$(PastelEVODatabase)].dbo.StkItem.Code + [$(PastelEVODatabase)].dbo._etblUnits.cUnitCode AS Code, \n        [$(PastelEVODatabase)].dbo._etblUnits.cUnitCode AS UOM, \n        [$(PastelEVODatabase)].dbo._etblUnitConversion.fUnitBQty AS Conversion, 1 AS IsActive, \n        [$(GraniteDatabase)].dbo.MasterItem.ID as MasterItem_id,\n        GETDATE() as AuditDate, '' as AuditUser, 0 as Version, \n        NULL as ERPIdentification\nFROM         [$(PastelEVODatabase)].dbo._etblUnits INNER JOIN\n                      [$(PastelEVODatabase)].dbo._etblUnitConversion ON [$(PastelEVODatabase)].dbo._etblUnits.idUnits = [$(PastelEVODatabase)].dbo._etblUnitConversion.idUnitConversion INNER JOIN\n                      [$(PastelEVODatabase)].dbo.StkItem ON [$(PastelEVODatabase)].dbo._etblUnitConversion.idUnitConversion = [$(PastelEVODatabase)].dbo.StkItem.iUOMDefPurchaseUnitID INNER JOIN\n                      [$(GraniteDatabase)].dbo.MasterItem ON [$(PastelEVODatabase)].dbo.StkItem.Code = [$(GraniteDatabase)].dbo.MasterItem.Code COLLATE SQL_Latin1_General_CP1_CI_AS\nUNION\nSELECT  * FROM [$(GraniteDatabase)].dbo.MasterItemAlias\n</code></pre>"},{"location":"database/release-notes/#09-june-2023-4500","title":"09 June 2023 (4.5.0.0)","text":""},{"location":"database/release-notes/#granitedatabase_2","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#new-tables_1","title":"New tables","text":""},{"location":"database/release-notes/#datagrid","title":"DataGrid","text":"<pre><code>CREATE TABLE [dbo].[DataGrid]\n(\n    [ID] BIGINT NOT NULL PRIMARY KEY IDENTITY, \n    [Group] VARCHAR(50) NOT NULL, \n    [Name] VARCHAR(50) NOT NULL UNIQUE, \n    [SQLView] VARCHAR(100) NULL, \n    [GridDefinition] NVARCHAR(MAX) NOT NULL, \n    [UserGroup_id] BIGINT NULL, \n    [User_id] BIGINT NULL,\n    [AuditDate] DATETIME NULL, \n    [AuditUser] VARCHAR(20) NULL,\n    [Version] SMALLINT NULL, \n    [isApplicationGrid] BIT NULL, \n    [isCustomGrid] BIT NULL,\n)\n</code></pre>"},{"location":"database/release-notes/#systemstaticdata","title":"SystemStaticData","text":"<pre><code>CREATE TABLE [dbo].[SystemStaticData]\n(\n    [ID] BIGINT NOT NULL PRIMARY KEY IDENTITY, \n    [Group] VARCHAR(100) NULL,\n    [Key] VARCHAR(100) NOT NULL UNIQUE, \n    [Value] VARCHAR(MAX) NOT NULL, \n    [Description] VARCHAR(MAX) NULL, \n    [isEncrypted] BIT NOT NULL DEFAULT 0, \n    [AuditDate] DATETIME NULL, \n    [AuditUser] NCHAR(10) NULL, \n    [Version] SMALLINT NULL\n)\n</code></pre>"},{"location":"database/release-notes/#systemsnippets_1","title":"SystemSnippets","text":"<pre><code>CREATE TABLE [SystemSnippets]\n(\n    [ID] INT NOT NULL PRIMARY KEY IDENTITY, \n    [Name] VARCHAR(50) NOT NULL,\n    [Description] NVARCHAR(MAX) NOT NULL, \n    [Code] NVARCHAR(MAX) NOT NULL,\n    [CodeComment] NVARCHAR(MAX) NULL,\n    [Tags] VARCHAR(MAX) NULL,\n    [ProcessType] VARCHAR(30) NULL,\n)\n</code></pre>"},{"location":"database/release-notes/#auditstocktakelines","title":"AuditStockTakeLines","text":"<pre><code>CREATE TABLE [dbo].[AuditStockTakeLines]\n(\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [StockTakeSession_id] BIGINT NOT NULL, \n    [StockTakeLines_id] BIGINT NOT NULL, \n    [TrackingEntity_id] BIGINT NULL, \n    [MasterItem_id] BIGINT NULL, \n    [Barcode] VARCHAR(50) NULL, \n    [MasterItemCode] VARCHAR(40) NULL,\n    [Action] VARCHAR(10) NOT NULL,\n    [QtyColumn] VARCHAR(20) NULL, \n    [FromQty] decimal NULL, \n    [ToQty] decimal NULL,\n    [FromStatus]  VARCHAR(20) NULL,\n    [ToStatus]  VARCHAR(20) NULL,\n    [FromLocation]  VARCHAR(50) NULL,\n    [ToLocation]  VARCHAR(50) NULL,\n    [User] VARCHAR(20) NOT NULL, \n    [AuditDate] DATE NOT NULL,\n    [AuditTime] TIME NOT NULL, \n)\n</code></pre>"},{"location":"database/release-notes/#systemhelp","title":"SystemHelp","text":"<pre><code>CREATE TABLE [dbo].[SystemHelp]\n(\n    [ID] [bigint] IDENTITY(1,1) NOT NULL,\n    [Title] VARCHAR(255) NULL, \n    [Content] VARCHAR(MAX) NULL,\n    [Component] VARCHAR(255) NULL\n)\n</code></pre>"},{"location":"database/release-notes/#table-changes","title":"Table Changes","text":""},{"location":"database/release-notes/#userscredential","title":"UsersCredential","text":"<p>Columns PasswordExpiration and FailedLoginAttempts added</p> <pre><code>    ALTER TABLE [UsersCredential]\n    ADD [PasswordExpiration] DATETIME NULL, \n        [FailedLoginAttempts] BIT NULL\n</code></pre>"},{"location":"database/release-notes/#document","title":"Document","text":"<p>Columns Route and Stop have been renamed to RouteName and StopName respectively</p> <pre><code>    ALTER TABLE Document\n    ADD [RouteName] VARCHAR(50) NULL,\n        [StopName] VARCHAR(50) NULL\n</code></pre>"},{"location":"database/release-notes/#process_1","title":"Process","text":"<pre><code>    ALTER TABLE [Process]\n    ADD [WebTemplate] VARCHAR(MAX) NULL\n</code></pre>"},{"location":"database/release-notes/#processstep_1","title":"ProcessStep","text":"<pre><code>    ALTER TABLE [ProcessStep]\n    ADD [WebTemplate] VARCHAR(MAX) NULL\n</code></pre>"},{"location":"database/release-notes/#users_2","title":"Users","text":"<p>Added new permissions</p> <pre><code>    ALTER TABLE [Users]\n    ADD [AllowSystemStaticData] BIT NULL DEFAULT 0,\n        [AllowManufactureDocument] BIT NOT NULL, \n        [AllowPickReversal] BIT NOT NULL, \n        [AllowReceiveReversal] BIT NOT NULL, \n        [AllowTransferReversal] BIT NOT NULL, \n        [AllowInventoryVariances] BIT NOT NULL,\n        [AllowReceivingProgress] BIT NOT NULL,\n        [AllowPickingProgress] BIT NOT NULL,\n        [AllowPickSlip] BIT NOT NULL,\n        [AllowTransferProgress] BIT NOT NULL,\n        [AllowManufactureProgress] BIT NOT NULL\n</code></pre>"},{"location":"database/release-notes/#usergroup","title":"UserGroup","text":"<pre><code>    ALTER TABLE [UserGroup]\n    ALTER COLUMN [Name] NOT NULL UNIQUE\n</code></pre>"},{"location":"database/release-notes/#audit","title":"Audit","text":"<p>Column NewValue now allows nulls <pre><code>    ALTER TABLE [Audit]\n    ALTER COLUMN [NewValue] VARCHAR(MAX) NULL\n</code></pre></p>"},{"location":"database/release-notes/#systemsettings_3","title":"SystemSettings","text":"<p>Add Version column</p> <pre><code>    ALTER TABLE\n    ADD [Version] SMALLINT NULL\n</code></pre>"},{"location":"database/release-notes/#deprecated-tables","title":"Deprecated Tables","text":"<ul> <li>ApplicationLog</li> <li>Emails</li> <li>Reports</li> <li>StockTakeLine</li> <li>StockTakeScanned</li> </ul>"},{"location":"database/release-notes/#new-views_2","title":"New Views","text":""},{"location":"database/release-notes/#api_querystocktakeprocesssummary","title":"API_QueryStockTakeProcessSummary","text":"<pre><code>CREATE VIEW [dbo].[API_QueryStockTakeProcessSummary] as\nSELECT dbo.StockTakeSession.[Name] AS [Session], dbo.MasterItem.Code,dbo. MasterItem.[Description], dbo.MasterItem.Category AS ItemCategory, dbo.MasterItem.[Type] AS ItemType, \n    SUM(OpeningQty) AS OpeningQty,\n    COUNT(StockTakeLines.TrackingEntity_id) AS Total, \n    SUM(CASE WHEN [Status] = 'OUTSTANDING' AND ISNULL(Scrap, 0) = 0 THEN OpeningQty ELSE 0 END) OutstandingQty,\n    SUM(CASE WHEN [Status] = 'COUNTED' AND ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.Count1Qty ELSE 0 END) AS Count1Qty,  \n    SUM(CASE WHEN [Status] = 'COUNTED' AND ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.Count2Qty ELSE 0 END) AS Count2Qty, \n    SUM(CASE WHEN [Status] = 'COUNTED' AND ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.Count3Qty ELSE 0 END) AS Count3Qty, \n    SUM(CASE WHEN [Status] = 'APPROVED' AND ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.ApprovedQty ELSE 0 END) AS ApprovedQty,\n    ISNULL(dbo.ERP_StockOnHand.QTYONHAND, 0) ERPQty\nFROM dbo.StockTakeSession INNER JOIN\n    dbo.StockTakeLines ON dbo.StockTakeSession.ID = dbo.StockTakeLines.StockTakeSession_id INNER JOIN\n    dbo.MasterItem ON dbo.StockTakeLines.MasterItem_id = dbo.MasterItem.ID INNER JOIN\n    dbo.TrackingEntity ON dbo.StockTakeLines.TrackingEntity_id = dbo.TrackingEntity.ID LEFT OUTER JOIN\n    dbo.ERP_StockOnHand ON dbo.MasterItem.Code = dbo.ERP_StockOnHand.ITEMNO\nGROUP BY dbo.StockTakeSession.[Name], dbo.MasterItem.Code, dbo.MasterItem.[Description], dbo.MasterItem.Category, dbo.MasterItem.[Type],  dbo.ERP_StockOnHand.QTYONHAND\n</code></pre>"},{"location":"database/release-notes/#changed-views_5","title":"Changed Views","text":""},{"location":"database/release-notes/#api_querypicksliplines","title":"API_QueryPickslipLines","text":"<p>Remove dependency on deprecated view Base_Inventory_Summary <pre><code>ALTER VIEW [dbo].[API_QueryPickslipLines]\n    AS \nSELECT  dbo.[Document].ID, dbo.DocumentDetail.ID AS DocumentDetailID, dbo.[Document].Number, Document_1.Number AS SalesOrder, \n        Document_1.TradingPartnerCode, Document_1.TradingPartnerDescription, dbo.MasterItem.Code, dbo.MasterItem.Description, \n        dbo.DocumentDetail.Qty AS PickSlipQty, DocumentDetail_1.Qty AS OrderQty, ISNULL(dbo.DocumentDetail.ActionQty, 0) AS PickedQty, \n        stock.QtyOnHand AS QtyOnHand, Document_1.ID AS SalesOrderID, dbo.MasterItem.ID AS MasterItemID, \n        dbo.DocumentDetail.LineNumber, DocumentDetail_1.LineNumber AS SalesOrderLine, dbo.DocumentDetail.Comment, dbo.DocumentDetail.Instruction, \n        dbo.DocumentDetail.Cancelled, dbo.DocumentDetail.Completed, dbo.DocumentDetail.UOM, dbo.DocumentDetail.Batch, dbo.DocumentDetail.ExpiryDate, \n        dbo.DocumentDetail.SerialNumber\nFROM  dbo.[Document] INNER JOIN\n         dbo.DocumentDetail ON dbo.[Document].ID = dbo.DocumentDetail.Document_id INNER JOIN\n         dbo.Type ON dbo.[Document].Type = dbo.Type.Name INNER JOIN\n         dbo.DocumentDetail AS DocumentDetail_1 ON dbo.DocumentDetail.LinkedDetail_id = DocumentDetail_1.ID INNER JOIN\n         dbo.[Document] AS Document_1 ON DocumentDetail_1.Document_id = Document_1.ID INNER JOIN\n         dbo.MasterItem ON dbo.DocumentDetail.Item_id = dbo.MasterItem.ID INNER JOIN\n         dbo.Status ON dbo.[Document].Status = dbo.Status.Name OUTER APPLY\n         (\n            SELECT ISNULL(SUM(Qty), 0) AS QtyOnHand\n            FROM TrackingEntity INNER JOIN\n            [Location] ON TrackingEntity.Location_id = [Location].ID\n            WHERE TrackingEntity.MasterItem_id = DocumentDetail.Item_id AND TrackingEntity.InStock = 1 AND ISNULL([Location].NonStock, 0) = 0\n         ) stock\nWHERE (dbo.Type.Name = 'PICKSLIP') AND (dbo.Status.Name &lt;&gt; 'COMPLETE')\nGO\n</code></pre></p>"},{"location":"database/release-notes/#api_querystockreplenish","title":"API_QueryStockReplenish","text":"<p>Remove dependency on deprecated view Base_Inventory_Summary <pre><code>CREATE VIEW [dbo].API_QueryStockReplenish\nAS\nSELECT Code, [Description], [Location].[Name] AS PickFaceLocation, stock.LocationQty, MasterItem.MinimumPickfaceQuantity AS MininmumQty, \nMasterItem.OptimalPickfaceQuantity AS OptimalQty, OptimalPickfaceQuantity - LocationQty AS ReplenishQty\nFROM dbo.MasterItem INNER JOIN\ndbo.[Location] ON MasterItem.PickfaceLocation_id = [Location].ID OUTER APPLY\n(\n    SELECT ISNULL(SUM(Qty), 0) AS LocationQty\n    FROM dbo.TrackingEntity \n    WHERE InStock = 1 AND TrackingEntity.Location_id = [Location].ID AND TrackingEntity.MasterItem_id = MasterItem.ID\n) stock\nWHERE OptimalPickfaceQuantity &gt; 0\nGO\n</code></pre></p>"},{"location":"database/release-notes/#api_querystocktakelinessummary","title":"API_QueryStockTakeLinesSummary","text":"<p>Added collation to join on ERP_StockOnHand view <pre><code>ALTER VIEW [dbo].[API_QueryStockTakeLinesSummary]\nAS\nSELECT dbo.MasterItem.Code, dbo.MasterItem.Description, dbo.MasterItem.Category AS ItemCategory, dbo.MasterItem.Type AS ItemType, dbo.StockTakeLines.OpeningLocationERP,\nSUM(dbo.StockTakeLines.OpeningQty) AS OpeningQty, dbo.StockTakeLines.Status, dbo.StockTakeSession.Name AS Session, \nCOUNT(dbo.TrackingEntity.ID) AS Total, \nSUM(CASE WHEN ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.TrackingEntity.Qty ELSE 0 END) AS SessionQty, \nSUM(CASE WHEN ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.Count1Qty ELSE 0 END) AS Count1Qty,  \nSUM(CASE WHEN ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.Count2Qty ELSE 0 END) AS Count2Qty, \nSUM(CASE WHEN ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.Count3Qty ELSE 0 END) AS Count3Qty, \nSUM(CASE WHEN ISNULL(dbo.StockTakeLines.Scrap, 0) = 0 THEN dbo.StockTakeLines.ApprovedQty ELSE 0 END) AS ApprovedQty,  \nERP_StockOnHand.QTYONHAND AS ERPQty\nFROM  dbo.TrackingEntity INNER JOIN\n         dbo.StockTakeLines ON dbo.TrackingEntity.ID = dbo.StockTakeLines.TrackingEntity_id INNER JOIN\n         dbo.StockTakeSession ON dbo.StockTakeLines.StockTakeSession_id = dbo.StockTakeSession.ID INNER JOIN\n         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID LEFT OUTER JOIN\n         ERP_StockOnHand ON MasterItem.FormattedCode = ERP_StockOnHand.ITEMNO COLLATE DATABASE_DEFAULT AND StockTakeLines.OpeningLocationERP = ERP_StockOnHand.[LOCATION] COLLATE DATABASE_DEFAULT\nGROUP BY dbo.MasterItem.Code, dbo.MasterItem.Description, dbo.StockTakeLines.Status, dbo.StockTakeSession.Name, dbo.MasterItem.Category, dbo.MasterItem.Type, dbo.StockTakeLines.OpeningLocationERP, ERP_StockOnHand.QTYONHAND\nGO\n</code></pre></p>"},{"location":"database/release-notes/#api_querystockdetail","title":"API_QueryStockDetail","text":"<p>Split CreateDate (datetime) to CreateDate (date) and Time (Time(0))</p> <pre><code>ALTER VIEW [dbo].[API_QueryStockDetail]\nAS\nSELECT dbo.TrackingEntity.Barcode, dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.Qty, dbo.MasterItem.ID AS MasterItem_id, dbo.MasterItem.Code AS Code, dbo.MasterItem.Description AS Description, dbo.Location.Name AS Location, dbo.Location.Site, dbo.TrackingEntity.Batch, dbo.TrackingEntity.ExpiryDate, NULL AS OnHoldDate, CAST(dbo.[TrackingEntity].CreatedDate AS Date) as CreatedDate, CAST(dbo.[TrackingEntity].CreatedDate AS Time(0)) as Time, dbo.CarryingEntity.Barcode AS Pallet, dbo.TrackingEntity.OnHold, dbo.TrackingEntity.StockTake,\ndbo.MasterItem.Category as ItemCategory, dbo.MasterItem.[Type] as ItemType, dbo.Location.Category as LocationCategory, dbo.Location.[Type] as LocationType \nFROM  dbo.TrackingEntity INNER JOIN\n         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID INNER JOIN\n         dbo.Location ON dbo.TrackingEntity.Location_id = dbo.Location.ID LEFT OUTER JOIN\n         dbo.CarryingEntity ON dbo.TrackingEntity.BelongsToEntity_id = dbo.CarryingEntity.ID\nWHERE (dbo.TrackingEntity.InStock = 1) AND (dbo.Location.NonStock = 0)\nGO\n</code></pre>"},{"location":"database/release-notes/#api_querytransactions","title":"API_QueryTransactions","text":"<p>Split column Date (datetime) into columns Date (date) and Time (Time(0))</p> <pre><code>ALTER VIEW [dbo].[API_QueryTransactions]\nAS\nSELECT dbo.[Transaction].ID, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, dbo.[Transaction].ActionQty, dbo.[Transaction].UOM, dbo.[Transaction].Comment, dbo.[Transaction].IntegrationDate, dbo.[Transaction].Process, dbo.Users.Name AS [User], \n         dbo.[Transaction].DocumentReference, dbo.[Document].Number AS Document, dbo.[Transaction].IntegrationStatus, dbo.CarryingEntity.Barcode AS Pallet, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, dbo.[Transaction].Type, dbo.[Transaction].IntegrationReference, dbo.DocumentDetail.LineNumber, TrackingEntity_1.Barcode AS FromBarcode,\n         CONVERT(Date, dbo.[Transaction].Date, 101) AS TransactionDate, SUBSTRING(CONVERT(varchar(20), dbo.[Transaction].Date), 12, 10) AS TransactionTime\nFROM  dbo.[Transaction] LEFT OUTER JOIN\n         dbo.DocumentDetail ON dbo.[Transaction].DocumentLine_id = dbo.DocumentDetail.ID AND dbo.[Transaction].Document_id = dbo.DocumentDetail.Document_id LEFT OUTER JOIN\n         dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id LEFT OUTER JOIN\n         dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n         dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n         dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n         dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID INNER JOIN\n         dbo.TrackingEntity ON dbo.[Transaction].TrackingEntity_id = dbo.TrackingEntity.ID LEFT OUTER JOIN\n         dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID INNER JOIN\n         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID LEFT OUTER JOIN\n         dbo.TrackingEntity AS TrackingEntity_1 ON dbo.[Transaction].FromTrackingEntity_id = TrackingEntity_1.ID\nGO\n</code></pre>"},{"location":"database/release-notes/#api_querytransactionsmanufacture","title":"API_QueryTransactionsManufacture","text":"<p>Split column Date (datetime) into columns Date (date) and Time (Time(0))</p> <pre><code>ALTER VIEW [dbo].[API_QueryTransactionsManufacture]\nAS\nSELECT dbo.[Transaction].ID, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, \n                  dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, dbo.[Transaction].ActionQty, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS Document, dbo.[Transaction].IntegrationStatus, \n                  dbo.CarryingEntity.Barcode AS Pallet, dbo.[Transaction].Comment, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, dbo.[Transaction].Type AS Type, dbo.[Transaction].IntegrationReference\nFROM     dbo.[Transaction] LEFT OUTER JOIN\n                  dbo.TrackingEntity ON dbo.TrackingEntity.ID = dbo.[Transaction].TrackingEntity_id LEFT OUTER JOIN\n                  dbo.MasterItem ON dbo.MasterItem.ID = dbo.TrackingEntity.MasterItem_id LEFT OUTER JOIN\n                  dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n                  dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n                  dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n                  dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID LEFT OUTER JOIN\n                  dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID LEFT OUTER JOIN\n                  dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id\n                  WHERE dbo.[Transaction].Type = 'CONSUME' OR dbo.[Transaction].Type = 'MANUFACTURE'\nGO\n</code></pre>"},{"location":"database/release-notes/#api_querytransactionspickreversal_1","title":"API_QueryTransactionsPickReversal","text":"<p>Split column Date (datetime) into columns Date (date) and Time (Time(0))</p> <pre><code>ALTER VIEW [dbo].[API_QueryTransactionsPickReversal]\nAS\nSELECT dbo.[Transaction].ID, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, dbo.[Transaction].ActionQty, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS [Document], dbo.[Transaction].IntegrationStatus, \n         dbo.CarryingEntity.Barcode AS Pallet, dbo.[Transaction].Comment, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, dbo.[Transaction].Type, dbo.[Transaction].IntegrationReference, dbo.[Transaction].ReversalTransaction_id, dbo.[Document].TradingPartnerCode, dbo.[Document].TradingPartnerDescription, dbo.[Document].Status, dbo.DocumentDetail.LineNumber\nFROM  dbo.[Transaction] INNER JOIN\n         dbo.DocumentDetail ON dbo.[Transaction].DocumentLine_id = dbo.DocumentDetail.ID LEFT OUTER JOIN\n         dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id LEFT OUTER JOIN\n         dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n         dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n         dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n         dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID FULL OUTER JOIN\n         dbo.TrackingEntity LEFT OUTER JOIN\n         dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID ON dbo.TrackingEntity.ID = dbo.[Transaction].TrackingEntity_id FULL OUTER JOIN\n         dbo.MasterItem ON dbo.TrackingEntity.MasterItem_id = dbo.MasterItem.ID\nWHERE (dbo.[Transaction].Type = 'PICK') AND ISNULL(dbo.[Transaction].ReversalTransaction_id, 0) = 0 AND ISNULL(dbo.[Transaction].IntegrationStatus, 0) = 0\nGO\n</code></pre>"},{"location":"database/release-notes/#api_querytransactionspicking","title":"API_QueryTransactionsPicking","text":"<p>Split column Date (datetime) into columns Date (date) and Time (Time(0))</p> <pre><code>CREATE VIEW [dbo].[API_QueryTransactionsPicking]\nAS\nSELECT dbo.[Transaction].ID, dbo.[Transaction].ReversalTransaction_id, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, \n                    dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, \n                    dbo.[Transaction].ActionQty, dbo.[Transaction].UOM, dbo.[Transaction].Comment, dbo.[Transaction].IntegrationDate,\n                    dbo.[Transaction].Process, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS Document, dbo.[Transaction].IntegrationStatus, \n                    dbo.CarryingEntity.Barcode AS Pallet, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, \n                    dbo.[Transaction].Type AS Type, dbo.[Transaction].IntegrationReference\nFROM     dbo.[Transaction] LEFT OUTER JOIN\n                    dbo.TrackingEntity ON dbo.TrackingEntity.ID = dbo.[Transaction].TrackingEntity_id LEFT OUTER JOIN\n                    dbo.MasterItem ON dbo.MasterItem.ID = dbo.TrackingEntity.MasterItem_id LEFT OUTER JOIN\n                    dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n                    dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n                    dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n                    dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID LEFT OUTER JOIN\n                    dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID LEFT OUTER JOIN\n                    dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id\nWHERE dbo.[Transaction].Type = 'PICK' OR dbo.[Transaction].Type = 'DYNAMICPICK'\nGO\n</code></pre>"},{"location":"database/release-notes/#api_querytransactionsreceiving","title":"API_QueryTransactionsReceiving","text":"<p>Split column Date (datetime) into columns Date (date) and Time (Time(0))</p> <pre><code>CREATE VIEW [dbo].[API_QueryTransactionsReceiving]\nAS\nSELECT dbo.[Transaction].ID, dbo.[Transaction].ReversalTransaction_id, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, \n                    dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, \n                    dbo.[Transaction].ActionQty, dbo.[Transaction].UOM, dbo.[Transaction].Comment, dbo.[Transaction].IntegrationDate,\n                    dbo.[Transaction].Process, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS Document, dbo.[Transaction].IntegrationStatus, \n                    dbo.CarryingEntity.Barcode AS Pallet, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, \n                    dbo.[Transaction].Type AS Type, dbo.[Transaction].IntegrationReference\nFROM     dbo.[Transaction] LEFT OUTER JOIN\n                    dbo.TrackingEntity ON dbo.TrackingEntity.ID = dbo.[Transaction].TrackingEntity_id LEFT OUTER JOIN\n                    dbo.MasterItem ON dbo.MasterItem.ID = dbo.TrackingEntity.MasterItem_id LEFT OUTER JOIN\n                    dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n                    dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n                    dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n                    dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID LEFT OUTER JOIN\n                    dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID LEFT OUTER JOIN\n                    dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id\nWHERE dbo.[Transaction].Type = 'RECEIVE'\nGO\n</code></pre>"},{"location":"database/release-notes/#api_querytransactionstransfer","title":"API_QueryTransactionsTransfer","text":"<p>Split column Date (datetime) into columns Date (date) and Time (Time(0))</p> <pre><code>CREATE VIEW [dbo].[API_QueryTransactionsTransfer]\nAS\nSELECT dbo.[Transaction].ID, dbo.[Transaction].ReversalTransaction_id, dbo.TrackingEntity.Barcode, dbo.MasterItem.Code, dbo.MasterItem.Description, CAST(dbo.[Transaction].Date AS Date) as Date, CAST(dbo.[Transaction].Date AS Time(0)) as Time, dbo.TrackingEntity.Batch, \n                    dbo.TrackingEntity.SerialNumber, dbo.TrackingEntity.ExpiryDate, dbo.[Transaction].FromQty, dbo.[Transaction].ToQty, \n                    dbo.[Transaction].ActionQty, dbo.[Transaction].UOM, dbo.[Transaction].Comment, dbo.[Transaction].IntegrationDate,\n                    dbo.[Transaction].Process, dbo.Users.Name AS [User], dbo.[Transaction].DocumentReference, dbo.[Document].Number AS Document, dbo.[Transaction].IntegrationStatus, \n                    dbo.CarryingEntity.Barcode AS Pallet, L1.Name AS FromLocation, L2.Name AS ToLocation, L3.Site, \n                    dbo.[Transaction].Type AS Type, dbo.[Transaction].IntegrationReference\nFROM     dbo.[Transaction] LEFT OUTER JOIN\n                    dbo.TrackingEntity ON dbo.TrackingEntity.ID = dbo.[Transaction].TrackingEntity_id LEFT OUTER JOIN\n                    dbo.MasterItem ON dbo.MasterItem.ID = dbo.TrackingEntity.MasterItem_id LEFT OUTER JOIN\n                    dbo.CarryingEntity ON dbo.[Transaction].ContainableEntity_id = dbo.CarryingEntity.ID LEFT OUTER JOIN\n                    dbo.Location AS L1 ON dbo.[Transaction].FromLocation_id = L1.ID LEFT OUTER JOIN\n                    dbo.Location AS L2 ON dbo.[Transaction].ToLocation_id = L2.ID LEFT OUTER JOIN\n                    dbo.Location AS L3 ON dbo.TrackingEntity.Location_id = L3.ID LEFT OUTER JOIN\n                    dbo.Users ON dbo.[Transaction].User_id = dbo.Users.ID LEFT OUTER JOIN\n                    dbo.[Document] ON dbo.[Document].ID = dbo.[Transaction].Document_id\nWHERE dbo.[Transaction].Type = 'TRANSFER' OR dbo.[Transaction].Type = 'DYNAMICTRANSFER'\nGO\n</code></pre>"},{"location":"database/release-notes/#deprecated-views","title":"Deprecated Views","text":"<ul> <li>App_DocumentDetail</li> <li>App_Documentdetail_Pickslips</li> <li>App_DocumentHeader</li> <li>App_Integration_Transactions</li> <li>App_Inventory_ByLocation</li> <li>App_Inventory_Instock</li> <li>App_Inventory_Pallets</li> <li>App_Inventory_QCHold</li> <li>App_Inventory_StockTake</li> <li>App_MasterFiles_Locations</li> <li>App_MasterFiles_MasterItems</li> <li>App_Outbound_Packing</li> <li>App_Outbound_PickSlips</li> <li>App_StockTake_Approved</li> <li>App_StockTake_PostingTotals</li> <li>App_StockTake_Processed</li> <li>App_StockTake_Scanned</li> <li>App_StockTake_ScannedSummary</li> <li>App_StockTake_Unscanned</li> <li>App_TrackingEntity</li> <li>App_Transactions_Location</li> <li>App_Warning_InventoryVariance</li> <li>App_Warning_Picking</li> <li>App_Warning_Receiving</li> <li>App_Warning_StockExpiry</li> <li>Base_App_Comparison</li> <li>Base_App_ExecutionProgress</li> <li>Base_App_TransactionPerUser</li> <li>Base_Inventory_Summary</li> <li>Base_Inventory_Summary_Location</li> <li>Base_Report_Inventory_Expiry</li> <li>Base_Stocktake</li> <li>Report_App_Transactions</li> <li>Report_App_Warning_StockReorder</li> <li>Report_App_Warning_StockToReplenish</li> <li>Report_Inbound_ReceivePerUser</li> <li>Report_Inbound_Receiving</li> <li>Report_Inventory_Adjustments</li> <li>Report_Inventory_Moves</li> <li>Report_Inventory_OnhandDetail</li> <li>Report_Inventory_OnhandSummary</li> <li>Report_Inventory_OnHandSummary_ForBufferStock</li> <li>Report_Inventory_OnholdDetail</li> <li>Report_Inventory_Reclassify</li> <li>Report_Inventory_ReplenishHistory</li> <li>Report_Inventory_Returns</li> <li>Report_Inventory_Scrapped</li> <li>Report_Inventory_Transfer</li> <li>Report_Outbound_Picking</li> <li>Report_Outbound_PicksPerUser</li> <li>Report_StockTake_Variance</li> <li>Report_Transactions_ActivityCost</li> </ul>"},{"location":"database/release-notes/#other","title":"Other","text":""},{"location":"database/release-notes/#misc-folder-renamed-to-tooling","title":"Misc folder renamed to Tooling","text":""},{"location":"database/release-notes/#moved-views-to-new-folders","title":"Moved views to new folders","text":"<ul> <li> <p>Views\\Labels folder</p> <ul> <li>Label_Box</li> <li>Label_Location</li> <li>Label_MasterItem</li> <li>Label_Pallet</li> <li>Label_TrackingEntity</li> <li>Label_Users</li> </ul> </li> <li> <p>Views\\Integration folder</p> <ul> <li>Integration_Transactions</li> <li>Integration_TransactionsComplete</li> </ul> </li> </ul>"},{"location":"database/release-notes/#moved-scripts-to-new-folders","title":"Moved scripts to new folders","text":"<ul> <li>Data\\ScheduledJobs folder<ul> <li>ScheduledJobs.sql</li> </ul> </li> <li>Data\\SystemSettings folder<ul> <li>SystemSettings.sql</li> <li>SystemSettingsAccpac.sql</li> <li>SystemSettingsEvolution.sql</li> <li>SystemSettingsProcessApp.sql</li> <li>SystemSettingsSAP.sql</li> <li>SystemSettingsScheduler.sql</li> </ul> </li> <li>Data\\Users folder<ul> <li>UserGroups.sql</li> <li>Users.sql</li> </ul> </li> </ul>"},{"location":"database/release-notes/#default-processes-moved-to-subfolder","title":"Default processes moved to subfolder","text":"<ul> <li>Process* moved to Process\\Default</li> </ul>"},{"location":"database/release-notes/#removed-unused-scripts","title":"Removed unused scripts","text":"<ul> <li>Customers*</li> <li>DataDemo*</li> <li>Reporting*</li> </ul>"},{"location":"database/release-notes/#postdeployscript","title":"PostDeployScript","text":"<ul> <li>Add .\\Data\\UserCredentials.sql</li> <li>Granite user creation updated to check if user exists before creating</li> </ul>"},{"location":"database/release-notes/#scriptinputparameters","title":"ScriptInputParameters","text":"<p>Value field changed to nvarchar(max) <pre><code>CREATE TYPE dbo.ScriptInputParameters AS TABLE\n(\n   Name NVARCHAR(50) NOT NULL,\n   Value  NVARCHAR(MAX)\n)\n</code></pre></p>"},{"location":"database/release-notes/#grids-data","title":"Grids data","text":"<ul> <li>Add ApplicationGrids.sql</li> <li>Add EnquiryGrids.sql</li> </ul>"},{"location":"database/release-notes/#systemsettings-data","title":"SystemSettings data","text":"<ul> <li>Change DatabaseVersion     <pre><code>    INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\n    VALUES    ('Granite', 'DatabaseVersion', '4.5.0.0', 'Granite Database version', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></li> <li>Add GraniteScheduler TimeZone and EmailAddress settings     <pre><code>    INSERT [dbo].[SystemSettings] ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser])\n    VALUES    ('GraniteScheduler', 'TimeZone', '', 'The time zone that will be used when scheduling CRON jobs', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n              ('GraniteScheduler', 'Username', '', 'The username that will be used to connect to the SMTP server (usually the same as the EmailAddress)', 'string', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></li> <li>Add settings to SystemSettingsAccpac.sql     <pre><code>    INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\n    VALUES ('IntegrationSage300', 'RoundSummarizedActionQty', 'true', 'Round summed ActionQty when posting transfers and moves', 0, 1, GETDATE(), 'AUTOMATION')\n\n    INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\n    VALUES ('IntegrationSage300', 'RoundSummarizedActionQtyToDecimalPlaces', '2', 'Number of decimal places to round ActionQty to', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></li> <li>Add Syspro settings     <pre><code>    INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\n    VALUES \n    ('IntegrationSyspro', 'SysproWriteXML', 'false', 'If true, logs XML that would be posted to C drive instead of posting to Syspro', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'Operator', '', 'Syspro Operator name', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'OperatorPassword', '', 'Syspro Operator password', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'CompanyId', '', 'Syspro CompanyID', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'CompanyPassword', '', 'Syspro Company password', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'SalesOrderPosting', 'SORTBO', 'Syspro business object to use for SalesOrder posting (SORTBO or SORTOS or ALL)', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'TransferPosting', 'GIT', 'Syspro integration method for Transfers (GIT or INVT)', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'Instance', '', 'Syspro Instance to use (empty for default)', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'MultipleBins', 'false', 'true or false. Set to true when Syspro has multiple bins enabled', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationSyspro', 'SerialNumbers', 'false', 'true or false. Set to true when Syspro has SerialNumbers enabled', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></li> <li>Add Omni settings     <pre><code>    INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\n    VALUES  \n    ('IntegrationOmni', 'Host', '', 'Servername or IP of the server where the API is hosted', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'Port', '', 'Port number that the Omni API is running on', 1, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'UserName', '', 'Omni user name that is used to transact via the API', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'Password', '', 'Password for the Omni user', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'CompanyName', '', 'Omni company name to post to', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'AdjustmentAccount', '', 'Account that adjustments will post to', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'ScrapAccount', '', 'Account that scrap transcations will post to', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'IntransitWarehouse', '', 'The intransit warehouse that will be used', 0, 1, GETDATE(), 'AUTOMATION'),\n    ('IntegrationOmni', 'PostDynamicTransferReceipt', 'false', 'true or false. Determines whether Omni transfer is auto posted for Granite DynamicTransfers', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></li> <li>Add SystemSettingsSQLCLR.sql     <pre><code>    INSERT [dbo].[SystemSettings] ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser])\n    VALUES  ('SQLCLR', 'Webservice', '', 'Granite Webservice Address', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n            ('SQLCLR', 'LabelPrintService', '', 'Label Print Service Address', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n            ('SQLCLR', 'IntegrationService', '', 'Integration Service Address', 'string', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></li> <li> <p>Application value changed from INTEGRATIONSERVICE to provider specific names:</p> <ul> <li>IntegrationSage300</li> <li>IntegrationSage200</li> <li>IntegrationSAPB1</li> </ul> </li> <li> <p>Changed casing on Application name for SystemSettingsScheduler.sql</p> <ul> <li>GRANITESCHEDULER -&gt; GraniteScheduler</li> </ul> </li> <li> <p>Changed casing on Application name for SystemSettingsProcessApp.sql</p> <ul> <li>PROCESSAPP -&gt; ProcessApp</li> </ul> </li> </ul>"},{"location":"database/release-notes/#systemsnippets-data","title":"SystemSnippets data","text":"<p>Add default snippets data to SystemSnippets table <pre><code>INSERT INTO SystemSnippets ([Name], [Description], [Code], [Tag0])\nVALUES \n('Basic Table','Basic html table.','{{ ''SELECT * FROM _replace_'' | dbSelect() | basicTable() }}', 'TABLE'),\n('Basic Table / Search','Table with search textbox.','{{ ''SELECT * FROM _replace_'' | dbSelect({}) | basicTable({enableSearch:true}) }}', 'TABLE'),\n('Basic Table / Search and Select','Table with search and select on column.','{{ ''SELECT * FROM _replace_'' | dbSelect({}) | basicTable({selectOnColumn:''_replace_'', enableSearch:true}) }}', 'TABLE'),\n('Basic List','Basic List', '{{ ''SELECT * FROM _replace_'' | dbSelect() | basicList() }}', 'LIST'),\n('Basic List / Search','List with search textbox', '{{ ''SELECT * FROM _replace_'' | dbSelect() | basicList({enableSearch:true}) }}', 'LIST'),\n('Label with Value','Label with step value', '&lt;div&gt;&lt;small&gt;_replace_&lt;/small&gt;&lt;header class=''gn-float-right''&gt;{{_replace_}}&lt;/header&gt;&lt;/div&gt;', 'LABEL'),\n('SQL select parameter','SQL select with parameter.', '{{ ''SELECT * FROM _replace_view_ WHERE _replace_col_ = @_replace_value_'' | dbSelect({_replace_step_}) |&gt; to =&gt; rows }}', 'SQL'),\n('SQL select single value','SQL select single value to variable', '{{ ''SELECT _replace_col_ FROM _replace_view_ WHERE _replace_col_ = @_replace_value_'' | dbScalar({_replace_step_}) |&gt; to =&gt; _replace_variable_ }}', 'SQL'),\n('SQL select single row','SQL select single row to variable', '{{ ''SELECT * FROM _replace_view_ WHERE _replace_col_ = @_replace_value_'' | dbSingle({_replace_step_}) |&gt; to =&gt; row }}', 'SQL'),\n('Hide New button','Hide New button on CarryingEntity step', '&lt;style&gt; #btnNew { display:none } &lt;/style&gt;', 'HIDE')\n</code></pre></p>"},{"location":"database/release-notes/#usercredentials-data","title":"UserCredentials data","text":"<p>Add default user to UsersCredential table <pre><code>INSERT INTO UsersCredential (Users_id, Password, Salt, PasswordStrength, Version, AuditDate, AuditUser)\nSELECT ID as User_id, \n'Pm7fzVwBm+rMN5+hTRDFQPicjE5JYU8TpZq7lQS8CYMCqsP0QefTlBk96q0EucwyXuLWwe25y+IuqPXe/NPUBg==', \n'bNbQLUjOj041iKexoJV9fCvSANYohJPchw6QOrBzzwGol6Xwydm44BsIABBMYlEA',\n'VeryWeak',\n1,\nGETDATE(),\n'AUTOMATION'\nFROM Users WHERE Name = '0'\n</code></pre></p>"},{"location":"database/release-notes/#pastel-evo-integration","title":"Pastel EVO Integration","text":""},{"location":"database/release-notes/#scheduledjobs-views","title":"ScheduledJobs Views","text":"<p>Removed: - Integration_Evolution_SalesOrderTradingPartner - Integration_Evolution_PurchaseOrderTradingPartner Added: - Integration_Evolution_TradingPartner Updated: - Integration_Evolution_ReceiptDetail - Integration_Evolution_ReceiptHeader - Integration_Evolution_IntransitDetail - Integration_Evolution_IntransitHeader - Integration_Evolution_MasterItem - Integration_Evolution_MasterItem_V7 - Integration_Evolution_PurchaseOrderDetail - Integration_Evolution_PurchaseOrderDetail_V7 - Integration_Evolution_PurchaseOrderHeader - Integration_Evolution_SalesOrderDetail - Integration_Evolution_SalesOrderDetail_V7 - Integration_Evolution_SalesOrderHeader - Integration_Evolution_TransferDetail - Integration_Evolution_TransferHeader - Integration_Evolution_WorkOrderDetail - Integration_Evolution_WorkOrderHeader</p>"},{"location":"database/release-notes/#scheduledjobs-triggers","title":"ScheduledJobs Triggers","text":"<p>Updated: - TriggerGranitePurchaseOrders - TriggerGraniteSalesOrders - TriggerGraniteWarehouseTransfer</p>"},{"location":"database/release-notes/#accpac-integration","title":"Accpac Integration","text":""},{"location":"database/release-notes/#scheduledjobs-views_1","title":"ScheduledJobs Views","text":"<p>Added: - Integration_Accpac_IntransitDetail - Integration_Accpac_IntransitHeader - Integration_Accpac_MasterItem - Integration_Accpac_PurchaseOrderDetail - Integration_Accpac_PurchaseOrderHeader - Integration_Accpac_ReceiptDetail - Integration_Accpac_ReceiptHeader - Integration_Accpac_SalesOrderDetail - Integration_Accpac_SalesOrderHeader - Integration_Accpac_TradingPartner - Integration_Accpac_TransferDetail - Integration_Accpac_TransferHeader - Integration_Accpac_WorkOrderDetail - Integration_Accpac_WorkOrderHeader</p>"},{"location":"database/release-notes/#scheduledjobs-triggers_1","title":"ScheduledJobs Triggers","text":"<ul> <li>TriggerGranitePurchaseOrders</li> <li>TriggerGraniteSalesOrders</li> <li>TriggerGraniteTransfers</li> <li>TriggerGraniteWorkOrders</li> </ul>"},{"location":"database/release-notes/#syspro-database","title":"Syspro Database","text":"<p>New project for Syspro integration</p>"},{"location":"database/release-notes/#tables","title":"Tables","text":"<ul> <li>InvMaster</li> <li>PorMasterDetail</li> <li>PorMasterHdr</li> <li>SorDetail</li> <li>SorMaster</li> <li>WipJobAllMat</li> <li>WipMaster</li> </ul>"},{"location":"database/release-notes/#triggers","title":"Triggers","text":"<ul> <li>TriggerGraniteWorkOrders</li> <li>TriggerGraniteSalesOrders</li> <li>TriggerGranitePurchaseOrders</li> </ul>"},{"location":"database/release-notes/#procedures","title":"Procedures","text":"<ul> <li>IntegrationMasterItems</li> <li>IntegrationProcessPurchaseOrder</li> <li>IntegrationProcessSalesOrder</li> <li>IntegrationProcessWorkOrders</li> </ul>"},{"location":"database/release-notes/#sapb1-database","title":"SAPB1 Database","text":""},{"location":"database/release-notes/#new-tables_2","title":"New Tables","text":"<ul> <li>ORDN</li> </ul>"},{"location":"database/release-notes/#sapb1-integration","title":"SAPB1 Integration","text":""},{"location":"database/release-notes/#scheduled-job-views","title":"Scheduled Job Views","text":"<ul> <li>Integration_SAPB1_MasterItem</li> <li>Integration_SAPB1_PurchaseOrderDetail</li> <li>Integration_SAPB1_PurchaseOrderHeader</li> <li>Integration_SAPB1_SalesOrderDetail</li> <li>Integration_SAPB1_SalesOrderHeader</li> <li>Integration_SAPB1_TransferDetail</li> <li>Integration_SAPB1_TransferHeader</li> </ul>"},{"location":"database/release-notes/#omni-integration","title":"Omni Integration","text":"<p>New project added to database solution</p> <p>Tables: - Omni_DebugJSON</p> <p>Functions: - FN_BasicAuthHeader</p> <p>StoredProcedures:  - HttpProcedures:     - HTTP_GET_JSON     - HTTP_POST     - HTTP_POST_JSON     - HTTP_PUT_JSON - Omni_PurchaseOrderSync - Omni_SalesOrderSync - Omni_StockTakeSync - Omni_WarehouseReqSync - Omni_WarehouseTransferSync - Omni_WorkOrderSync</p>"},{"location":"database/release-notes/#24-feb-2023-4220","title":"24 Feb 2023 (4.2.2.0)","text":""},{"location":"database/release-notes/#granitedatabase_3","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#new-tables_3","title":"New tables","text":"<ul> <li>UsersCredential     <pre><code>CREATE TABLE [dbo].[UsersCredential]\n(\n    [ID] [bigint] IDENTITY(1,1) NOT NULL, \n    [Users_id] BIGINT NOT NULL unique,\n    [Password] VARCHAR(MAX) NOT NULL, \n    [Salt] VARCHAR(64) NOT NULL, \n    [PasswordStrength] VARCHAR(20) NULL, \n    [AuditDate] DATETIME NULL,\n    [AuditUser] VARCHAR(20) NULL, \n    [Version] SMALLINT NULL, \n    CONSTRAINT [PK_UsersCredential] PRIMARY KEY ([ID]),\n)\n</code></pre></li> <li>ApplicationLog     <pre><code>CREATE TABLE [dbo].[ApplicationLog]\n(\n    [Id] BIGINT NOT NULL PRIMARY KEY IDENTITY, \n    [Date] DATETIME NOT NULL, \n    [Application] VARCHAR(50) NULL,\n    [LogOrigin] VARCHAR(50) NULL,\n    [LogLevel] VARCHAR(20) NULL, \n    [Message] VARCHAR(MAX) NULL,\n    [User] VARCHAR(20) NULL, \n    [GraniteTransaction_id] BIGINT NULL,\n    [Document_id] BIGINT NULL, \n    [DocumentDetail_id] BIGINT NULL\n)\n</code></pre></li> </ul>"},{"location":"database/release-notes/#table-changes_1","title":"Table changes","text":"<ul> <li>TradingPartner increase Email column size and add ERPIdentification     <pre><code>ALTER TABLE TradingPartner\nALTER COLUMN [Email] [varchar](500) NULL\n</code></pre> <pre><code>ALTER TABLE TradingPartner\nADD [ERPIdentification] varchar(50) NULL\n</code></pre></li> <li>ScheduledJobsHistory AuditDate not null     <pre><code>ALTER TABLE ScheduledJobsHistory\nALTER COLUMN [AuditDate] [datetime] NOT NULL\n</code></pre></li> <li>ProcessStepLookup increase column lengths     <pre><code>ALTER TABLE ProcessStepLookup\nALTER COLUMN [Value] [varchar](100) NULL\nGO\nALTER TABLE ProcessStepLookup\nALTER COLUMN [Description] [varchar](100) NULL\n</code></pre></li> <li>ProcessStepLookupDynamic increase column lengths     <pre><code>ALTER TABLE ProcessStepLookupDynamic\nALTER COLUMN [Value] [varchar](100) NULL\nGO\nALTER TABLE ProcessStepLookupDynamic\nALTER COLUMN [Description] [varchar](100) NULL\n</code></pre></li> <li>IntegrationDocumentQueue change ERP_id datatype decimal(19,0) -&gt; varchar(50)     <pre><code>ALTER TABLE IntegrationDocumentQueue\nALTER COLUMN [ERP_id] VARCHAR(50) NOT NULL\n</code></pre></li> <li>Status add column Version     <pre><code>ALTER TABLE [Status]\nADD [Version] SMALLINT NULL\n</code></pre></li> </ul>"},{"location":"database/release-notes/#view-changes","title":"View changes","text":"<pre><code>Various fixes. Update the following views to ensure compatibility\n</code></pre> <ul> <li>API_QueryStockDetail (spelling fix, LocactionType -&gt; LocationType)</li> <li>API_QueryStockTakeLines (add missing column, MasterItem.Description)</li> <li>API_QueryStockTakeLinesSummary (Change add columns Count1Qty, Count2Qty, Count3Qty)</li> <li>Integration_Transactions (fix only showing most recent IntegraitonLog entry for all failed transactions)</li> </ul>"},{"location":"database/release-notes/#stored-procedure-changes","title":"Stored Procedure changes","text":"<ul> <li>EmailTemplate (updated to maintain compatibility with GraniteScheduler)     <pre><code>INSERT INTO @Output (Name, Value)\nVALUES  ('RecipientList', @RecipientList),\n        ('CC', @CC),\n        ('BCC', @BCC),\n        ('Subject', @Subject),\n        ('Body', @Body),\n        ('BodyIsHtml', CAST(ISNULL(@BodyIsHtml, 0) as varchar)),\n        ('AttachmentPath', @AttachmentPath)\n\nSELECT * FROM @Output\n</code></pre>     changes to     <pre><code>SELECT  @RecipientList RecipientList, \n        @CC CC, \n        @BCC BCC, \n        @Subject [Subject], \n        @Body Body, \n        @BodyIsHtml BodyIsHtml, \n        @AttachmentPath AttachmentPath\n</code></pre></li> </ul>"},{"location":"database/release-notes/#default-process-scripts","title":"Default Process scripts","text":"<ul> <li>Fix DefaultAdjustmentProcess.sql incorrect process name for lookup values</li> <li>Fix DefaultQualityControlProcess.sql incorrect process name for lookup values</li> </ul>"},{"location":"database/release-notes/#miscellaneous","title":"Miscellaneous","text":""},{"location":"database/release-notes/#new","title":"New","text":"<ul> <li>Add older comparison scripts<ul> <li>CompareTables.sql</li> <li>CompareTablesAndViews.sql </li> </ul> </li> <li>Add data compare scripts<ul> <li>RowCountCompare.sql</li> <li>ViewCountCompare.sql</li> </ul> </li> <li>Add  .sql</li> <li>Add DropUnusedIndex.sql</li> <li>Add UnusedIndexes.sql</li> <li>Add ShowDBLocks.sql</li> </ul>"},{"location":"database/release-notes/#changes","title":"Changes","text":"<ul> <li>ColumnCompare.sql (<ul> <li>Add where clause example to include/exclude views)</li> <li>Add column isTable</li> </ul> </li> </ul>"},{"location":"database/release-notes/#evolutiondatabase","title":"EvolutionDatabase","text":""},{"location":"database/release-notes/#new_1","title":"New","text":"<ul> <li>Add Views and triggers for ScheduledJobs (still needs work)</li> </ul>"},{"location":"database/release-notes/#07-sep-2022-4210","title":"07 Sep 2022 (4.2.1.0)","text":"<pre><code>    Major release to support Audit and Versioning.\n    Add version column to all tables with audit functionality. \n    Document and DocumentDetail add columns to be used by integration to flag sync failures.\n    Several minor changes as listed below.\n</code></pre>"},{"location":"database/release-notes/#table-changes-add-version-column","title":"Table Changes Add Version column","text":"<pre><code>ALTER TABLE [Category] ADD [Version] SMALLINT NULL\n</code></pre> <pre><code>ALTER TABLE [Type] ADD [Version] SMALLINT NULL\n</code></pre> <p><pre><code>ALTER TABLE [TradingPartner] ADD [Version] SMALLINT NULL\n</code></pre> Add AuditDate, AuditUser also <pre><code>ALTER TABLE [ProcessMembers] \nADD [Version] SMALLINT NULL,\n    [AuditDate] DATETIME NULL, \n    [AuditUser] VARCHAR(20) NULL,\n</code></pre> <pre><code>ALTER TABLE [UserGroup] \nADD [Version] SMALLINT NULL,\n    [AuditDate] DATETIME NULL, \n    [AuditUser] VARCHAR(20) NULL,\n</code></pre></p> <p><pre><code>ALTER TABLE [Process] \nADD [Version] SMALLINT NULL,\n    [AuditDate] DATETIME NULL, \n    [AuditUser] VARCHAR(20) NULL,\n</code></pre> <pre><code>ALTER TABLE [ProcessStep] \nADD [Version] SMALLINT NULL,\n[AuditDate] DATETIME NULL ,\n[AuditUser] VARCHAR(20) NULL\n</code></pre></p>"},{"location":"database/release-notes/#table-changes-add-erpsyncfailed-erpsyncfailedreason","title":"Table changes Add ERPSyncFailed, ERPSyncFailedReason","text":"<pre><code>ALTER TABLE [Document]\nADD [ERPSyncFailed] BIT NOT NULL DEFAULT 0,\n[ERPSyncFailedReason] VARCHAR(500) NULL,\n[Version] SMALLINT NULL\n</code></pre> <pre><code>ALTER TABLE [DocumentDetail] \nADD [ERPSyncFailed] BIT NOT NULL DEFAULT 0,\n[ERPSyncFailedReason] VARCHAR(500) NULL,\n[Version] SMALLINT NULL\n</code></pre>"},{"location":"database/release-notes/#view-changes_1","title":"View Changes","text":"<pre><code>View changes below fixing various issues. Alteration on views required.\n</code></pre> <ul> <li>Add column MasterItem_id to the following views</li> <li>API_QueryInventoryVariance</li> <li>API_QueryInventoryVarianceDetail</li> <li>API_QueryStockDetail</li> <li>API_QueryStockTotals </li> <li> <p>API_QueryStockTotalsDetail</p> </li> <li> <p>Fix Integration_Transactions view</p> </li> <li> <p>Add clause to exclude CONSUME and Process.IntegrationIsActive. Also Exclude reversed transactions.</p> </li> <li> <p>Fix reversal views, don't show already reversed transactions </p> </li> <li>API_QueryTransactionsTransferReversal</li> <li>API_QueryTransactionsReceiveReversal</li> <li>API_QueryTransactionsPickReversal</li> </ul>"},{"location":"database/release-notes/#15-aug-2022","title":"15 Aug 2022","text":""},{"location":"database/release-notes/#view-changes_2","title":"View changes","text":""},{"location":"database/release-notes/#-add-masteritem-id-to-views-api_querystocktotalsdetail-api_querystocktotals-api_querystockdetail","title":"- Add masterItem ID to views. API_QueryStockTotalsDetail, API_QueryStockTotals, API_QueryStockDetail","text":""},{"location":"database/release-notes/#04-aug-2022-4200","title":"04 Aug 2022 (4.2.0.0)","text":"<p>Minor release for database changes in regards to future work. Release also include changes related to Function Stored Procedures</p>"},{"location":"database/release-notes/#systemsettings-new-data-entry","title":"SystemSettings new data entry","text":"<p>Setting to hold database version in SystemSettings table.</p> <pre><code>INSERT INTO SystemSettings ([Application], [Key], [Value], [Description], [isEncrypted], [isActive], AuditDate, AuditUser)\nVALUES ('GRANITE', 'DatabaseVersion', '4.2.0.0', 'Granite Database version', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre>"},{"location":"database/release-notes/#new-table-type","title":"New table type","text":"<p>ScriptInputIdentities new type used by Function stored procedures <pre><code>CREATE TYPE [dbo].[ScriptInputIdentities] AS TABLE(\n    [ID] [bigint] NOT NULL\n)\nGO\n</code></pre></p>"},{"location":"database/release-notes/#function-template","title":"Function Template","text":"<ul> <li>New example of Function stored procedure</li> </ul>"},{"location":"database/release-notes/#new-table","title":"New Table","text":"<ul> <li>Audit Table (usage of table for future release)</li> </ul>"},{"location":"database/release-notes/#27-july-2022","title":"27 July 2022","text":""},{"location":"database/release-notes/#data-changes","title":"Data changes","text":"<ul> <li>Add new processes for \"Menu\" groupings</li> <li>Default data entry in SystemSettings for GRANITESCHEDULER (ScheduleService)</li> <li>Scheduled job entry for InventorySnapshot (ScheduleService)</li> <li>Example EmailTemplate procedure</li> </ul>"},{"location":"database/release-notes/#view-changes_3","title":"View changes","text":"<ul> <li>API_QueryDocumentProgressDetail add UOM columns, add lineType for manufacturing</li> <li>SystemMetaData_View various improvements</li> </ul>"},{"location":"database/release-notes/#table-changes_2","title":"Table changes","text":"<ul> <li>Users add column AllowSystemSettings, AllowScheduledJobs, AllowSystemMetaData, AllowDataImport</li> <li>ScheduledJobs rename column JobParameter to StoredProcedure</li> </ul>"},{"location":"database/release-notes/#new-tables_4","title":"New Tables","text":"<ul> <li>SystemSettings</li> <li>ScheduledJobsHistory</li> <li>ScheduledJobInput</li> </ul>"},{"location":"database/release-notes/#stored-procs-changes","title":"Stored Procs changes","text":"<ul> <li>Job_Inventory_DailySnapShot remove dependency on Base view.</li> </ul>"},{"location":"database/release-notes/#30-june","title":"30 June","text":""},{"location":"database/release-notes/#process-and-steps-default","title":"Process and Steps default","text":"<ul> <li>Default Process and Steps data/setup improvements.</li> </ul>"},{"location":"database/release-notes/#new-views_3","title":"New Views","text":"<ul> <li>API_QueryStockReorder</li> <li>API_QueryStockReplenish</li> </ul>"},{"location":"database/release-notes/#new-function","title":"New function","text":"<ul> <li>FN_GetOptionalField</li> </ul>"},{"location":"database/release-notes/#07-june","title":"07 June","text":"<p>Documentation for Accpac, SAP, Evolution Tables. Path: \\Software Installs\\Granite\\Granite V3.4.4\\GraniteDatabase</p>"},{"location":"database/release-notes/#granitedatabase_4","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#table-changes_3","title":"Table changes","text":"<ul> <li>Users, Name and Password not null</li> <li>Users, Name UNIQUE</li> <li>SystemMetaData, New column ProcessName</li> </ul>"},{"location":"database/release-notes/#view-changes_4","title":"View changes","text":"<ul> <li>API_QueryTransactionsPicking, add column ReversalTransaction_id</li> <li>API_QueryTransactionsReceiving, add column ReversalTransaction_id</li> <li>API_QueryTransactionsTransfer, add column ReversalTransaction_id</li> <li>API_QueryStockDetail, add columns MasterItem and Location Category and Type</li> <li>API_QueryStockTotals</li> <li>API_QueryDocumentProgressDetail</li> <li>API_QueryStockTakeLinesSummary</li> </ul>"},{"location":"database/release-notes/#new-function_1","title":"New function","text":"<ul> <li>SSRS_ParameterSplit, function used by SSRS reports to split comma delimited string</li> </ul>"},{"location":"database/release-notes/#sapb1","title":"SAPB1","text":"<ul> <li>IntegrationProcessSalesOrder - Added Unit of Measure, Comment to lines, Changed Status on the Temporary Table from bit to varchar.</li> <li>Created Queue stored proc for Transfer Requests</li> <li>Created Process stored proc for Transfer Requests</li> </ul>"},{"location":"database/release-notes/#accpac","title":"ACCPAC","text":""},{"location":"database/release-notes/#stored-proc-changes","title":"Stored Proc Changes","text":"<ul> <li>IntegrationProcessTransfer, Tweaks to the TransferIntegration for Sage Accpac. Mainly to deal with Intransit Receipt Document</li> <li>IntegrationProcessPurchaseOrder. Update Granite document isActive</li> <li>IntegrationProcessSalesOrder. Update Granite document isActive</li> </ul>"},{"location":"database/release-notes/#new-stored-proc","title":"New Stored Proc","text":"<p>Downwards integration for Supplier Returns - New IntegrationProcessSupplierReturn, TriggerGraniteSupplierReturn</p>"},{"location":"database/release-notes/#20-may-2022","title":"20 May 2022","text":""},{"location":"database/release-notes/#granitedatabase_5","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#view-changes_5","title":"View changes","text":"<ul> <li>Integration_Transactions, exclude SPLIT transaction type, should not integrate. AND (dbo.[Transaction].Type != 'SPLIT')</li> <li>SystemMetaData_View, various fixes</li> <li>ProcessStepLookup_View, distinct UNION to exclude double entries</li> </ul>"},{"location":"database/release-notes/#18-may-2022","title":"18 May 2022","text":""},{"location":"database/release-notes/#granitedatabase_6","title":"GraniteDatabase","text":""},{"location":"database/release-notes/#new-table_1","title":"New table","text":"<ul> <li>ScheduledJobs     <pre><code>[ID] BIGINT NOT NULL PRIMARY KEY IDENTITY,\n[isActive] [bit] NOT NULL,\n[JobName] [varchar](50) NOT NULL UNIQUE,\n[JobDescription] [varchar](100) NULL,\n[Type] [varchar](50) NULL,\n[JobParameter] [varchar](100) NULL,\n[Interval] [varchar](50) NULL,\n[IntervalFormat] [varchar](50) NULL,\n[Status] [varchar](50) NULL,\n[LastExecutionTime] [datetime] NULL,\n[LastExecutionResult] [varchar](50) NULL,\nAuditDate datetime NULL,\nAuditUser varchar(20) NULL\n</code></pre></li> </ul>"},{"location":"database/release-notes/#table-changes_4","title":"Table changes","text":"<ul> <li>Users AllowBulkScrap &amp; AllowBulkMove DEFAULT 0</li> <li>TradingPartner not null constraint on Code, Description, DocumentType</li> <li>TradingPartner Code increase to 50</li> <li>Table SystemSettings add column Application     <pre><code>[Application] VARCHAR(50) NOT NULL\n</code></pre></li> </ul>"},{"location":"database/release-notes/#view-changes_6","title":"View changes","text":"<ul> <li>API_QueryStockTakeLines add missing recommendation</li> <li>API_QueryPickslipLines added in Comment and Instruction and missing fields    </li> <li>API_QueryTransactions add FromBarcode</li> </ul>"},{"location":"database/release-notes/#13-may-2022","title":"13 May 2022","text":""},{"location":"database/release-notes/#view-changes-alter-views","title":"View Changes (alter views)","text":"<ul> <li>API_QueryStockTakeLines: Add recommendation for Count1,2,3 match</li> </ul>"},{"location":"database/release-notes/#05-may-2022","title":"05 May 2022","text":""},{"location":"database/release-notes/#view-changes-alter-views_1","title":"View Changes (alter views)","text":"<p>Should be safe at this stage to re-create all API_* views for existing clients (upgrades) - API_QueryDocumentProgress: Add column TradingPartnerCode, ExpectedDate.  - API_QueryDocumentProgress, API_QueryDocument: Include completed documents with audit date in last 14 / 30 days - API_QueryStockTakeLinesSummary. Change join from Barcode to ID on TrackingEntity Table - API_QueryStockTakeLines. Change join from Barcode to ID on TrackingEntity Table - API_QueryUserGroups, Add Users columns</p>"},{"location":"database/release-notes/#table-document-add-columns","title":"Table Document add columns","text":"<pre><code>Route varchar(30) \nStop varchar(30) \nAssignedTo varchar(250)\n</code></pre>"},{"location":"database/release-notes/#table-document-change-column","title":"Table Document change column","text":"<pre><code>TradingPartnerDescription varchar(250)\n</code></pre>"},{"location":"database/release-notes/#table-tradingpartner-change-column","title":"Table TradingPartner change column","text":"<pre><code>Description varchar(250)\n</code></pre>"},{"location":"database/release-notes/#table-custom_documenttrackinglog-change-column","title":"Table custom_DocumentTrackingLog change column","text":"<pre><code>Comment varchar(250)\n</code></pre>"},{"location":"database/release-notes/#table-custom_documenttrackinglog-add-column","title":"Table custom_DocumentTrackingLog add column","text":"<pre><code>Process varchar(50) \nAdditionalData varchar(250)\n</code></pre>"},{"location":"database/release-notes/#table-stocktakelines-add-columns","title":"Table StockTakeLines add columns","text":"<pre><code>OpeningLocationERP varchar(15)\nMasterItemCode varchar(40)\n</code></pre>"},{"location":"database/release-notes/#31-mar-2022","title":"31 Mar 2022","text":""},{"location":"database/release-notes/#table-stocktakelines-add-column","title":"Table StockTakeLines Add column","text":"<pre><code>TrackingEntity_id bigint\n</code></pre>"},{"location":"database/release-notes/#views-new","title":"Views New","text":"<ul> <li>SystemMetaData_View</li> </ul>"},{"location":"database/release-notes/#25-mar-2022","title":"25 Mar 2022","text":""},{"location":"database/release-notes/#table-masteritemalias","title":"Table MasterItemAlias","text":"<ul> <li>Change column Code type to VARCHAR(50)</li> </ul>"},{"location":"database/release-notes/#23-mar-2022","title":"23 Mar 2022","text":""},{"location":"database/release-notes/#table-functionparameter-add-column","title":"Table FunctionParameter Add column","text":"<pre><code>isBool bit\n</code></pre>"},{"location":"database/release-notes/#08-mar-2022","title":"08 Mar 2022","text":"<p>Table FunctionParameterLookup Add column  <pre><code>isActive bit\n</code></pre></p>"},{"location":"database/release-notes/#table-functionparameterlookup","title":"Table FunctionParameterLookup","text":"<ul> <li>Rename column Function to FunctionName</li> <li>Rename column Description to ParameterName</li> </ul>"},{"location":"database/release-notes/#new-views_4","title":"New Views","text":"<ul> <li>FunctionParameterLookup_View</li> </ul>"},{"location":"database/release-notes/#changed-views_6","title":"Changed Views","text":"<ul> <li>API_QueryDocumentProgressDetail change lineNumber to bigint</li> <li>API_QueryTransactionsPickReversal</li> <li>API_QueryTransactionsReceiveReversal</li> <li>API_QueryTransactions</li> </ul>"},{"location":"database/release-notes/#27-feb-2022","title":"27 Feb 2022","text":""},{"location":"database/release-notes/#new-views_5","title":"New Views","text":"<ul> <li>API_QueryTransactionsTransferReversal</li> <li>API_QueryStockTakeCriteria</li> </ul>"},{"location":"database/release-notes/#changed-views_7","title":"Changed Views","text":"<ul> <li>App_Outbound_Packing where clause for type incorrect.</li> <li>API_QueryStockDetail. Rename columns MasterItemCode and MasterItemDescription to Code and Description</li> <li>API_QueryTransactions. Add column LineNumber</li> <li>API_QueryPickslipLines. Add column SalesOrderLine </li> <li>API_QueryStockTotalsDetail, API_QueryStockTotals. Exclude Non stock location</li> <li>API_QueryStockDetail. Rename columns MasterItemCode and MasterItemDescription to Code    and Description</li> <li>API_QueryDocumentProgress add column document description</li> </ul>"},{"location":"database/release-notes/#table-transaction-add-column","title":"Table Transaction add column","text":"<pre><code>LinkedTransaction_id bigint NULL\n</code></pre>"},{"location":"database/release-notes/#table-documentdetail-update-columns","title":"Table DocumentDetail Update columns","text":"<pre><code> LineNumber varchar(50)\n Comment varchar(250)\n ```\n\n### Table StockTakeSession add column \n```sql\nSite varchar(30) NULL\n</code></pre>"},{"location":"database/release-notes/#table-processstep-data","title":"Table ProcessStep data","text":"<ul> <li>Add step DocumentReference to all standard Document Post processes</li> </ul>"},{"location":"database/release-notes/#accpac_1","title":"Accpac:","text":""},{"location":"database/release-notes/#stored-procs-new-fixes","title":"Stored Procs New &amp; Fixes","text":"<ul> <li>Fix IntegrationProcessTransfer. Receipt qty fetch from ICTRID</li> <li>New Upwards integration scripts Accpac IC / Assemblies.</li> <li>IntegrationProcessTransfer add no lock</li> <li>IntegrationProcessSalesOrder add no lock</li> <li>IntegrationProcessPurchaseOrder add no lock</li> </ul>"},{"location":"database/release-notes/#22-nov-2021","title":"22 Nov 2021","text":""},{"location":"database/release-notes/#table-users-new-columns","title":"Table Users new columns","text":"<pre><code>[AllowBulkScrap] bit NOT NULL\n[AllowBulkMove] bit NOT NULL\n</code></pre>"},{"location":"database/release-notes/#10-nov-2021","title":"10 Nov 2021","text":""},{"location":"database/release-notes/#execute-script-to-add-previous-data-for-documents","title":"EXECUTE Script to add previous Data for Documents:","text":"<pre><code>INSERT INTO TradingPartner (Code,[Description],[Name], DocumentType, AuditDate, AuditUser)\nSELECT DISTINCT TradingPartnerCode, TradingPartnerDescription, TradingPartnerCode, [Type], getdate(), 'INTEGRATION'\nFROM Document WHERE TradingPartnerCode NOT IN (SELECT Code FROM TradingPartner)\n</code></pre>"},{"location":"database/release-notes/#accpac_2","title":"Accpac:","text":""},{"location":"database/release-notes/#update-stored-procs-to-insert-trading-partner","title":"Update Stored procs to insert trading partner:","text":"<ul> <li>IntegrationProcessPurchaseOrder </li> <li>IntegrationProcessSalesOrder </li> </ul>"},{"location":"database/release-notes/#pastel-evo","title":"Pastel Evo:","text":""},{"location":"database/release-notes/#update-stored-procs-to-insert-trading-partner_1","title":"Update Stored procs to insert trading partner:","text":"<ul> <li>IntegrationProcessPurchaseOrder </li> <li>IntegrationProcessSalesOrder </li> </ul>"},{"location":"database/release-notes/#sap-b1","title":"SAP B1:","text":""},{"location":"database/release-notes/#update-stored-procs-to-insert-trading-partner_2","title":"Update Stored procs to insert trading partner:","text":"<ul> <li>GranitePurchaseOrder </li> <li>GraniteSalesOrder </li> </ul>"},{"location":"database/release-notes/#3-november-2021","title":"3 November 2021","text":""},{"location":"database/release-notes/#table-tradingpartner-new-columns","title":"Table TradingPartner new columns","text":"<pre><code>DocumentType \nAuditDate \nAuditUser\n</code></pre>"},{"location":"database/release-notes/#table-tradingpartner-rename-column-name-to-description","title":"Table TradingPartner rename column Name to Description","text":""},{"location":"database/release-notes/#table-users-new-column","title":"Table Users new column","text":"<p><pre><code>AllowTradingPartner \n</code></pre> Table Document new column  <pre><code>ExpectedDate\n</code></pre></p>"},{"location":"database/release-notes/#new-view","title":"New View","text":"<ul> <li>API_QueryTradingPartners</li> </ul>"},{"location":"database/release-notes/#update-view-api_querylocations-remove-0-qty-trackingentities","title":"Update view API_QueryLocations remove 0 qty trackingentities","text":""},{"location":"database/release-notes/#data-table-type","title":"Data Table Type","text":"<ul> <li>Rename document types to INTRANSIT and RECEIPT</li> </ul>"},{"location":"database/release-notes/#06-oct-2021","title":"06 Oct 2021","text":""},{"location":"database/release-notes/#table-transaction-new-columns","title":"Table Transaction new columns","text":"<pre><code>[ReversalTransaction_id] BIGINT NULL\n</code></pre>"},{"location":"database/release-notes/#table-documentdetail-new-columns","title":"Table DocumentDetail new columns","text":"<pre><code>[ReversalAuditUser] VARCHAR(20) NULL\n[ReversalAuditDate] DATETIME NULL\n</code></pre>"},{"location":"database/release-notes/#data-table-status","title":"Data Table Status","text":"<ul> <li>Rename status CANCELED to CANCELLED</li> </ul>"},{"location":"database/release-notes/#data-table-type_1","title":"Data Table Type","text":"<ul> <li>Add transaction type TRANSACTIONREVERSAL</li> </ul>"},{"location":"database/release-notes/#new-views_6","title":"New Views","text":"<ul> <li>API_QueryTransactionsReceiveReversal</li> <li>API_QueryTransactionsPickReversal</li> </ul>"},{"location":"database/release-notes/#07-sep-2021","title":"07 Sep 2021","text":""},{"location":"database/release-notes/#new-sql-views","title":"New Sql Views","text":"<ul> <li>API_QueryTransactionsPicking</li> <li>API_QueryTransactionsReceiving </li> <li>API_QueryTransactionsManufacture </li> <li>API_QueryTransactionsTransfer</li> </ul>"},{"location":"database/release-notes/#06-sep-2021","title":"06 Sep 2021","text":""},{"location":"database/release-notes/#table-process-change-column-integrationmethod-varchar-20-to-50","title":"Table Process change column IntegrationMethod - Varchar 20 to 50","text":"<pre><code>[IntegrationMethod] VARCHAR(50) NULL\n</code></pre>"},{"location":"database/release-notes/#table-stocktakelines-new-columns","title":"Table StockTakeLines new columns","text":"<pre><code>[MasterItem_id] BIGINT NULL\n</code></pre>"},{"location":"database/release-notes/#pastelevo-database","title":"PastelEVO Database","text":""},{"location":"database/release-notes/#add-scripts-for-pastel-transfer","title":"Add scripts for Pastel Transfer","text":"<p>Note the previous and still supported \u201ctransfer\u201d moved to IntransitTransfer.</p>"},{"location":"database/release-notes/#fix-stored-proc-integrationprocessworkorder-collate-issue","title":"Fix Stored Proc IntegrationProcessWorkOrder - collate issue","text":"<pre><code>...\\PastelEVOIntegration\\WorkOrder\\IntegrationProcessWorkOrder.sql\n</code></pre>"},{"location":"database/release-notes/#20-july-2021","title":"20 July 2021","text":"<ul> <li>New user AUTOMATION and UserGroup SYSTEM. Use when you have external applications, scripts, excel etc performing data alterations.</li> <li>Change: API_QueryDocumentProgress increase decimal point on progress percentage.</li> <li>Change: Table IntegrationLog column LogOrigin from varchar 20 to 50</li> <li>New: Add table FunctionParamaterLookup.</li> <li>Change: Table InventoryDailyBalanace add columns ERPSTDCOST and ERPLASTCOST.</li> <li>Change: API_QueryDocumentProgressDetail add Instruction and Comment column.</li> <li>Change: API_QueryProcesses add Prescripts column.</li> <li>Change: API_QueryDocumentProgress add TradingPartnerCode and Description. </li> <li>Change: API_QueryDocuments add InetgrationReference column. Add order by ID.</li> <li>Change/Alter: ProcessStepLookupDynamic table change identity seed to 100000.</li> <li>Change: Location table, Columns Name and Barcode length changed from 30 to 50.</li> <li>New: IntegrationMethodExample.sql \u2013 example stored procedure of how to implement custom integration stored proc.</li> <li>New Table ProcessStepLookupDynamic</li> <li>Change: ProcessStepLookup_View include data from ProcessStepLookupDynamic</li> <li>Add TRANSFERDYNAMICPOST process and process step.</li> </ul>"},{"location":"database/release-notes/#31-march-2021","title":"31 March 2021","text":""},{"location":"database/release-notes/#new-process-data-stocktakecount","title":"New Process Data StockTakeCount","text":"<pre><code>...\\Process\\DefaultStockTakeCountProcess.sql\n</code></pre>"},{"location":"database/release-notes/#new-process-data-returnpost","title":"New Process Data ReturnPost","text":"<pre><code>...\\Process\\DefaultDocumentPostProcesses.sql (RETURNPOST entry)\n</code></pre>"},{"location":"database/release-notes/#16-march-2021","title":"16 March 2021","text":""},{"location":"database/release-notes/#table-processsteplookup-new-columns","title":"Table ProcessStepLookUp new columns","text":"<pre><code>[UserName] VARCHAR(20) NULL\n</code></pre>"},{"location":"database/release-notes/#view-processsteplookup_view-new-columns","title":"View ProcessStepLookUp_View new columns","text":"<pre><code>[UserName]\n</code></pre>"},{"location":"database/release-notes/#1-march-2021","title":"1 March 2021","text":"<ul> <li>Add API views (web desktop) to create script execution</li> <li>Update view API_QueryTrackingEntities, add calculated column for TrackingEntity status</li> </ul>"},{"location":"database/release-notes/#10-jan-2021","title":"10 Jan 2021","text":""},{"location":"database/release-notes/#table-users-new-columns_1","title":"Table Users new columns","text":"<pre><code>[AllowProcess] BIT NULL DEFAULT 1\n[AllowUserGroups] BIT NULL DEFAULT 1\n</code></pre>"},{"location":"database/release-notes/#table-documentdetail-new-columns_1","title":"Table DocumentDetail new columns","text":"<pre><code>[LinePriority] int NULL \n[Instruction] VARCHAR(250) NULL\n</code></pre>"},{"location":"database/release-notes/#new-process-data-custom","title":"New Process Data Custom","text":"<pre><code>\u2026\\Process\\DefaultCustomProcess.sql (example)\n</code></pre>"},{"location":"iis/getting-started/","title":"IIS","text":"<p>IIS is the web server that is used for hosting all of Granite's APIs and applications. Once you've followed the steps below to install and configure IIS, you'll be ready to set up any of the Granite applications and APIs.</p>"},{"location":"iis/getting-started/#install","title":"Install","text":"<ol> <li> <p>From the control panel, select Programs and then click on Turn Windows Features on or off:</p> <p></p> </li> <li> <p>Go through the dialog that pops up to select the features shown below</p> Windows DesktopWindows Server <p>On desktop versions of Windows, select the following features under <code>Internet Information Services</code> and click OK:</p> <p></p> <p>On windows server editions, the Server Manager page pops up instead. Click next until you get to the Server Roles page:</p> <p></p> <p>Select these features under Web Server, then go to the next page and click install.</p> </li> <li> <p>Install the IIS URL Rewrite Module</p> </li> <li> <p>Install the latest ASP.NET Core Runtime 6 and 8 hosting bundles</p> <ul> <li>ASP.NET Core 8</li> <li>ASP.NET Core 6</li> </ul> <p></p> </li> </ol>"},{"location":"iis/getting-started/#creating-certificates","title":"Creating Certificates","text":"<p>Certificates are needed to host secured sites in IIS over https.  Most Granite applications and apis require this, so we will need to create a certificate for them to use. They can all use the same certificate, so you do not need to create multiple.</p> <p>Be sure to follow the correct section below based on the operating system of the machine you are installing on - older versions of Windows require some extra steps.</p>"},{"location":"iis/getting-started/#windows-10-server-2016-and-up","title":"Windows 10 / Server 2016 and up","text":"<p>On the server, open <code>PowerShell ISE</code> as Administrator and paste the following into a new script window</p> <pre><code>$FriendlyName = 'GraniteWMS'  # Give your certificate a name\n$ServerName = 'appsrv01.domain.local'  # Server name. This can also be just appsrv01\n$IPAddress = '192.168.0.168'  # Server IP address\n$ExportPath = \"C:\\GraniteInstalls\\$FriendlyName.cer\"  # Path to save certificate to\n\n# Create a new self-signed certificate with DNS and IP SAN\nNew-SelfSignedCertificate -Subject $IPAddress -CertStoreLocation \"cert:\\LocalMachine\\My\" -FriendlyName $FriendlyName  -TextExtension @(\"2.5.29.17={text}dns=$ServerName &amp;ipaddress=$IPAddress\") \n\n#Get Cert Thumbprint\n$Cert = Get-ChildItem -Path Cert:LocalMachine\\MY | Where-Object {$_.FriendlyName -Match $FriendlyName} | Select-Object Thumbprint\n$Thumbprint = $Cert.Thumbprint\n\n#Copy Cert to file\nExport-Certificate -Cert (Get-Item Cert:\\LocalMachine\\My\\$Thumbprint) -FilePath $ExportPath\n</code></pre> <p>Set your variables on the first four lines and execute the script. Ensure that the <code>$FriendlyName</code> is a unique name for the certificate - there must not be any other certificates in the store with the same name. It should look like this if all has worked:</p> <p></p> <p>You should now be able to select the certificate in IIS's Edit Bindings screen:</p> <p></p> <p>If you don't see the certificate you've just created in the dropdown, find it in the folder it exported to and double click it and select install. Be sure to install to the Local Machine store, and on the next page click browse and select the Personal store.</p> <p>If your certificate is still not available in IIS, please reach out to the development team for assistance.</p>"},{"location":"iis/getting-started/#windows-81-server-2012-r2-and-below","title":"Windows 8.1 / Server 2012 R2 and below","text":"<p>On older versions of Windows you need to create the certificate on your own machine and then import it on the server.</p> <p>On YOUR MACHINE, open <code>PowerShell ISE</code> as Administrator and paste the following into a new script window.</p> <pre><code>$FriendlyName = 'GraniteWMS'  # Give your certificate a name\n$ServerName = 'appsrv01.domain.local'  # Server name. This can also be just appsrv01\n$IPAddress = '192.168.0.168'  # Server IP address\n$ExportPath = \"C:\\GraniteInstalls\\$FriendlyName.cer\"  # Path to save certificate to\n\n# Create a new self-signed certificate with DNS and IP SAN\nNew-SelfSignedCertificate -Subject $IPAddress -CertStoreLocation \"cert:\\LocalMachine\\My\" -FriendlyName $FriendlyName  -TextExtension @(\"2.5.29.17={text}dns=$ServerName &amp;ipaddress=$IPAddress\") \n\n#Get Cert Thumbprint\n$Cert = Get-ChildItem -Path Cert:LocalMachine\\MY | Where-Object {$_.FriendlyName -Match $FriendlyName} | Select-Object Thumbprint\n$Thumbprint = $Cert.Thumbprint\n\n#Copy Cert to file\nExport-Certificate -Cert (Get-Item Cert:\\LocalMachine\\My\\$Thumbprint) -FilePath $ExportPath\n</code></pre> <p>Set your variables on the first four lines and execute the script. Ensure that the <code>$FriendlyName</code> is a unique name for the certificate - there must not be any other certificates in the store with the same name. It should look like this if all has worked:</p> <p></p> <p>Now search the start menu for <code>Manage computer certificates</code> and open it. Under Personal certificates you should see the certificate you have just created:</p> <p></p> <p>Right click it, and under All Tasks, select Export. Click Next and ensure you select <code>Yes, export the private key</code>:</p> <p></p> <p>On the next screen ensure you select the following:</p> <p></p> <p>On the next page, enter and confirm a password:</p> <p></p> <p>Lastly you will be prompted for a path to save the certificate to. Browse to where you want to save it and give it a name, then finish going through the export wizard.</p> <p>You should now have a <code>.pfx</code> file in the directory you selected with the name you entered.</p> <p>Copy the <code>.pfx</code> file to the server and double click it to install.</p> <p>Ensure you select <code>Local Machine</code>:</p> <p></p> <p>Click next until you get to a page prompting you for the password you set when exporting the certificate. Enter the password and be sure to select the Include all extended properties checkbox:</p> <p></p> <p>On the next page ensure you select the Personal certificate store, then finish going through the wizard.</p> <p>Your certificate should now be selectable from the IIS bindings edit screen:</p> <p></p>"},{"location":"iis/getting-started/#troubleshooting","title":"Troubleshooting","text":"Export-Certificate : The system cannot find the path specified <p>If you get this error it means that the path that the folder that you have specified in the <code>$ExportPath</code> variable does not exist. Make sure to create the folder you want to place the certificate in before you run the PowerShell script.</p> <p>Once you've created the folder to export to, you can comment out the part of the PowerShell script that creates the certificate to just run the export part.</p> Get-Item : Cannot find path 'Cert:\\LocalMachine\\My\\...' <p>Looking at the below screenshot you'll see that there are multiple thumbprints after <code>Cert:\\LocalMachine\\My\\</code></p> <p></p> <p>This happens when you have multiple certificates installed to the store with the same FriendlyName. The script needs a unique Friendly name to find the correct certificate.</p> <p>You can end up with multiple certificates named the same when the script has successfully created and installed the certificate but failed to export it, and you run the entire script again. </p> <p>You can remove unused certificates from the <code>Manage computer certificates</code> explorer by right clicking them and deleting. Try to ensure when you create a new certificate that you are giving it a unique name to prevent this from happening.</p>"},{"location":"iis/getting-started/#adding-a-site-to-iis","title":"Adding a site to IIS","text":"<p>Before you add your site to IIS, ensure that you have configured the relevant <code>appsettings.json</code> or <code>web.config</code> file as per the application's installation guide</p> <p>To add a site to IIS, open the IIS Manager and right click the Sites folder to select <code>Add Website</code>: </p> <p>In the dialogue enter relevant settings for your application. </p> <ul> <li>Site name is the name that will be used in IIS for this website.</li> <li>Physical path is where the application folder actually is</li> <li> <p>Binding settings determine the url that your application will be accessible at.  You should use either the host name or the IP address of the machine that you are installing on.  This ProcessApp will be accessible at <code>https://josh-laptop:40086</code></p> <p>Note</p> <p>Because we need the ProcessApp to use https, we have to select a SSL certificate that we have previously created. If we are adding a http site, there is no option to select an SSL certificate</p> </li> </ul> <p></p> <p>Once you click OK, you will see your site is available in IIS:</p> <p></p>"},{"location":"integration/accpac/","title":"Accpac","text":"<p>This document contains all of the information needed to set up and configure integration with Accpac. There are two parts to the complete integration solution:</p> <p>The SDK Provider is used by the Integration Service to map transactions performed in Granite to the relevant format for Accpac.</p> <p>The integration jobs are used by the Scheduler to pull Accpac's documents, item codes, and trading partners into Granite.</p>"},{"location":"integration/accpac/#external-resources","title":"External Resources","text":"<ul> <li>https://www.acutedata.com/sage-300-kb/</li> </ul>"},{"location":"integration/accpac/integration-jobs/","title":"Integration Jobs","text":"<p>Integration jobs are a special type of Scheduler job called injected jobs.  See below for information for specifics on how document and master data jobs work</p>"},{"location":"integration/accpac/integration-jobs/#supported-document-types","title":"Supported document types","text":"<ul> <li> <p>ORDER </p> <p>Accpac type: Sales Order</p> </li> <li> <p>RECEIVING</p> <p>Accpac type: Purchase Order</p> </li> <li> <p>INTRANSIT </p> <p>Accpac type: Transit Transfer</p> </li> <li> <p>RECEIPT</p> <p>Accpac type: Transit Receipt</p> </li> <li> <p>TRANSFER</p> <p>Accpac type: Transfer</p> </li> <li> <p>WORKORDER</p> <p>Accpac type: Assemblies</p> </li> </ul>"},{"location":"integration/accpac/integration-jobs/#how-it-works","title":"How it works","text":""},{"location":"integration/accpac/integration-jobs/#document-jobs","title":"Document jobs","text":"<p>Triggers on the ERP document tables insert a record into the Granite IntegrationDocumentQueue table whenever a change is applied to a document. </p> <p>GraniteScheduler runs injected jobs that monitor the IntegrationDocumentQueue table for records that need to be processed.</p> <p>When a record with Status 'ENTERED' is found, the job uses views on the Granite database to fetch the  information related to that document from the ERP database and apply the changes to the Granite document. </p> <p>All valid changes to data in the Granite tables are logged to the Audit table, showing the previous value and the new value.</p> <p>If a change is made in the ERP system that would put Granite into an invalid state, no changes are applied. Instead, the ERPSyncFailed field is set to true and the ERPSyncFailedReason field shows the reason for the failure. The IntegrationLog table will contain futher details on the failure if applicable.</p>"},{"location":"integration/accpac/integration-jobs/#master-data-jobs","title":"Master data jobs","text":"<p>MasterItems and TradingPartners have their own jobs. These jobs compare the results of their respective views to the data in the Granite tables and insert new records / update records as needed.</p> <p>The document jobs themselves also sync changes to the TradingPartners &amp; MasterItems that are on the document. This means that on sites that do not process a lot of changes to master data you can limit the MasterItem/TradingPartner jobs to running once a day or even less frequently. The only thing they are really still needed for is setting isActive to false when something is deactivated in the ERP system.</p>"},{"location":"integration/accpac/integration-jobs/#install","title":"Install","text":"<p>Note</p> <p>If you are upgrading from the old StoredProcedure/Trigger integration, ensure that ERPIdentification (Document, DocumentDetail, MasterItem, TradingPartner) column is populated with correct values before attempting to start the new jobs</p>"},{"location":"integration/accpac/integration-jobs/#set-up-database-triggers-views","title":"Set up database triggers &amp; views","text":"<p>Run the create scripts for the views and triggers that you will need for the version of ERP &amp; document types that the site uses.</p> <p>All document types also require the Integration_ERP_MasterItem view.</p>"},{"location":"integration/accpac/integration-jobs/#add-the-injected-job-files-to-granitescheduler","title":"Add the Injected job files to GraniteScheduler","text":"<p>To add the injected job files to the GraniteScheduler, simply copy the dlls and xml files into the root folder of GraniteScheduler. </p> <p>Example:</p> <p></p>"},{"location":"integration/accpac/integration-jobs/#configure","title":"Configure","text":""},{"location":"integration/accpac/integration-jobs/#schedule-configuration","title":"Schedule configuration","text":"<p>See the GraniteScheduler manual for the basics on how to configure injected jobs.</p> <p>Sometimes when the documents in Accpac are very large, the lines will not be finished inserting before we start fetching the records to create in Granite. To circumvent this issue, we have a setting that allows you to configure an offset for the <code>LastUpdateDateTime</code> field in the <code>IntegrationDocumentQueue</code> table.</p> <p>To configure this you simply add an entry into the <code>ScheduledJobInputs</code> table with the Name <code>LastUpdateTimeOffset</code> and the Value in minutes that you want to offset by</p> JobName Name Value SalesOrderJob LastUpdateTimeOffset 5 <p>Using this example, the SalesOrderJob will only pick up documents that have been sitting in the IntegrationDocumentQueue for longer than 5 minutes at the time the job runs. This should give Accpac the time it needs to insert all of the lines on a very large document. </p>"},{"location":"integration/accpac/integration-jobs/#email-on-error","title":"Email on Error","text":"<p>Note</p> <p>Emailing functionality is now handled by the Utility API, set up has changed from previous versions.</p> <p>Ensure that you have configured the UtilityApi for the Accpac injected jobs in the <code>SystemSettings</code> table:</p> Application Key Value Granite.Integration.Accpac.Job UtilityApi https://localhost:5001/ <p>Ensure you have the <code>IntegrationError</code> email template in your database. This is the email template that is used for all error notifications in these injected jobs. </p> <p>Then for each job that needs to send failure notifications, add a job input for <code>MailOnError</code> and <code>MailOnErrorToAddresses</code>:</p> JobName Name Value &lt; JobName goes here &gt; MailOnError true &lt; JobName goes here &gt; MailOnErrorToAddresses name@client.co.za;name2@client.co.za"},{"location":"integration/accpac/integration-jobs/#view-customisation","title":"View customisation","text":"<p>Each view can be customised to include custom logic or map extra fields to fields on the corresponding Granite table. </p> <p>All of the standard fields on Granite tables are supported, simply add the required field to your view with an alias matching the Granite field name on the table the view maps to.</p> <p>Non standard fields are also supported, but for these to work your column name on the destination table must start with 'Custom'. On the view, simply alias the name of the field to match the name of the field on the destination Granite table, including the 'Custom' prefix.</p> <p>For fields like Document.Status where you may have custom rules / statuses, use a CASE statement in your view definition so that the view returns the Status that you want to set on the Granite Document table.</p> <p>It is highly advised that you check the validity of yor job on the GraniteScheduler /config page after making a change to your view! Especially after changing filter criteria/joins, your view may be returning duplicate rows - the job validation will bring this to your attention.</p>"},{"location":"integration/accpac/integration-jobs/#whats-different-about-accpac-jobs","title":"What's different about Accpac jobs","text":""},{"location":"integration/accpac/integration-jobs/#inserting-lines-between-existing-lines-in-accpac","title":"Inserting lines between existing lines in Accpac","text":"<p>If enough lines are added in between existing lines on an Accpac document, existing line numbers can change. This will break the document in Granite as we lose the reference to the specific line in Accpac.  Luckily, this can be easily avoided by ensuring that the Accpac user modifying documents is trained to only ever add new lines at the bottom.</p>"},{"location":"integration/accpac/integration-jobs/#things-to-look-out-for","title":"Things to look out for","text":""},{"location":"integration/accpac/integration-jobs/#importance-of-erpidentification","title":"Importance of ERPIdentification","text":"<p>The injected jobs use the ERPIdentification column on the Document, DocumentDetail and MasterItem tables to look for matching records in the corresponding view. It is very important that you ensure that these values are populated for all records in Granite if you are upgrading from the old Document stored procedures.</p>"},{"location":"integration/accpac/integration-jobs/#validation","title":"Validation","text":"<p>Each job type has it's own validation criteria that must be passed before the job will execute. You can check the validity of injected jobs on the GraniteScheduler /config page. </p> <p>Here is an example of some failed validation:</p> <p></p>"},{"location":"integration/accpac/sdk-provider/","title":"SDK Provider","text":"<p>The Accpac SDK provider is responsible for mapping Granite transactions to the relevant format for posting to Accpac. It makes use of the Accpac Advantage SDK to post to Accpac.</p>"},{"location":"integration/accpac/sdk-provider/#setup","title":"Setup","text":"<ol> <li> <p>Check the version of the Accpac SDK that is currently installed on the server. The SDK is usually found at <code>C:\\Program Files (x86)\\Common Files\\Sage\\Sage 300 ERP</code>. Take note of the first two numbers of <code>Accpac.Advantage.dll</code> file version.</p> <p>Note</p> <p>If the SDK is not yet installed, please engage with the client's Accpac consultant - the SDK is required for Granite integration.</p> </li> <li> <p>In the <code>Providers\\Accpac</code> folder, find the <code>AccpacX.Y</code> folder matching the installed SDK version. <code>X.Y</code> must match the first two numbers of the installed SDK version. For example, if the installed SDK version is 6.5.0.30, you will take the files from the Accpac6.5 folder</p> </li> <li> <p>Copy everything in the <code>Providers\\Accpac\\AccpacX.Y</code> folder into Integration Service folder (root folder).</p> </li> <li> <p>Ensure <code>SDKProvider.xml</code> setup or copied correctly     <pre><code>&lt;module name=\"Provider\"&gt;\n&lt;bind\n    service=\"Granite.Integration.Contract.IProvider, Granite.Integration.Contract\"\n    to=\"Granite.Integration.Accpac.Provider, Granite.Integration.Accpac\"/&gt;\n&lt;/module&gt;\n</code></pre></p> </li> <li> <p>Configure your connection string and endpoint in the <code>Granite.Integration.Web.exe.config</code> file</p> </li> </ol>"},{"location":"integration/accpac/sdk-provider/#settings","title":"Settings","text":"<p>Note</p> <p>To pick up any changes to the SystemSettings table, the IntegrationService will need to be restarted.</p> <p>The settings for Sage 300 (Accpac) are configured in the SystemSettings table. The IntegrationService will pick up the settings using the Application name specified in it's <code>.config</code> file: If this setting is missing from the config file or left empty, the IntegrationService will default to using <code>IntegrationSage300</code> as the SystemSettingsApplicationName You can browse the IntegrationService's <code>/config</code> page to have the IntegrationService create the default settings in the SystemSettings table for you.</p>"},{"location":"integration/accpac/sdk-provider/#config-file-settings","title":"Config File Settings","text":"<pre><code>    &lt;add key=\"SystemSettingsApplicationName\" value=\"IntegrationSage300\" /&gt;\n    &lt;add key=\"EndPoint\" value=\"http://:40091/\" /&gt;\n</code></pre>"},{"location":"integration/accpac/sdk-provider/#systemsettingsapplicationname","title":"SystemSettingsApplicationName","text":"<p>The Application name of the entries in the SystemSettings table that you want to use for this integration service. This setting allows you to have multiple integration services running with different settings.</p>"},{"location":"integration/accpac/sdk-provider/#database-systemsettings","title":"Database SystemSettings","text":"<p>The script to insert the default settings is located in the GraniteDatabase release. <pre><code>~\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingsAccpac.sql\n</code></pre></p> Application Key Value Description IntegrationSage300 UserID Sage300 user name IntegrationSage300 Password Sage300 user password IntegrationSage300 CompanyID Sage300 company ID IntegrationSage300 POExchangeRate false Override exchange rate for PO and Multiple PO IntegrationSage300 PurchaseOrderOverrideLocation false Override line location for PO and Multiple PO IntegrationSage300 RoundSummarizedActionQty true Round summed ActionQty when posting transfers and moves IntegrationSage300 RoundSummarizedActionQtyToDecimalPlaces 2 Number of decimal places to round ActionQty to"},{"location":"integration/accpac/sdk-provider/#poexchangerate","title":"POExchangeRate","text":"<ul> <li>Options: true or false</li> <li>Used by: RECEIVE and RECEIVINGPOSTMULTIPLE</li> <li>Override the Receipt rate with the Purchase Order rate</li> <li>PO rate source: SELECT RATE FROM POPORH1 WHERE PONUMBER = 'your_po_number'</li> </ul>"},{"location":"integration/accpac/sdk-provider/#purchaseorderoverridelocation","title":"PurchaseOrderOverrideLocation","text":"<ul> <li>Options: true or false</li> <li>Used by: RECEIVE and RECEIVINGPOSTMULTIPLE</li> <li>Override the Receipt location with Granite location</li> </ul>"},{"location":"integration/accpac/sdk-provider/#roundsummarizedactionqty","title":"RoundSummarizedActionQty","text":"<ul> <li>Options: true or false</li> <li>Used by:<ul> <li>Replenish</li> <li>Move</li> <li>Dynamic Transfer</li> </ul> </li> <li>Turns rounding for summed ActionQty on or off</li> </ul>"},{"location":"integration/accpac/sdk-provider/#roundsummarizedactionqtytodecimalplaces","title":"RoundSummarizedActionQtyToDecimalPlaces","text":"<ul> <li>Options: integer value</li> <li>Used by:<ul> <li>Replenish</li> <li>Move</li> <li>Dynamic Transfer</li> </ul> </li> <li>Only comes into effect if RoundSummarizedActionQty is true</li> <li>Sets the number of decimal places that we round the summed ActionQty to</li> </ul>"},{"location":"integration/accpac/sdk-provider/#integration-methods","title":"Integration Methods","text":"<p>By default if the method name below is the same as a Granite Transaction type, it will autowire the integration. If you require a different integration action you can specify the name below in the Process IntegrationMethod property.</p>"},{"location":"integration/accpac/sdk-provider/#takeon","title":"TAKEON","text":"<ul> <li>Granite Transaction: TAKEON</li> <li>Accpac: I/C Receipts</li> <li>Supports: <ul> <li>Integration Reference</li> <li>Lots</li> <li>Serials</li> <li>UOM</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves receipt</li> <li>True - Posts receipt</li> </ul> </li> <li>Returns:<ul> <li>RECPNUMBER</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference RECPNUMBER Y ICREEH Create or update if exists, if empty follows Accpac sequence ID REFERENCE Y ICREEH MasterItemCode ITEMNO Y ICREED ERPLocation LOCATION Y ICREED Qty RECPQTY Y ICREED Lot LOTNUMF N ICREEDL Qty QTY N ICREEDL Serial SERIALNUMF N ICREEDS"},{"location":"integration/accpac/sdk-provider/#adjustment","title":"ADJUSTMENT","text":"<ul> <li>Granite Transaction: ADJUSTMENT</li> <li>Accpac: I/C Adjustments<ul> <li>Adjustment Type: Decrease Quantity OR Increase Quantity</li> </ul> </li> <li>Supports:<ul> <li>Integration Reference</li> <li>Lots </li> <li>Serials</li> <li>WOFFACCT (GL Account), mapped to Granite Comment</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves adjustment</li> <li>True - Posts adjustment</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM N ICADEH Create or update if exists, if empty follows Accpac sequence MasterItemCode ITEMNO Y ICADED FromLocation LOCATION Y ICADED ActionQty QUANTITY Y ICADED Batch LOTNUMF N ICADEDL ActionQty QTY N ICADEDL SerialNumber SERIALNUMF N ICADEDS Comment WOFFACCT N ICADED if comment not empty, this is the GL account"},{"location":"integration/accpac/sdk-provider/#adjustment_cost","title":"ADJUSTMENT_COST","text":"<p>Same as ADJUSTMENT but Adjustment Type set to Cost - Adjustment Type: Decrease Cost OR Increase Cost</p>"},{"location":"integration/accpac/sdk-provider/#adjustment_both","title":"ADJUSTMENT_BOTH","text":"<p>Same as ADJUSTMENT but Adjustment Type set to Both (Cost &amp; Qty) - Adjustment Type: Decrease Both OR Increase Both</p>"},{"location":"integration/accpac/sdk-provider/#adjustmentstatus","title":"ADJUSTMENTSTATUS","text":"<p>Note</p> <p>Document field on Granite transaction that is posted must match the Adjustment Number in Accpac.</p> <ul> <li>Granite Transaction: ADJUSTMENT</li> <li>Accpac: I/C Adjustments<ul> <li>Updates the status of the adjustment to Posted</li> </ul> </li> </ul>"},{"location":"integration/accpac/sdk-provider/#reclassify","title":"RECLASSIFY","text":"<ul> <li>Granite Transaction: RECLASSIFY</li> <li>Accpac: I/C Adjustments<ul> <li>Adjustment Type: Decrease Quantity AND Increase Quantity</li> </ul> </li> <li>Support <ul> <li>Integration Reference (Accpac Adjustment number, create or update if exists) </li> <li>Lots </li> <li>Serials</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves adjustment</li> <li>True - Posts adjustment</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM N ICADEH Create or update if exists, if empty follows Accpac sequence MasterItemCode ITEMNO Y ICADED FromLocation LOCATION Y ICADED ActionQty QUANTITY Y ICADED Batch LOTNUMF N ICADEDL ActionQty QTY N ICADEDL SerialNumber SERIALNUMF N ICADEDS"},{"location":"integration/accpac/sdk-provider/#reclassify_cost","title":"RECLASSIFY_COST","text":"<p>Same as RECLASSIFY but Adjustment Type set to COST - Adjustment Type: Decrease Cost AND Increase Cost</p>"},{"location":"integration/accpac/sdk-provider/#reclassify_both","title":"RECLASSIFY_BOTH","text":"<p>Same as RECLASSIFY but Adjustment Type set to BOTH (Cost &amp; Qty) - Adjustment Type: Decrease Both AND Increase Both</p>"},{"location":"integration/accpac/sdk-provider/#reclassify_split","title":"RECLASSIFY_SPLIT","text":"<p>Same as RECLASSIFY but Decrease Quantity and Increase Quantity post as two separate Adjustments in Accpac</p>"},{"location":"integration/accpac/sdk-provider/#scrap","title":"SCRAP","text":"<ul> <li>Granite Transaction: SCRAP</li> <li>Accpac: I/C Adjustments<ul> <li>Adjustment Type Decrease Quantity</li> </ul> </li> <li>Supports: <ul> <li>Integration Reference </li> <li>Lots</li> <li>Serials</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves adjustment</li> <li>True - Posts adjustment</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM N ICADEH Create or update if exists, if empty follows Accpac sequence MasterItemCode ITEMNO Y ICADED FromLocation LOCATION Y ICADED ActionQty QUANTITY Y ICADED Batch LOTNUMF N ICADEDL ActionQty QTY N ICADEDL SerialNumber SERIALNUMF N ICADEDS"},{"location":"integration/accpac/sdk-provider/#scrap_cost","title":"SCRAP_COST","text":"<p>Same as SCRAP but Adjustment Type set to COST - Adjustment Type: Decrease Cost</p>"},{"location":"integration/accpac/sdk-provider/#scrap_both","title":"SCRAP_BOTH","text":"<p>Same as SCRAP but Adjustment Type set to BOTH - Adjustment Type: Decrease Both</p>"},{"location":"integration/accpac/sdk-provider/#move","title":"MOVE","text":"<ul> <li>Granite Transaction: MOVE</li> <li>Accpac: I/C Transfers Type Transfer </li> <li>Supports: <ul> <li>RoundSummarizedActionQty (See setting description)</li> <li>RoundSummarizedActionQtyToDecimalPlaces (See setting description)</li> <li>Integration Reference</li> <li>Serial</li> <li>Lot</li> <li>Comment </li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves transfer</li> <li>True - Posts transfer</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM N ICTREH Create or update if exists, if empty follows Accpac sequence Document REFERENCE N ICTREH MasterItemCode ITEMNO Y ICTRED FromLocation FROMLOC Y ICTRED ToLocation TOLOC Y ICTRED Comment COMMENTS N ICTRED ActionQty QTYREQ Y ICTRED Batch LOTNUMF N ICTREDL ActionQty QTY N ICTREDL SerialNumber SERIALNUMF N ICTREDS"},{"location":"integration/accpac/sdk-provider/#replenish","title":"REPLENISH","text":"<ul> <li>Granite Transaction: REPLENISH</li> <li>Accpac: I/C Transfers Type Transfer </li> <li>Supports: <ul> <li>RoundSummarizedActionQty (See setting description)</li> <li>RoundSummarizedActionQtyToDecimalPlaces (See setting description)</li> <li>Integration Reference </li> <li>Serial</li> <li>Lot</li> <li>Comment </li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves transfer</li> <li>True - Posts transfer</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM N ICTREH Create or update if exists, if empty follows Accpac sequence Document REFERENCE N ICTREH MasterItemCode ITEMNO Y ICTRED FromLocation FROMLOC Y ICTRED ToLocation TOLOC Y ICTRED Comment COMMENTS N ICTRED ActionQty QTYREQ Y ICTRED Batch LOTNUMF N ICTREDL ActionQty QTY N ICTREDL SerialNumber SERIALNUMF N ICTREDS"},{"location":"integration/accpac/sdk-provider/#transfer","title":"TRANSFER","text":"<ul> <li>Granite Transaction: TRANSFER</li> <li>Accpac: **I/C Transfers **<ul> <li>Type: Transfer, Transit and Receipt, based on Granite document type.</li> </ul> </li> <li>Supports:<ul> <li>Serial</li> <li>LOT</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves transfer</li> <li>True - Posts transfer</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Document REFERENCE N ICTREH MasterItemCode ITEMNO Y ICTRED FromLocation FROMLOC Y ICTRED ToLocation TOLOC Y ICTRED ActionQty QTYREQ Y ICTRED Batch LOTNUMF N ICTREDL ActionQty QTY N ICTREDL SerialNumber SERIALNUMF N ICTREDS"},{"location":"integration/accpac/sdk-provider/#transferreceipt","title":"TRANSFERRECEIPT","text":"<ul> <li>Granite Transaction: TRANSFER</li> <li>Accpac: **I/C Transfers **<ul> <li>Type: Receipt</li> </ul> </li> <li>Supports:<ul> <li>Serial</li> <li>LOT</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Document REFERENCE N ICTREH MasterItemCode ITEMNO Y ICTRED FromLocation FROMLOC Y ICTRED ToLocation TOLOC Y ICTRED ActionQty QTYREQ Y ICTRED Batch LOTNUMF N ICTREDL ActionQty QTYMOVED N ICTREDL SerialNumber SERIALNUMF N ICTREDS"},{"location":"integration/accpac/sdk-provider/#dynamictransfer","title":"DYNAMICTRANSFER","text":"<ul> <li>Granite Transaction: DYNAMICTRANSFER</li> <li>Accpac: I/C Transfers Type Transfer </li> <li>Supports: <ul> <li>RoundSummarizedActionQty (See setting description)</li> <li>RoundSummarizedActionQtyToDecimalPlaces (See setting description)</li> <li>Integration Reference (Accpac Transfer number, create or update if exists) </li> <li>Serial</li> <li>Lot</li> <li>Comment (Accpac Comments field)</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves transfer</li> <li>True - Posts transfer</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM N ICTREH Create or update if exists, if empty follows Accpac sequence Document REFERENCE N ICTREH MasterItemCode ITEMNO Y ICTRED FromLocation FROMLOC Y ICTRED ToLocation TOLOC Y ICTRED Comment COMMENTS N ICTRED ActionQty QTYREQ Y ICTRED Batch LOTNUMF N ICTREDL ActionQty QTY N ICTREDL SerialNumber SERIALNUMF N ICTREDS"},{"location":"integration/accpac/sdk-provider/#pick","title":"PICK","text":"<p>Note</p> <p>IntegrationPost setting does not affect saving/invoicing for SalesOrder. Default Create Invoice option must be switched on/off in Accpac.</p> <ul> <li>Granite Transaction: PICK</li> <li>Accpac: O/E Transactions Order Entry</li> <li> <p>Supports:</p> <ul> <li>Serial</li> <li>Lot</li> </ul> </li> <li> <p>IntegrationPost:</p> <ul> <li>Not supported, see NOTE above</li> </ul> </li> <li>Returns:<ul> <li>LASTSHINUM if there is one, else LASTINVNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document ORDNUMBER Y OEORDH LineNumber LINENUM Y OEORDD Qty QTYSHIPPED Y OEORDD Lot LOTNUMF N OEORDDL Qty QTY N OEORDDL Serial SERIALNUMF N OEORDDS"},{"location":"integration/accpac/sdk-provider/#pickweight","title":"PICKWEIGHT","text":"<p>Note</p> <p>Weight of the item being picked in Granite must be in the Transaction Comment field. This will post to the EXTWEIGHT field in Accpac.</p> <ul> <li>Granite Transaction: PICK</li> <li>Accpac: O/E Transactions Order Entry</li> <li>Supports:<ul> <li>Comment (posts to Accpac EXTWEIGHT field)</li> </ul> </li> <li>IntegrationPost:<ul> <li>True - CREATEINV will be set to true</li> <li>False - CREATEINV will be set to false</li> </ul> </li> <li>Returns:<ul> <li>SHINUMBER if there is one, else LASTINVNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document ORDNUMBER Y OESHIH LineNumber ORDLINENUM Y OESHID ActionQty QTYSHIPPED Y OESHID Comment EXTWEIGHT Y OESHID"},{"location":"integration/accpac/sdk-provider/#dynamicpick","title":"DYNAMICPICK","text":"<ul> <li>Granite Transaction: PICKINGDYNAMIC</li> <li>Accpac: O/E Transactions Order Entry<ul> <li>Create and Post</li> </ul> </li> <li>Supports:<ul> <li>UOM</li> </ul> </li> <li>IntegrationPost:<ul> <li>Order will always be Processed regardless of setting</li> <li>True - Check Customer Credit Limit</li> </ul> </li> <li>Returns:<ul> <li>LASTSHINUM if there is one, else LASTINVNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document ORDNUMBER Y OEORDH FromLocation LOCATION Y OEORDH LineNumber LINENUM Y OEORDD ActionQty QTYORDERED Y OEORDD ActionQty QTYSHIPPED Y OEORDD Only applies if IntegrationPost is true UOM ORDUNIT N OEORDD"},{"location":"integration/accpac/sdk-provider/#receive","title":"RECEIVE","text":"<ul> <li>Granite Transaction: RECEIVE</li> <li>Accpac: P/O Transactions Purchase Order Entry</li> <li>Supports: <ul> <li>POExchangeRate (See setting description)</li> <li>PurchaseOrderOverrideLocation (See setting description)</li> <li>DocumentReference (posts to the REFERENCE field in Accpac)</li> <li>Lots with ExpiryDate</li> <li>Serials</li> <li>UOM</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always process receipt</li> </ul> </li> <li>Returns:<ul> <li>RCPNUMBER</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document PONUMBER Y PORCPH1 DocumentReference REFERENCE Y PORCPH1 UOM RCPUNIT Y PORCPL ActionQty RQRECEIVED Y PORCPL ToLocation LOCATION Y PORCPL Only applies if PurchaseOrderOverrideLocation is true MasterItemCode ITEMNO Y PORCPL Batch LOTNUMF N PORCPLL ExpiryDate EXPIRYDATE N PORCPLL ActionQty QTY N PORCPLL SerialNumber SERIALNUMF N PORCPLS"},{"location":"integration/accpac/sdk-provider/#receivingpostmultiple","title":"RECEIVINGPOSTMULTIPLE","text":"<p>Note</p> <p>The TransactionDocumentReference field is used to group all the Purchase Orders you would like to post as one receipt. The RECEIVINGPOSTMULTIPLE process should be used for posting. </p> <ul> <li>Granite Transaction: RECEIVE</li> <li>Accpac: P/O Transactions Purchase Order Entry</li> <li>Supports:<ul> <li>POExchangeRate (See setting description)</li> <li>PurchaseOrderOverrideLocation (See setting description)</li> <li>DocumentReference (posts to REFERENCE field in Accpac)</li> <li>Lots with ExpiryDate</li> <li>Serials</li> <li>UOM</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always process receipt</li> </ul> </li> <li>Returns:<ul> <li>RCPNUMBER</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document PONUMBER Y PORCPR DocumentReference REFERENCE Y PORCPH1 UOM RCPUNIT Y PORCPL ActionQty RQRECEIVED Y PORCPL ToLocation LOCATION Y PORCPL Only applies if PurchaseOrderOverrideLocation is true MasterItemCode ITEMNO Y PORCPL Batch LOTNUMF N PORCPLL ExpiryDate EXPIRYDATE N PORCPLL ActionQty QTY N PORCPLL SerialNumber SERIALNUMF N PORCPLS"},{"location":"integration/accpac/sdk-provider/#returnreceipt","title":"RETURNRECEIPT","text":"<p>Note</p> <p>Return document must be brought in to Granite as an ORDER document. We pick against it to reduce stock, and when we post we update the Return document's qtys.</p> <ul> <li>Granite Transaction: PICK</li> <li>Accpac: P/O Transactions Receipt Entry</li> <li>IntegrationPost:<ul> <li>Not supported, will always create return</li> </ul> </li> <li>Returns:<ul> <li>RETNUMBER</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document RCPNUMBER Y PORETH1 LineNumber RCPLSEQ Y PORETL ActionQty RQRETURNED Y PORETL"},{"location":"integration/accpac/sdk-provider/#manufacture","title":"MANUFACTURE","text":"<ul> <li>Granite Transaction: MANUFACTURE</li> <li>Accpac: I/C Transactions Assemblies</li> <li>Supports:<ul> <li>Comment</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Enters assembly</li> <li>True - Posts assembly</li> </ul> </li> <li>Returns:<ul> <li>Comma separated list of DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour MasterItemCode ITEMNO Y ICASEN Comment BOMNO Y ICASEN Must contain Accpac BOMNO FromLocation LOCATION Y ICASEN ActionQty QUANTITY Y ICASEN"},{"location":"integration/accpac/sdk-provider/#update_assemblies","title":"UPDATE_ASSEMBLIES","text":"<p>Note</p> <p>Granite document number must exist in Accpac as the Assembly number. If not found will throw error.</p> <ul> <li>Granite Transaction: MANUFACTURE</li> <li>Accpac: I/C Transactions Assemblies</li> <li>Supports:<ul> <li>Transaction IDs </li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Enters assembly</li> <li>True - Posts assembly</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document DOCNUM Y ICASEN MasterItemCode ITEMNO Y ICASEN ActionQty QUANTITY Y ICASEN Transaction ID REFERENCE Y ICASEN"},{"location":"integration/accpac/sdk-provider/#internalusage","title":"***INTERNALUSAGE","text":"<p>Note</p> <p>Can be used with multiple Granite Transaction Types (Adjsutment, Scrap etc.).  Granite Transactions must be linked to a document with a number matching the Accpac Internal Usage number</p> <ul> <li>Granite Process IntegrationMethod: INTERNALUSAGE</li> <li>Accpac: I/C Transactions Internal Usage. <ul> <li>Based on document, update internal usage</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves internal usage</li> <li>True - Posts internal usage</li> <li>GLACCT (GL Account), mapped to Granite Comment</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour Document DOCNUM Y ICICEH Must be the Accpac Internal Usage DOCNUM \"GRANITE WMS\" REFERENCE Y ICICEH MasterItemCode ITEMNO Y ICICED FromLocation LOCATION Y ICICED ActionQty QUANTITY Y ICICED Comment GLACCT N ICICED if comment not empty, this is the GL account"},{"location":"integration/accpac/sdk-provider/#internalusagedynamic","title":"***INTERNALUSAGEDYNAMIC","text":"<p>Note</p> <p>Can be used with multiple Granite Transaction Types, set the Process' IntegrationMethod to INTERNALUSAGEDYNAMIC to post. </p> <ul> <li>Granite Process IntegrationMethod: INTERNALUSAGEDYNAMIC</li> <li>Accpac: I/C Transactions Internal Usage</li> <li>Supports: <ul> <li>Integration Reference (Accpac Internal Usage Number)</li> <li>Lots</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Saves internal usage</li> <li>True - Posts internal usage</li> </ul> </li> <li>Returns:<ul> <li>DOCNUM</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table Behaviour IntegrationReference DOCNUM Y ICICEH Create or update if exists, if empty follows Accpac sequence \"GRANITE WMS\" REFERENCE Y ICICEH LineNumber LINENO Y ICICED ActionQty QUANTITY Y ICICED Batch LOTNUMF N ICICEDL ActionQty QTY N ICICEDL"},{"location":"integration/accpac/sdk-provider/#issue","title":"***ISSUE","text":"<p>Note</p> <p>Requires custom module (Pacific Technology Solutions' Internal Issues) Granite Document Description must be set to \"NormalPick\" to ensure that we post to an existing document in Accpac.  If this is not set, we still post to an existing document with matching Number when one is found - however if a matching document is not found we create it (DynamicIssue). Can be used with multiple Granite Transaction Types, set the Process' IntegrationMethod to ISSUE to post.  Granite Transactions must be linked to a document with a number matching the Accpac Internal Issue Number</p> <ul> <li>Granite Process IntegrationMethod: ISSUE</li> <li>Accpac: II Internal Issues Custom module (Pacific Technology Solutions' Internal Issues)</li> </ul>"},{"location":"integration/accpac/sdk-provider/#materialallocation","title":"***MATERIALALLOCATION","text":"<p>Note</p> <p>Granite Document Description must be set to CONTRACT/PROJECT/CATEGORY (in that order with slashes separating them).</p> <ul> <li>Granite Process IntegrationMethod: MATERIALALLOCATION</li> <li>Accpac: Project and Job Costing -&gt; PJC Transactions -&gt; Material Allocation</li> <li>IntegrationPost:<ul> <li>Not supported, will always create material allocation</li> </ul> </li> <li>Returns:<ul> <li>MALLOCNO</li> </ul> </li> </ul> Granite Accpac SDK Required Accpac Table \"GRANITE\" REFERENCE Y PMMTAH Document Description Contract FMTCONTNO Y PMMTAD Document Description Project PROJECT Y PMMTAD Document Description Category CATEGORY Y PMMTAD MasterItem Code RESOURCE Y PMMTAD ToLocation LOCATION Y PMMTAD ActionQty QUANTITY Y PMMTAD"},{"location":"integration/accpac/sdk-provider/#autosimply-10-oct-2023-under-construction","title":"AutoSimply (10 Oct 2023: under construction)","text":""},{"location":"integration/accpac/sdk-provider/#issuances","title":"Issuances","text":"<p>This method is used when you want to post the consumption of the work order seperate from the receipt  of the finish goods. It will post based on each CONSUME transaction.</p> <ul> <li>Granite Process IntegrationMethod: AUTOSIMPLY_ISSUANCES</li> <li>Accpac/AutoSimply: Manufacture -&gt; MF Transactions -&gt; Material Issuances -&gt; Issuances</li> <li>Support for: <ul> <li>Lots</li> </ul> </li> <li>Returns:<ul> <li>ISSUENO</li> </ul> </li> <li>Notes:</li> <li>Single MO (work order) per Issuances</li> <li>MO status released</li> </ul> Granite Accpac SDK Required Accpac Table Document Description ISSDESC N MFISSUH Document Number ToMO Y MFISSUH Document Number FromMO Y MFISSUH LineNumber DETAILNUM Y MFISSUD ActionQty ISSQTY Y MFISSUD ActionQty XGENALCQTY N MFISSUD"},{"location":"integration/accpac/sdk-provider/#receipts","title":"Receipts","text":"<p>This method is also used by Backflush. Perform an Receipt of finish goods based on the Granite Manufacture transactions for the WorkOrder. Prior to receipt typically the Issuances need to be done, or you need to perform a backflush as per below.</p> <ul> <li>Granite Process IntegrationMethod: AUTOSIMPLY_RECEIPTS</li> <li>Accpac/AutoSimply: Manufacture -&gt; MF Transactions -&gt; Material Receipt -&gt; Receipts</li> <li>Support for: <ul> <li>Lots</li> </ul> </li> </ul>"},{"location":"integration/accpac/sdk-provider/#backflush","title":"Backflush","text":"<p>Backflush will take the total based on manufactured transactions (finish goods) and will ask autosimply to \"automate\" the issuances. This method ignores Granite consume transactions.  The result will be both a Issuances and Receipt in one where only the Manufacture transactions of Granite is used.</p> <ul> <li>Granite Process IntegrationMethod: AUTOSIMPLY_BACKFLUSH</li> <li>Accpac/AutoSimply: Manufacture -&gt; MF Transactions -&gt; MO Backflush</li> </ul> Granite Accpac SDK Required Accpac Table Document Number ToMO Y MFISSUH Document Number FromMO Y MFISSUH ActionQty BaseQty Y MFISSUD"},{"location":"integration/acumatica/","title":"Acumatica","text":"<p>This document contains all of the information needed to set up and configure integration with Acumatica. There are two parts to the complete integration solution:</p> <ul> <li> <p>The SDK Provider is used by the Integration Service to map transactions performed in Granite to the relevant format for Acumatica.</p> </li> <li> <p>The integration jobs are used by the Scheduler to pull Acumatica's documents, item codes, and trading partners into Granite.</p> </li> </ul> <p>To get an overview of the Acumatica entities/objects that are used in integration see Acumatica Overview</p>"},{"location":"integration/acumatica/acumatica-overview/","title":"Acumatica Overview","text":"<p>The purpose of the this to provide of an overview of the parts of Acumatica's system that Granite interacts with in the upwards and downwards integration. </p>"},{"location":"integration/acumatica/acumatica-overview/#investigating-acumatica","title":"Investigating Acumatica","text":"<p>Acumatica has a useful feature that gives more detail on the details of the various fields in the system.  To use it, hover over the name of a field until the ? icon appears, select the icon and a description will appear on the right. </p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#stockitems","title":"StockItems","text":"<p>The StockItems are Acumatica's MasterItems. They can be found under Inventory &gt; Stock Items.</p> <p></p> <p>The most notable field is the Lot/Serial Class (this is only visible if Lot/Serial tracking is enabled). In Acumatica, Lot and Serial number share the same property call LotSerialNbr. This class determines if either lot, serial, or neither is tracked. </p> <p>Expiry date can only be tracked in the standard way if either lot or serial is tracked and cannot be tracked separately. </p>"},{"location":"integration/acumatica/acumatica-overview/#warehouses","title":"Warehouses","text":"<p>Warehouses in Acumatica represent a physical location where stock can be kept (a warehouse, a section of a warehouse, a store).</p> <p>The only relevant field for Granite is the WarehouseID which is the ERPLocation</p> <p>These are found under Inventory &gt; Warehouses.</p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#documents","title":"Documents","text":"<p>Documents follow a similar structure to Granite's documents with one main difference being Allocations. Allocations will only be visible if Lot/Serial Tracking is enabled.  The hierarchy is as follows: Document (Header) &gt; Details &gt; Allocations. Not all documents have Allocations. </p> <p>The header contains the info of the documents status, vendor/customer, and number.</p> <p>The Details contain the Inventory ID (MasterItem Code), Qty, and processed qty. </p> <p>The Allocations are seen under Line details and contain the serial numbers or lot numbers, Quantity, and expiry date if applicable. </p> <p> </p>"},{"location":"integration/acumatica/acumatica-overview/#document-types","title":"Document Types:","text":"<p>The following documents are used in the integration process:</p> <ul> <li>Purchase Orders</li> <li>Purchase Receipts</li> <li>Transfers</li> <li>Receipts</li> <li>Sales Orders</li> <li>Shipments</li> <li>Issues</li> </ul>"},{"location":"integration/acumatica/acumatica-overview/#purchase-orders","title":"Purchase Orders","text":"<p>Purchase orders are inbound documents and are brought into Granite as Receiving documents.  They do not have allocations (line details) as these are on the purchase receipt.</p> <p>These documents are not updated with directly with received quantities, rather, Purchase Receipts are created that specify the received quantities. </p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#purchase-receipts","title":"Purchase Receipts","text":"<p>Purchase receipts are associated with a Purchase order and represent what was actually received against the Purchase Order.  You can have multiple Purchase Receipts per Purchase order. </p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#transfers","title":"Transfers","text":"<p>Transfers are movements of goods between warehouses. </p> <p>There are 2 types of Transfers: 1-step and 2-step</p> <ul> <li>1-Step Transfers are the equivalent of Transfers in Granite. A difference to note is the the quantity on the document is the quantity that will be transferred when the document is marked as Released, there is no Action Qty. </li> </ul> <p></p> <ul> <li>2-Step Transfers are the equivalent of Intransit documents in Granite. Similar to the 1-Step, there is no Action Qty, the quantity on the document is the quantity that will be removed from the warehouse and marked as intransit when the document is marked as Released. </li> </ul> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#receipts","title":"Receipts","text":"<p>Receipts are transactions that bring stock into Acumatica. For the purpose of our we will only be using Receipts that are associated with a Transfer and have a TransferNbr in the header. These receipts are brought into Granite as Receipt documents.</p> <p>As with transfers, they do not have an Action Qty and the quantity will be the quantity that is received at the warehouse when the document is marked as Released. </p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#sales-orders","title":"Sales Orders","text":"<p>These are outbound documents and are brought into Granite as Order documents.  Like Purchase orders, they do not have allocations (Line details), these are on the Shipment. </p> <p>These documents are not updated directly with picked quantities. Instead, shipments are created against it that specify the quantities picked. </p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#shipments","title":"Shipments","text":"<p>Shipments are associated with a Sales order and represent the quantities picked.  There can only one open Shipment against per Sales order. Once a Shipment is Released, a new shipment can be created if back orders are allowed on the Sales Order. </p> <p></p>"},{"location":"integration/acumatica/acumatica-overview/#issues","title":"Issues","text":"<p>Inventory Issues are used to issue inventory from stock. Once issued it is removed from stock and no further record is kept for it. This is currently not associated with any Granite document or process but is an integration method that can be used. For details please see the Acumatica SDK-Provider</p> <p></p>"},{"location":"integration/acumatica/integration-jobs/","title":"Integration Jobs","text":"<p>Integration jobs are a special type of Scheduler job called injected jobs.  See below for information for specifics on how document and master data jobs work</p>"},{"location":"integration/acumatica/integration-jobs/#supported-document-types","title":"Supported document types","text":"<ul> <li> <p>ORDER</p> <p>Acumatica type: Sales Order</p> </li> <li> <p>RECEIVING</p> <p>Acumatica type: Purchase Order</p> </li> <li> <p>TRANSFER</p> <p>Acumatica type: Transfer (1-Step)</p> </li> <li> <p>INTRANSIT</p> <p>Acumatica type: Transfer (2-Step)</p> </li> <li> <p>RECEIPT</p> <p>Acumatica type: Receipt (with TransferNbr)</p> </li> </ul>"},{"location":"integration/acumatica/integration-jobs/#how-it-works","title":"How it works","text":""},{"location":"integration/acumatica/integration-jobs/#document-jobs","title":"Document Jobs","text":"<p>All data is currently fetched through Acumatica's ODataV4 endpoint. The ODataV4 endpoint allows us to construct queries on the underlying DAC (Data Access classes). ODataV4 does not uses Generic Inquiries and as such no custom views are needed in Acumatica.</p> <p>GraniteScheduler runs injected jobs that check the IntegrationDocumentQueue for the lastUpdated time for the relevant document type(if no lastUpdated time is found it will use current time - 24hours). With this last updated time, it will then do a OData request for all relevant documents that have a last updated time greater than the lastUpdated time from the IntegrationDocumentQueue. If there are any documents that fit those criteria they are inserted into the IntegrationDocumentQueue. The job then runs this queue.</p> <p>When a record with Status 'ENTERED' is found, the job uses a OData request to fetch the information related to that document from the Acumatica and apply the changes to the Granite document. </p> <p>All valid changes to data in the Granite tables are logged to the Audit table, showing the previous value and the new value.</p> <p>If a change is made in the ERP system that would put Granite into an invalid state, no changes are applied. Instead, the ERPSyncFailed field is set to true and the ERPSyncFailedReason field shows the reason for the failure. The IntegrationLog table will contain further details on the failure if applicable.</p>"},{"location":"integration/acumatica/integration-jobs/#document-statuses","title":"Document Statuses","text":"<p>For Sales Orders the statuses are mapped in the following way:</p> Acumatica Status Granite Status Back Order, Open ENTERED Expired, Canceled, Rejected CANCELLED On Hold, Credit Hold, Risk Hold, Pending Approval, Pending Processing ONHOLD Completed, Invoiced, Shipping COMPLETE <p>For Purchase Orders the statuses are mapped in the following way:</p> Acumatica Status Granite Status Open ENTERED Canceled, Rejected CANCELLED On hold, Pending Approval, Pending Email, Pending Printing ONHOLD Completed, Closed COMPLETED <p>For Transfers and Receipts the statuses are mapped in the following way:</p> Acumatica Status Granite Status Balanced ENTERED On hold ONHOLD Released COMPLETED"},{"location":"integration/acumatica/integration-jobs/#master-data-jobs","title":"Master data jobs","text":"<p>MasterItems and TradingPartners have their own Jobs. These Jobs fetch all StockItems, Vendors, and Customers from  Acumatica and compares them to the MasterItems and TradingPartners in Granite. Any inserts / updates are done as required. </p> <p>The document jobs also sync changes to the MasterItems that are on the document. This means that on sites that do not make many changes to their MasterItems it is better to limit running this job to once a day or even less frequently. </p> <p>Document Jobs do not automatically sync trading partners as they are not required to create to the document in Granite and as such are only synced when the TradingPartner Job runs. </p>"},{"location":"integration/acumatica/integration-jobs/#install","title":"Install","text":""},{"location":"integration/acumatica/integration-jobs/#set-up-database-triggers-views-and-data","title":"Set up database triggers, views, and data","text":"<p>Run the <code>AcumaticaIntegrationJobs_Create.sql</code> script to insert the required SystemSettings and ScheduledJob table entries needed.  You can then just activate the Scheduled Jobs that are needed. </p> <p>The system setting AcumaticaApplicationName is defaulted to 'Acumatica'. If you change this then you should also change it in the Integration service config file so that the scheduled Jobs amd Integration service can share settings. If you wish to use different SystemSettings for each then you need to specify a different value. </p>"},{"location":"integration/acumatica/integration-jobs/#systemsettings","title":"SystemSettings","text":""},{"location":"integration/acumatica/integration-jobs/#base-url","title":"Base URL","text":"<p>The base url can be found in IIS if hosted locally or provided by the customer if hosted in the cloud.</p> <p> </p> <p>Note</p> <p>You need to set the password from inside the Webdesktop if you are going to encrypt the password. </p>"},{"location":"integration/acumatica/integration-jobs/#acumaticaintansitlocation","title":"AcumaticaIntansitLocation","text":"<p>Acumatica does not specify a intransit location on its 2-step transfers so it needs to be specified in this system setting. This is the ERP location for the location used in Intransit documents. </p> <p> </p>"},{"location":"integration/acumatica/integration-jobs/#add-the-injected-job-files-to-granitescheduler","title":"Add the Injected job files to GraniteScheduler","text":"<p>To add the injected job files to the GraniteScheduler, simply copy the dlls and xml files into the root folder of GraniteScheduler. </p>"},{"location":"integration/acumatica/integration-jobs/#configure","title":"Configure","text":""},{"location":"integration/acumatica/integration-jobs/#schedule-configuration","title":"Schedule configuration","text":"<p>See the GraniteScheduler manual for the details on how to configure injected jobs. Most of the work will have already been done for you by the <code>AcumaticaIntegrationJobs_Create.sql</code> script, you can simply activate the jobs you want to run.</p>"},{"location":"integration/acumatica/integration-jobs/#email-on-error","title":"Email on Error","text":"<p>Note</p> <p>Emailing functionality is now handled by the Utility API, set up has changed from previous versions.</p> <p>Ensure that you have configured the UtilityApi for the Acumatica injected jobs in the <code>SystemSettings</code> table:</p> Application Key Value GraniteScheduler UtilityApiUrl https://localhost:5001/ <p>Ensure you have the <code>IntegrationError</code> email template in your database. This is the email template that is used for all error notifications in these injected jobs. </p> <p>Then for each job that needs to send failure notifications, add a job input for <code>MailOnError</code> and <code>MailOnErrorToAddresses</code>:</p> JobName Name Value &lt; JobName goes here &gt; MailOnError true &lt; JobName goes here &gt; MailOnErrorToAddresses name@client.co.za;name2@client.co.za"},{"location":"integration/acumatica/sdk-provider/","title":"SDK Provider","text":"<p>The Acumatica SDK provider is responsible for mapping Granite Transactions to the relevant format for posting to Acumatica. It makes use of the Acumatica REST API.</p>"},{"location":"integration/acumatica/sdk-provider/#how-it-connects","title":"How it connects","text":"<p>The upwards integration achieved using Acumatica's rest API. For more details on the Acumatica object's used in integration please consult the Acumatica Overview. </p>"},{"location":"integration/acumatica/sdk-provider/#setup","title":"Setup","text":"<ol> <li> <p>Copy everything in the <code>Providers\\Acumatica</code> folder into Integration Service folder (root folder).</p> </li> <li> <p>Ensure <code>SDKProvider.xml</code> setup or copied correctly     <pre><code>&lt;module name=\"Provider\"&gt;\n&lt;bind\n    service=\"Granite.Integration.Contract.IProvider, Granite.Integration.Contract\"\n    to=\"Granite.Integration.Acumatica.Provider, Granite.Integration.Acumatica\"/&gt;\n&lt;/module&gt;\n</code></pre></p> </li> <li> <p>Configure your connection string and endpoint in the <code>Granite.Integration.Web.exe.config</code> file</p> </li> </ol>"},{"location":"integration/acumatica/sdk-provider/#settings","title":"Settings","text":"<p>Note</p> <p>To pick up any changes to the SystemSettings table, the IntegrationService will need to be restarted. </p> <p>The settings for Acumatica are configured in the SystemSettings table. The IntegrationService will pick up the settings using the Application name specified in it's <code>.config</code> file: If this setting is missing from the config file or left empty, the IntegrationService will default to using <code>Acumatica</code> as the SystemSettingsApplicationName. You can browse the IntegrationService's <code>/config</code> page to have the IntegrationService create the default settings in the SystemSettings table for you. </p>"},{"location":"integration/acumatica/sdk-provider/#config-file-settings","title":"Config File Settings","text":"<pre><code>    &lt;add key=\"SystemSettingsApplicationName\" value=\"Acumatica\" /&gt;\n    &lt;add key=\"EndPoint\" value=\"http://:40091/\" /&gt;\n</code></pre>"},{"location":"integration/acumatica/sdk-provider/#systemsettingsapplicationname","title":"SystemSettingsApplicationName","text":"<p>The Application name of the entries in the SystemSettings table that you want to use for this integration service. If this setting is the same as Application name for the ScheduledJobs they can use the same SystemSettings.</p> <p>This setting allows you to have multiple integration services running with different settings.</p>"},{"location":"integration/acumatica/sdk-provider/#acumatica-settings","title":"Acumatica Settings","text":""},{"location":"integration/acumatica/sdk-provider/#lotserial-tracking","title":"Lot/Serial Tracking","text":"<p>For Granite to be able to post Serial Numbers or Batch back to Acumatica the feature in System Management &gt; Enable/Disable Features &gt; Lot and Serial Tracking needs to be turned on. </p> <p>After that a Lot/Serial class must be created and assigned to all Item Classes that require Lot/Serial tracking. </p> <p>If this is not done, acumatica will discard any Lot\\Serial information sent as part of the request. </p>"},{"location":"integration/acumatica/sdk-provider/#control-quantity","title":"Control Quantity","text":"<p>Acumatica has a feature that requires the user to validate the document quantity before changing the document status.  This needs to be disabled in order from Granite to post documents into the system. </p> <p>The setting needs to be disabled in the following places (if Granite is integrating these documents):</p> <ul> <li>Sales Order Preferences &gt; Validate Shipment Total on Confirmation</li> <li>Inventory Preferences &gt; Validate Document Totals on Entry</li> </ul>"},{"location":"integration/acumatica/sdk-provider/#integration-methods","title":"Integration Methods","text":"<p>By default if the method names below is the same as a Granite Transaction type, it will autowire the integration.  If you require a different integration action you can specify the name below in the Process IntegrationMethod property. </p>"},{"location":"integration/acumatica/sdk-provider/#adjustment","title":"ADJUSTMENT","text":"<ul> <li>Granite Transaction: ADJUSTMENT</li> <li>Acumatica: INVENTORY ADJUSTMENT</li> <li>Supports:<ul> <li>Lot</li> <li>Serial</li> </ul> </li> <li>Integration Post<ul> <li>False - Creates a new Inventory Adjustment with status Balanced</li> <li>True - Creates a new Inventory Adjustment and performs the Release action to change the Status to Released</li> </ul> </li> <li>Returns:     Reference Number </li> </ul> Granite Acumatica Entity Required Behavior Code InventoryID Y Qty Qty Y FromLocation WarehouseID Y UOM UOM Y Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#scrap","title":"SCRAP","text":"<ul> <li>Granite Transaction: SCRAP</li> <li>Acumatica: INVENTORY ADJUSTMENT</li> <li>Supports:<ul> <li>Lot</li> <li>Serial</li> </ul> </li> <li>Integration Post<ul> <li>False - Creates a new Inventory Adjustment with status Balanced</li> <li>True - Creates a new Inventory Adjustment and performs the Release action to change the Status to Released</li> </ul> </li> <li>Returns:     Reference Number </li> </ul> Granite Acumatica Entity Required Behavior Code InventoryID Y Qty Qty Y FromLocation WarehouseID Y UOM UOM Y Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#movereplenish","title":"MOVE/REPLENISH","text":"<p>MOVE and REPLENISH create the same transaction in Acumatica. They both share a transaction type in Acumatica with Transfers. To prevent them being brought into Granite as transfers the external reference populated with Granite Move or Granite Replenish as you can see below.</p> <p></p> <ul> <li>Granite Transaction: MOVE/REPLENISH</li> <li>Acumatica: TransferOrder</li> <li>Supports:<ul> <li>Serial</li> <li>Lot</li> </ul> </li> <li> <p>Return</p> <ul> <li>Transfer Number</li> </ul> </li> <li> <p>Integration Post</p> <ul> <li>False - Creates a 1-Step Transfer in Acumatica with status Balanced. </li> <li>True - Changes the status of the transfer from Balanced to Released</li> </ul> </li> <li>Returns:     TransferNumber</li> </ul> Granite Acumatica Entity Required Behavior Code InventoryID Y Qty Qty Y FromLocation WarehouseID Y ToLocation ToWarehouseID Y UOM UOM Y Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#takeon","title":"TAKEON","text":"<p>TAKEON uses the same transaction type in Acumatica as Transfer receipts. To prevent takeon receipts from being pulled into Granite as Transfer receipts the Description is populated with \"Granite Takeon\".  The scheduled job will then exclude there from being integrated.</p> <p></p> <ul> <li>Granite Transaction: TAKEON</li> <li>Acumatica: Inventory Receipt</li> <li>Supports:<ul> <li>Serial</li> <li>Lot</li> </ul> </li> <li>Integration Post<ul> <li>False - Creates a Inventory Receipt in Acumatica with status Balanced</li> <li>True - Changes the status of the Inventory Receipt to from Balanced to Released</li> </ul> </li> <li>Return<ul> <li>Inventory Receipt Number</li> </ul> </li> </ul> Granite Acumatica Entity Required Behavior Code InventoryID Y Qty Qty Y ToLocation WarehouseID Y UOM UOM Y Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#reclassify","title":"RECLASSIFY","text":"<p>This process first performs as Adjustment decreasing the stock and then a receipt of the new stock.</p> <ul> <li>Granite Transaction: RECLASSIFY</li> <li>Acumatica: Adjustment =&gt; Receipt</li> <li>Supports:<ul> <li>Serial</li> <li>Lot</li> </ul> </li> <li>Integration Post<ul> <li>False - Creates an Adjustment and Inventory Receipt in Acumatica with status Balanced</li> <li>True - Creates an Adjustment and Inventory Receipt and performs the Release action to change the Status to Released</li> </ul> </li> <li>Returns:     Receipt Number</li> </ul> Granite Acumatica Entity Required Behavior FromCode InventoryID Y ToCode InventoryID Y Qty Qty Y FromLocation WarehouseID Y ToLocation WarehouseID Y UOM UOM Y Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#issue","title":"ISSUE","text":"<p>This process issues inventory from stock. After this point it is no longer tracked in Acumatica. This can be seen as a pick but not against a document.  It is not mapped to any specific Granite transaction type. If you have a requirement you will need to specify it as the integration method on the relevant process as you can see below. </p> <p></p> <ul> <li>Granite Transaction: NONE</li> <li>Acumatica: ISSUE</li> <li> <p>Supports:</p> <ul> <li>Lot</li> <li>Serial</li> </ul> </li> <li> <p>Integration Post</p> <ul> <li>False - Creates a new Issue with the status Balanced</li> <li>True - Creates a new Issue and performs the Release action to change the status from balanced to Released</li> </ul> </li> </ul> <p>-Returns      Issue Number</p> Granite Acumatica Entity Required Behavior Code InventoryID Y Qty ShippedQty Y FromLocation WarehouseID Y Lot LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#pick","title":"PICK","text":"<ul> <li>Granite Transaction: PICK</li> <li>Acumatica: CREATE SHIPMENT</li> <li> <p>Supports:</p> <ul> <li>Lot</li> <li>Serial</li> </ul> </li> <li> <p>Integration Post</p> <ul> <li>False - Creates a new Shipment with the status Balanced</li> <li>True - Creates a new shipment and performs the Release action to change the Status to Released</li> </ul> </li> <li> <p>Returns:     Shipment Number</p> </li> </ul> Granite Acumatica Entity Required Behavior Document OrderNumber Y LineNumber Y Qty ShippedQty Y DocumentTradingPartnerCode CustomerID Y FromLocation WarehouseID Y Lot LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#receive","title":"RECEIVE","text":"<ul> <li>Granite Transaction: RECEIVE</li> <li>Acumatica: CREATE PURCHASE RECEIPT</li> <li> <p>Supports:</p> <ul> <li>Lot</li> <li>Serial</li> </ul> </li> <li> <p>Integration Post</p> <ul> <li>False - Creates a new Purchase Order Receipt with the status Balanced</li> <li>True - Creates a new Purchase Order Receipt and performs the Release action to change the Status to Released. </li> </ul> </li> <li>Returns:     Purchase Order Receipt Number</li> </ul> Granite Acumatica Entity Required Behavior Document POOrderNumber Y LineNumber Y Qty ReceiptQty Y DocumentTradingPartnerCode VendorID Y TLocation WarehouseID Y Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/acumatica/sdk-provider/#transfer","title":"TRANSFER","text":"<p>Note</p> <p>Acumatica does not have separate fields on Transfers and Receipts for Qty vs ActionQty. As such, the current behavior is to only accept completed lines where the Qty and ActionQty in Granite are equal and therefore match the value in Acumatica.</p> <ul> <li>Granite Transaction: TRANSFER</li> <li>Acumatica: TransferOrder</li> <li>Supports:<ul> <li>Serial</li> <li>Lot</li> </ul> </li> <li> <p>Return</p> <ul> <li>Transfer Number</li> </ul> </li> <li> <p>Integration Post</p> <ul> <li>False - Changes the status of the transfer/receipt from On Hold to Balanced. </li> <li>True - Changes the status of the transfer/receipt from On Hold to Released</li> </ul> </li> <li>Returns:     Transfer/Receipt Number</li> </ul> Granite Acumatica Entity Required Behavior Document TransferOrder/InventoryReceipt Y LineNumber Y Qty Y Compares qty to acumatica document qty Batch LotSerialNbr N Serial LotSerialNbr N ExpirationDate ExpiryDate N"},{"location":"integration/evo/","title":"Evolution","text":"<p>This document contains all of the information needed to set up and configure integration with Evolution. There are two parts to the complete integration solution:</p> <p>The SDK Provider is used by the Integration Service to map transactions performed in Granite to the relevant format for Evolution.</p> <p>The integration jobs are used by the Scheduler to pull Evolution's documents, item codes, and trading partners into Granite.</p>"},{"location":"integration/evo/integration-jobs/","title":"Integration Jobs","text":"<p>Integration jobs are a special type of Scheduler job called injected jobs.  See below for information for specifics on how document and master data jobs work</p>"},{"location":"integration/evo/integration-jobs/#supported-document-types","title":"Supported document types","text":"<ul> <li> <p>ORDER </p> <p>Evolution type: Sales Order</p> </li> <li> <p>RECEIVING</p> <p>Evolution type: Purchase Order</p> </li> <li> <p>INTRANSIT </p> <p>Evolution type: Inter Branch Transfer OR Inter Branch Requisition</p> </li> <li> <p>RECEIPT</p> <p>Evolution type: Inter Branch Receipt</p> </li> <li> <p>TRANSFER</p> <p>Evolution type: Warehouse Transfer</p> </li> <li> <p>WORKORDER</p> <p>Evolution type: Manufacture Process</p> </li> </ul>"},{"location":"integration/evo/integration-jobs/#how-it-works","title":"How it works","text":""},{"location":"integration/evo/integration-jobs/#document-jobs","title":"Document Jobs","text":"<p>Triggers on the ERP document tables insert a record into the Granite IntegrationDocumentQueue table whenever a change is applied to a document. </p> <p>Scheduler runs injected jobs that monitor the IntegrationDocumentQueue table for records that need to be processed.</p> <p>When a record with Status 'ENTERED' is found, the job uses views on the Granite database to fetch the  information related to that document from the ERP database and apply the changes to the Granite document. </p> <p>All valid changes to data in the Granite tables are logged to the Audit table, showing the previous value and the new value.</p> <p>If a change is made in the ERP system that would put Granite into an invalid state, no changes are applied. Instead, the ERPSyncFailed field is set to true and the ERPSyncFailedReason field shows the reason for the failure. The IntegrationLog table will contain futher details on the failure if applicable.</p>"},{"location":"integration/evo/integration-jobs/#master-data-jobs","title":"Master data jobs","text":"<p>MasterItems and TradingPartners have their own jobs. These jobs compare the results of their respective views to the data in the Granite tables and insert new records / update records as needed.</p> <p>The document jobs themselves also sync changes to the TradingPartners &amp; MasterItems that are on the document. This means that on sites that do not process a lot of changes to master data you can limit the MasterItem/TradingPartner jobs to running once a day or even less frequently.  The only thing they are really still needed for is setting isActive to false when something is deactivated in the ERP system.</p>"},{"location":"integration/evo/integration-jobs/#install","title":"Install","text":"<p>Note</p> <p>If you are upgrading from the old StoredProcedure/Trigger integration, ensure that ERPIdentification (Document, DocumentDetail, MasterItem, TradingPartner) column is populated with correct values before attempting to start the new jobs</p>"},{"location":"integration/evo/integration-jobs/#set-up-database-triggers-views","title":"Set up database triggers &amp; views","text":"<p>Run the create scripts for the views and triggers that you will need for the version of ERP &amp; document types that the site uses.</p> <p>All document types also require the Integration_ERP_MasterItem view.</p>"},{"location":"integration/evo/integration-jobs/#add-the-injected-job-files-to-granitescheduler","title":"Add the Injected job files to GraniteScheduler","text":"<p>To add the injected job files to the GraniteScheduler, simply copy the dlls and xml files into the root folder of GraniteScheduler. </p> <p>Example:</p> <p></p>"},{"location":"integration/evo/integration-jobs/#configure","title":"Configure","text":""},{"location":"integration/evo/integration-jobs/#schedule-configuration","title":"Schedule configuration","text":"<p>See the GraniteScheduler manual for the basics on how to configure injected jobs.</p> <p>Sometimes when the documents in Evo are very large, the lines will not be finished inserting before we start fetching the records to create in Granite. To circumvent this issue, we have a setting that allows you to configure an offset for the <code>LastUpdateDateTime</code> field in the <code>IntegrationDocumentQueue</code> table.</p> <p>To configure this you simply add an entry into the <code>ScheduledJobInputs</code> table with the Name <code>LastUpdateTimeOffset</code> and the Value in minutes that you want to offset by</p> JobName Name Value SalesOrderJob LastUpdateTimeOffset 5 <p>Using this example, the SalesOrderJob will only pick up documents that have been sitting in the IntegrationDocumentQueue for longer than 5 minutes at the time the job runs. This should give Evo the time it needs to insert all of the lines on a very large document. </p>"},{"location":"integration/evo/integration-jobs/#email-on-error","title":"Email on Error","text":"<p>Note</p> <p>Emailing functionality is now handled by the Utility API, set up has changed from previous versions.</p> <p>Ensure that you have configured the UtilityApi for the Evo injected jobs in the <code>SystemSettings</code> table:</p> Application Key Value Granite.Integration.Evo.Job UtilityApi https://localhost:5001/ <p>Ensure you have the <code>IntegrationError</code> email template in your database. This is the email template that is used for all error notifications in these injected jobs. </p> <p>Then for each job that needs to send failure notifications, add a job input for <code>MailOnError</code> and <code>MailOnErrorToAddresses</code>:</p> JobName Name Value &lt; JobName goes here &gt; MailOnError true &lt; JobName goes here &gt; MailOnErrorToAddresses name@client.co.za;name2@client.co.za"},{"location":"integration/evo/integration-jobs/#view-customisation","title":"View customisation","text":"<p>Each view can be customised to include custom logic or map extra fields to fields on the corresponding Granite table. </p> <p>All of the standard fields on Granite tables are supported, simply add the required field to your view with an alias matching the Granite field name on the table the view maps to.</p> <p>Non standard fields are also supported, but for these to work your column name on the destination table must start with 'Custom'. On the view, simply alias the name of the field to match the name of the field on the destination Granite table, including the 'Custom' prefix.</p> <p>For fields like Document.Status where you may have custom rules / statuses, use a CASE statement in your view definition so that the view returns the Status that you want to set on the Granite Document table.</p> <p>It is highly advised that you check the validity of yor job on the GraniteScheduler /config page after making a change to your view! Especially after changing filter criteria/joins, your view may be returning duplicate rows - the job validation will bring this to your attention.</p>"},{"location":"integration/evo/integration-jobs/#whats-different-about-evolution-jobs","title":"What's different about Evolution jobs","text":""},{"location":"integration/evo/integration-jobs/#single-line-per-masteritem-for-intransit-receipt-and-transfer","title":"Single line per MasterItem for INTRANSIT, RECEIPT, and TRANSFER","text":"<p>Because of the way that these documents are stored and managed on the Evolution database, we can only handle a single line per MasterItem on transfer documents. If a document of one of these types contains multiple lines for a MasterItem, the document insert/update will fail setting the ERPSyncFailedReason accordingly. </p>"},{"location":"integration/evo/integration-jobs/#salesorders-and-purchaseorders-line-mapping","title":"SalesOrders and PurchaseOrders line mapping","text":"<p>Because Evolution stores multiple copies of SalesOrders and PurchaseOrders when changes are made or the document changes status, there is special logic implemented to find the correct versions of lines on the Evolution database. It is calculated using the idInvoiceLines (DocumentDetail ERPIdentification) and the iOrigLineID field. For that reason, the SalesOrderDetail and PurchaseOrderDetail views MUST include all rows from the _btblInvoiceLines table for any given document. These views must not modify the values in ERPIdentification or iOrigLineID for any reason.</p>"},{"location":"integration/evo/integration-jobs/#changing-masteritem-codes","title":"Changing MasterItem codes","text":"<p>If Rename Item Code is used in Evolution to change an Item Code, we will update the MasterItem in Granite to match, thereby updating all of the TrackingEntities and Transactions to the new Code as well. </p> <p>We will not update the MasterItem in Granite if a new Item Code is created in Evolution and Global Item Change is used to change Evolution stock over to the new Item Code. In this case the new Item Code will be added to Granite, but all TrackingEntities will need to be reclassified to the new MasterItem.</p>"},{"location":"integration/evo/integration-jobs/#things-to-look-out-for","title":"Things to look out for","text":""},{"location":"integration/evo/integration-jobs/#importance-of-erpidentification","title":"Importance of ERPIdentification","text":"<p>The injected jobs use the ERPIdentification column on the Document, DocumentDetail and MasterItem tables to look for matching records in the corresponding view. It is very important that you ensure that these values are populated for all records in Granite if you are upgrading from the old Document stored procedures.</p>"},{"location":"integration/evo/integration-jobs/#validation","title":"Validation","text":"<p>Each job type has it's own validation criteria that must be passed before the job will execute. You can check the validity of injected jobs on the GraniteScheduler /config page. </p> <p>Here is an example of some failed validation:</p> <p></p>"},{"location":"integration/evo/sdk-provider/","title":"SDK Provider","text":"<p>The Evolution SDK provider is responsible for mapping Granite transactions to the relevant format for posting to Evolution. It makes use of the Evolution SDK in order to post.</p>"},{"location":"integration/evo/sdk-provider/#setup","title":"Setup","text":"<ol> <li> <p>Check the version of the Evolution SDK that is currently installed on the server. The SDK is usually found at <code>C:\\Program Files (x86)\\Sage Evolution</code>. Take note of the first two numbers of <code>Pastel.Evolution.dll</code> file version.</p> <p>Note</p> <p>If the SDK is not yet installed, please engage with the client's Evolution consultant - the SDK is required for Granite integration.</p> </li> <li> <p>In the <code>Providers\\Evo</code> folder, find the <code>EvoX.Y</code> folder matching the installed SDK version. <code>X.Y</code> must match the first two numbers of the installed SDK version. For example, if the installed SDK version is 7.20.0.14, you will take the files from the Evo7.20 folder</p> </li> <li> <p>Copy everything in the <code>Providers\\Evo\\EvoX.Y</code> folder into Integration Service folder (root folder).</p> </li> <li> <p>Ensure <code>SDKProvider.xml</code> setup or copied correctly     <pre><code>&lt;module name=\"Provider\"&gt;\n&lt;bind\n    service=\"Granite.Integration.Contract.IProvider, Granite.Integration.Contract\"\n    to=\"Granite.Integration.PastelEvo.Provider, Granite.Integration.PastelEvo\"/&gt;\n&lt;/module&gt;\n</code></pre></p> </li> <li> <p>Configure your connection string and endpoint in the <code>Granite.Integration.Web.exe.config</code> file</p> </li> </ol>"},{"location":"integration/evo/sdk-provider/#settings","title":"Settings","text":""},{"location":"integration/evo/sdk-provider/#config-file","title":"Config File","text":"<p>The settings for Sage 200 (Evo) are configured in the SystemSettings table. The IntegrationService will pick up the settings using the Application name specified in it's <code>.config</code> file: <pre><code>&lt;add key =\"SystemSettingsApplicationName\" value=\"IntegrationSage200\"/&gt;\n</code></pre> If this setting is missing from the config file or left empty, the IntegrationService will default to using <code>IntegrationSage200</code> as the SystemSettingsApplicationName</p> <p>You can browse the IntegrationService's <code>/config</code> page to have the IntegrationService create the default settings in the SystemSettings table for you.</p> <p>The script to insert the default settings is also located in the GraniteDatabase release: <pre><code>~\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingsEvolution.sql\n</code></pre></p> <p>Note</p> <p>To pick up any changes to the SystemSettings table, the IntegrationService will need to be restarted.</p>"},{"location":"integration/evo/sdk-provider/#database-systemsettings","title":"Database SystemSettings","text":"Application Key Value Description IntegrationSage200 EvoSqlServer Evo database''s SqlServer instance IntegrationSage200 EvoDatabase Evo database name IntegrationSage200 EvoSqlUserName Sql user for Evo database IntegrationSage200 EvoSqlPassword Sql password for Evo database IntegrationSage200 EvoCommonSqlServer Evo Common database''s SqlServer instance IntegrationSage200 EvoCommonSqlUserName Sql user for Evo Common database IntegrationSage200 EvoCommonSqlPassword Sql password for Evo Common database IntegrationSage200 EvoCommonDatabase Evo Common database name IntegrationSage200 EvoSDKSerialNumber DE09110172 Evo SDK Serial number. Alternate value DE09110060 IntegrationSage200 EvoSDKAuthKey 1228187 Evo SDK auth key. Alternate value 4929466 IntegrationSage200 EvoBreakApartActive false IntegrationSage200 EvoBranchContextActive false IntegrationSage200 EvoBranchUseLocation false IntegrationSage200 EvoTransactionCodeGoodsReceiveVoucher RC IntegrationSage200 EvoTransactionCodeAdjustments ADJ IntegrationSage200 EvoTransactionCodeReclassifyAdjustments ADJ IntegrationSage200 EvoTransactionCodeIssue IIS IntegrationSage200 EvoTransactionCodeProjectsIssue IIS IntegrationSage200 EvoTransactionCodeMove WHT IntegrationSage200 EvoTransactionCodeTransfer WHT IntegrationSage200 EvoManufactureActive false IntegrationSage200 EvoManufactureCodes 2 List of comma separated codes <p>Note</p> <p>in most cases the Data and Common Pastel EVO database is on the same SQL instance and settings will be the same.</p>"},{"location":"integration/evo/sdk-provider/#evosqlserver","title":"EvoSqlServer","text":"<ul> <li>SQL server instance name</li> </ul>"},{"location":"integration/evo/sdk-provider/#evodatabase","title":"EvoDatabase","text":"<ul> <li>Pastel EVO database name</li> </ul>"},{"location":"integration/evo/sdk-provider/#evosqlusername","title":"EvoSqlUserName","text":"<ul> <li>SQL server username</li> </ul>"},{"location":"integration/evo/sdk-provider/#evosqlpassword","title":"EvoSqlPassword","text":"<ul> <li>SQL server password</li> </ul>"},{"location":"integration/evo/sdk-provider/#evocommonsqlserver","title":"EvoCommonSqlServer","text":"<ul> <li>SQL server instance name for common database</li> </ul>"},{"location":"integration/evo/sdk-provider/#evocommondatabase","title":"EvoCommonDatabase","text":"<ul> <li>Pastel EVO common database name</li> </ul>"},{"location":"integration/evo/sdk-provider/#evocommonsqlusername","title":"EvoCommonSqlUserName","text":"<ul> <li>SQL server username for common database</li> </ul>"},{"location":"integration/evo/sdk-provider/#evocommonsqlpassword","title":"EvoCommonSqlPassword","text":"<ul> <li>SQL server password for common database</li> </ul>"},{"location":"integration/evo/sdk-provider/#evosdkserialnumber","title":"EvoSDKSerialNumber","text":"<ul> <li>SDK serial number</li> </ul>"},{"location":"integration/evo/sdk-provider/#evosdkauthkey","title":"EvoSDKAuthKey","text":"<ul> <li>SDK Auth key</li> </ul>"},{"location":"integration/evo/sdk-provider/#evobreakapartactive","title":"EvoBreakApartActive","text":"<ul> <li>Options: true / false</li> <li>Used by: SCRAP</li> <li>When active validate the Batch against the EvoManufactureCodes (appsetting)</li> </ul>"},{"location":"integration/evo/sdk-provider/#evomanufactureactive","title":"EvoManufactureActive","text":"<ul> <li>Options: true / false</li> <li>Used by: TAKEON</li> <li>Workings: When active verify against EvoManufactureCodes (app setting) if valid perform custom Manufacture (MANUFACTURE post).</li> </ul>"},{"location":"integration/evo/sdk-provider/#evomanufacturecodes","title":"EvoManufactureCodes","text":"<ul> <li>Options: comma separated codes. Example : 3214, 3431, 9876</li> <li>Used by: EvoManufactureActive (TAKEON, SCRAP)</li> </ul>"},{"location":"integration/evo/sdk-provider/#evobranchcontextactive","title":"EvoBranchContextActive","text":"<ul> <li>Options: true / false</li> <li>Used by: Application level</li> <li>When active set branch. Branch based on Pastel item OR EvoBranchUseLocation setting.</li> <li>EvoBranchUseLocation: see setting.</li> </ul>"},{"location":"integration/evo/sdk-provider/#evobranchuselocation","title":"EvoBranchUseLocation","text":"<ul> <li>Options: true / false</li> <li>Used by: EvoBranchContextActive</li> <li>When active use Granite site on transaction as branch ID.</li> </ul>"},{"location":"integration/evo/sdk-provider/#evotransactioncodegoodsreceivevoucher","title":"EvoTransactionCodeGoodsReceiveVoucher","text":"<ul> <li>Options: string value representing GoodsReceive Voucher code</li> <li>Used by: TAKEON Inventory transaction code </li> </ul>"},{"location":"integration/evo/sdk-provider/#evotransactioncodeadjustments","title":"EvoTransactionCodeAdjustments","text":"<ul> <li>Options: string value representing transaction inventory code</li> <li>Used by: ADJUSTMENT Inventory transaction code </li> </ul>"},{"location":"integration/evo/sdk-provider/#evotransactioncodereclassifyadjustments","title":"EvoTransactionCodeReclassifyAdjustments","text":"<ul> <li>Options: string value representing transaction inventory code</li> <li>Used by: RECLASSIFY Inventory transaction code </li> </ul>"},{"location":"integration/evo/sdk-provider/#evotransactioncodemove","title":"EvoTransactionCodeMove","text":"<ul> <li>Options: string value representing transaction inventory code</li> <li>Used by: MOVE Inventory transaction code </li> </ul>"},{"location":"integration/evo/sdk-provider/#evotransactioncodetransfer","title":"EvoTransactionCodeTransfer","text":"<ul> <li>Options: string value representing transaction inventory code</li> <li>Used by: TRANSFER Inventory transaction code </li> </ul>"},{"location":"integration/evo/sdk-provider/#evotransactioncodeissue","title":"EvoTransactionCodeIssue","text":"<ul> <li>Options: string value representing transaction inventory code</li> <li>Used by: ISSUE Inventory transaction code </li> </ul>"},{"location":"integration/evo/sdk-provider/#integration-methods","title":"Integration Methods","text":"<p>By default if the method name below is the same as a Granite Transaction type, it will autowire the integration. If you require a different integration action you can specify the name below in the Process IntegrationMethod property.</p>"},{"location":"integration/evo/sdk-provider/#takeon","title":"TAKEON","text":"<p>Note</p> <p>If setting EvoManufactureActive is true and part of the batch of the item taken on is specified in setting EvoManufactureCodes, the item is posted using MANUFACTURE method</p> <ul> <li>Granite: Transaction type TAKEON </li> <li>Evolution: InventoryTransaction RC</li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post InventoryTransaction </li> </ul> </li> <li>Pre-post validation:<ul> <li>ActionQty is greater than 0</li> </ul> </li> <li>Returns:<ul> <li>InventoryTransaction.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code InventoryTransaction.InventoryItem Y ToSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch Batch InventoryTransaction.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate InventoryTransaction.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber InventoryTransaction.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo ToLocation InventoryTransaction.Warehouse Y If ToLocation is empty, uses FromLocation ActionQty InventoryTransaction.Quantity Y Transaction ID InventoryTransaction.Reference Y Prefixed with \"GRANITE ID: \" Comment InventoryTransaction.Reference2 N If Comment is empty, will be set to \"Granite TakeOn\""},{"location":"integration/evo/sdk-provider/#adjustment","title":"ADJUSTMENT","text":"<ul> <li>Granite: Transaction type ADJUSTMENT</li> <li>Evolution: InventoryTransaction ADJ - Inventory Adjustments<ul> <li>Inventory Adjustments Increase and Decrease. </li> </ul> </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post InventoryTransaction </li> </ul> </li> <li>Pre-post validation:<ul> <li>ActionQty is greater than 0</li> </ul> </li> <li>Returns:<ul> <li>InventoryTransaction.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code InventoryTransaction.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch ToLocation InventoryTransaction.Warehouse Y If ToLocation is empty, uses FromLocation Comment InventoryTransaction.Reference2 N If Comment is empty, will be set to \"Granite Adjustment\" Batch InventoryTransaction.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate InventoryTransaction.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber InventoryTransaction.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo ActionQty InventoryTransaction.Quantity Y Transaction ID InventoryTransaction.Reference Y Prefixed with \"GRANITE ID: \""},{"location":"integration/evo/sdk-provider/#reclassify","title":"RECLASSIFY","text":"<p>Note</p> <p>Processes two InventoryAdjustments in Evo. One decreases the qty of the original item code, and the other increases the qty of the new item code.</p> <ul> <li>Granite: Transaction type RECLASSIFY</li> <li>Evolution: Inventory Transaction ADJ. <ul> <li>Inventory Adjustments Increase and Decrease. </li> </ul> </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post InventoryTransaction </li> </ul> </li> <li>Returns:<ul> <li>InventoryTransaction.ID for QtyDecrease, InventoryTransaction.ID for QtyIncrease </li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code InventoryTransaction.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch FromLocation InventoryTransaction.Warehouse Y This is the location used for the QtyDecrease transaction ToLocation InventoryTransaction.Warehouse Y This is the location used for the QtyIncrease transaction Comment InventoryTransaction.Reference2 N Batch InventoryTransaction.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate InventoryTransaction.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo ActionQty InventoryTransaction.Quantity Y Transaction ID InventoryTransaction.Reference Y Prefixed with \"GRANITE ID: \""},{"location":"integration/evo/sdk-provider/#replenish","title":"REPLENISH","text":"<ul> <li>Granite: Transaction type REPLENISH</li> <li>WarehouseTransfer. Inventory Warehouse Transfer. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment</li> <li>EvoTransactionCodeMove</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post WarehouseTransfer </li> </ul> </li> <li>Pre-post validation:<ul> <li>ToLocation and FromLocation are not the same</li> <li>InventoryItem is warehouse tracked in Evo</li> </ul> </li> <li>Returns:<ul> <li>WarehouseTransfer.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code WarehouseTransfer.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch Batch WarehouseTransfer.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate WarehouseTransfer.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber WarehouseTransfer.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo ActionQty WarehouseTransfer.Quantity Y FromLocation WarehouseTransfer.FromWarehouse Y ToLocation WarehouseTransfer.ToWarehouse Y Transaction ID WarehouseTransfer.Reference Y Prefixed with \"GRANITE ID: \" Comment WarehouseTransfer.Description N If Comment is empty, will be set to \"Granite Move\""},{"location":"integration/evo/sdk-provider/#transfer","title":"TRANSFER","text":"<p>Note</p> <p>Transfer integration does NOT update an existing Transfer document in Evolution. It creates a new warehouse transfer in Evolution when posted. Transactions are grouped by Code, Batch, ExpiryDate, Serial, FromLocation, ToLocation and ActionQty is summed before posting</p> <ul> <li>WarehouseTransfer. Inventory Warehouse Transfer. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment</li> <li>EvoTransactionCodeMove</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post WarehouseTransfer </li> </ul> </li> <li>Pre-post validation:<ul> <li>ToLocation and FromLocation are not the same</li> <li>InventoryItem is warehouse tracked in Evo</li> </ul> </li> <li>Returns:<ul> <li>WarehouseTransfer.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code WarehouseTransfer.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch Batch WarehouseTransfer.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate WarehouseTransfer.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber WarehouseTransfer.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo ActionQty WarehouseTransfer.Quantity Y FromLocation WarehouseTransfer.FromWarehouse Y ToLocation WarehouseTransfer.ToWarehouse Y Transaction ID WarehouseTransfer.Reference Y Prefixed with \"GRANITE ID: \" Comment WarehouseTransfer.Description N If Comment is empty, will be set to \"Granite Move\""},{"location":"integration/evo/sdk-provider/#dynamictransfer","title":"DYNAMICTRANSFER","text":"<ul> <li>WarehouseTransfer. Inventory Warehouse Transfer. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment</li> <li>EvoTransactionCodeMove</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post WarehouseTransfer </li> </ul> </li> <li>Pre-post validation:<ul> <li>ToLocation and FromLocation are not the same</li> <li>InventoryItem is warehouse tracked in Evo</li> </ul> </li> <li>Returns:<ul> <li>WarehouseTransfer.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code WarehouseTransfer.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch Batch WarehouseTransfer.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate WarehouseTransfer.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber WarehouseTransfer.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo ActionQty WarehouseTransfer.Quantity Y FromLocation WarehouseTransfer.FromWarehouse Y ToLocation WarehouseTransfer.ToWarehouse Y Transaction ID WarehouseTransfer.Reference Y Prefixed with \"GRANITE ID: \" Comment WarehouseTransfer.Description N If Comment is empty, will be set to \"Granite Move\""},{"location":"integration/evo/sdk-provider/#move","title":"MOVE","text":"<ul> <li>WarehouseTransfer. Inventory Warehouse Transfer. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment </li> <li>EvoTransactionCodeMove</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post WarehouseTransfer </li> </ul> </li> <li>Pre-post validation:<ul> <li>ToLocation and FromLocation are not the same</li> <li>InventoryItem is warehouse tracked in Evo</li> </ul> </li> <li>Returns:<ul> <li>WarehouseTransfer.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code WarehouseTransfer.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch Batch WarehouseTransfer.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate WarehouseTransfer.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber WarehouseTransfer.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo ActionQty WarehouseTransfer.Quantity Y FromLocation WarehouseTransfer.FromWarehouse Y ToLocation WarehouseTransfer.ToWarehouse Y Transaction ID WarehouseTransfer.Reference Y Prefixed with \"GRANITE ID: \" Comment WarehouseTransfer.Description N If Comment is empty, will be set to \"Granite Move\""},{"location":"integration/evo/sdk-provider/#scrap","title":"SCRAP","text":"<p>Note</p> <p>If setting EvoManufactureActive is true and part of the batch of the item scrapped is specified in setting EvoManufactureCodes, the item will attempt to post as a manufacturing transaction. This is not supported currently and will return an error.</p> <ul> <li>InventoryTransaction ADJ. Inventory Adjustments Decrease. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment </li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post InventoryTransaction </li> </ul> </li> <li>Pre-post validation:<ul> <li>ActionQty is greater than 0</li> </ul> </li> <li>Returns:<ul> <li>InventoryTransaction.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code InventoryTransaction.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch ToLocation InventoryTransaction.Warehouse Y If ToLocation is empty, uses FromLocation ActionQty InventoryTransaction.Quantity Y Comment InventoryTransaction.Reference2 N If Comment is empty, will be set to \"Granite Adjustment\" Batch InventoryTransaction.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate InventoryTransaction.Lot.ExpiryDate N Only applies if InventoryItem Lots expire in Evo SerialNumber InventoryTransaction.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo Transaction ID InventoryTransaction.Reference Y Prefixed with \"GRANITE ID: \""},{"location":"integration/evo/sdk-provider/#pick","title":"PICK","text":"<p>Note</p> <p>Branch can be set on the Sales Order header OR on the Sales Order line using the Inventory Item on the line. </p> <p>Lot support for picking does not work like it does on other integration methods. </p> <p>If the lot number is specified on a line in Evolution, we must pick the same lot in Granite.</p> <p>If we do not pick the same lot in Granite on the same line, we will not post the qty picked on the line in Granite.</p> <ul> <li>SalesOrder. Order Entry Sales Order.</li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Serial</li> <li>Comment</li> <li>DocumentReference</li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Save SalesOrder</li> <li>True - Process SalesOrder</li> </ul> </li> <li>Returns:<ul> <li>SalesOrder number or Invoice number, depending on IntegrationPost setting</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour ActionQty Detail.ToProcess Y Batch Detail.Note N Only applies if setting EvoBatchInNotes is true. Adds to comma separated list of unique batches SerialNumber Detail.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo Comment SalesOrder.ExternalOrderNo N Transaction.DocumentReference SalesOrder.MessageLine1 N"},{"location":"integration/evo/sdk-provider/#dynamicpick","title":"DYNAMICPICK","text":"<p>Note</p> <p>Branch is set based on the Sales Order header </p> <p>Transactions are grouped by Code, Batch, ExpiryDate, Serial, FromLocation, ToLocation and ActionQty is summed before posting</p> <ul> <li>SalesOrder. Order Entry Sales Order. </li> <li>Supports: <ul> <li>TradingPartner</li> <li>Branch</li> <li>Comment </li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Save SalesOrder</li> <li>True - Process SalesOrder</li> </ul> </li> <li>Returns:<ul> <li>SalesOrder number or Invoice number, depending on IntegrationPost setting</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour Document TradingPartnerCode SalesOrder.Customer Y MasterItem Code Detail.InventoryItem Y ActionQty Detail.Quantity Y ActionQty Detail.ToProcess Y Comment SalesOrder.ExternalOrderNo N"},{"location":"integration/evo/sdk-provider/#receive","title":"RECEIVE","text":"<p>Note</p> <p>Branch can be set on the Purchase Order header OR on the Purchase Order line using the Inventory Item on the line. </p> <p>Lot support for receiving does not work like it does on other integration methods.  If the lot number is specified on a line in Evolution, we must receive the same lot in Granite. If we do not receive the same lot in Granite on the same line, we will not post the qty received on the line in Granite. If the lot number is not specified on line in Evolution but the InventoryItem is Lot tracked, we will post the Batch received in Granite.</p> <p>Transactions are grouped by Code, Batch, ExpiryDate, Serial, FromLocation, ToLocation and ActionQty is summed before posting</p> <ul> <li>PurchaseOrder. Order Entry Purchase Order. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment </li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Save PurchaseOrder</li> <li>True - ProcessStock PurchaseOrder</li> </ul> </li> <li>Returns:<ul> <li>PurchaseOrder number or Receipt number, depending on IntegrationPost setting</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour ActionQty Detail.ToProcess Y Batch Detail.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo, and Lot is not specified on the line in Evo ExpiryDate Detail.Lot.Code N Only applies if InventoryItem Lots are set to expire in Evo SerialNumber Detail.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo Comment PurchaseOrder.ExternalOrderNo N"},{"location":"integration/evo/sdk-provider/#dynamicreceive","title":"DYNAMICRECEIVE","text":"<p>Note</p> <p>Branch is set based on the Purchase Order header.</p> <p>Transactions are grouped by Code, Batch, ExpiryDate, Serial, FromLocation, ToLocation and ActionQty is summed before posting</p> <ul> <li>PurchaseOrder. Order Entry Purchase Order. </li> <li>Supports: <ul> <li>TradingPartner</li> <li>Branch</li> <li>Comment </li> </ul> </li> <li>IntegrationPost:<ul> <li>False - Save PurchaseOrder</li> <li>True - Process PurchaseOrder</li> </ul> </li> <li>Returns:<ul> <li>PurchaseOrder number or Receipt number, depending on IntegrationPost setting</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour Document TradingPartnerCode PurchaseOrder.Supplier Y MasterItem Code Detail.InventoryItem Y ActionQty Detail.Quantity Y ActionQty Detail.ToProcess Y Comment PurchaseOrder.ExternalOrderNo N"},{"location":"integration/evo/sdk-provider/#receiveline","title":"RECEIVELINE","text":"<p>Note</p> <p>Branch can be set on the Purchase Order header OR on the Purchase Order line using the Inventory Item on the line. </p> <p>Lot support for receiving does not work like it does on other integration methods.  If the lot number is specified on a line in Evolution, we must receive the same lot in Granite. If we do not receive the same lot in Granite on the same line, we will not post the qty received on the line in Granite. If the lot number is not specified on line in Evolution but the InventoryItem is Lot tracked, we will post the Batch received in Granite.</p> <p>Transactions are grouped by Code, Batch, ExpiryDate, Serial, FromLocation, ToLocation and ActionQty is summed before posting</p> <ul> <li>PurchaseOrder. Order Entry Purchase Order. </li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Serial</li> <li>Comment (Evolution ExternalOrderNo field)</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Save PurchaseOrder</li> </ul> </li> <li>Returns:<ul> <li>PurchaseOrder number</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour ActionQty Detail.ToProcess Y Batch Detail.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo, and Lot is not specified on the line in Evo ExpiryDate Detail.Lot.Code N Only applies if InventoryItem Lots are set to expire in Evo SerialNumber Detail.SerialNumbers N Only applies if InventoryItem is Serial tracked in Evo Comment PurchaseOrder.ExternalOrderNo N"},{"location":"integration/evo/sdk-provider/#manufacture","title":"MANUFACTURE","text":"<p>Note</p> <p>Transactions are grouped by Code, Batch, ExpiryDate, Serial, FromLocation, ToLocation and ActionQty is summed before posting</p> <ul> <li> <p>Custom implementation using SDK GLTransaction MFMF, MFDR, MFR4M in conjunction with Database _bspPostStTrans.</p> </li> <li> <p>Posts 2 GL transactions with TransactionCode \"MFDR\" for each BOM Item</p> <ul> <li>Credit account is InventoryItem Group's StockAccount</li> <li>Debit account is GL Account \"7600\"</li> </ul> </li> <li> <p>Posts a GL transaction with transaction code \"MFMF\" for each BOM Item</p> <ul> <li>Credits GL account \"7600\"</li> </ul> </li> <li> <p>Posts a GL transaction with TransactionCode \"40\" for the manufactured item</p> <ul> <li>Debits manufactured item's group's StockAccount (if null defaults to \"7700&gt;020\")</li> </ul> </li> <li> <p>Executes procedure _bspPostStTrans twice for each BOM Item</p> <ul> <li>MFDR</li> <li>MFR4M</li> </ul> </li> <li> <p>Executes procedure _bspPostStTrans for the manufactured item</p> <ul> <li>MFMF</li> </ul> </li> <li> <p>Returns AutoIndex from final _bspPostStTrans if successful</p> </li> </ul>"},{"location":"integration/evo/sdk-provider/#issue","title":"ISSUE","text":"<ul> <li>InventoryTransaction IIS. Pastel OverrideCreditAccount based on Granite transaction Comment.</li> <li>Supports: <ul> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Comment (Evolution Reference2 field)</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post InventoryTransaction</li> </ul> </li> <li>Returns:<ul> <li>InventoryTransaction.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code InventoryTransaction.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch FromLocation InventoryTransaction.Warehouse Y ActionQty InventoryTransaction.Quantity Y Comment InventoryTransaction.Reference2 N If Comment is empty, will set \"Granite Issue\" Comment InventoryTransaction.OverrideCreditAccount N If Comment is a valid GL Account Code, it will override the default credit account Batch InventoryTransaction.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate InventoryTransaction.Lot.Code N Only applies if InventoryItem Lots are set to expire in Evo Transaction ID InventoryTransaction.Reference N Prefixed with \"GRANITE ID: \""},{"location":"integration/evo/sdk-provider/#projectissue","title":"PROJECTISSUE","text":"<ul> <li>InventoryTransaction. Qty decrease against a project</li> <li>Supports:<ul> <li>EvoTransactionCodeProjectsIssue (See settings detail)</li> <li>Branch</li> <li>LOT</li> <li>Expiry</li> <li>Comment (Evolution Reference2 field)</li> </ul> </li> <li>IntegrationPost:<ul> <li>Not supported, will always Post InventoryTransaction</li> </ul> </li> <li>Returns:<ul> <li>InventoryTransaction.Audit</li> </ul> </li> </ul> Granite Evo SDK Required Behaviour MasterItem Code InventoryTransaction.InventoryItem Y FromSite Branch N Applies if EvoBranchContextActive is true and EvoBranchUseLocation is true, if EvoBranchUseLocation is false uses InventoryItem's branch EvoTransactionCodeProjectsIssue InventoryTransaction.TransactionCode Y TransactionDocumentReference InventoryTransaction.Project Y FromLocation InventoryTransaction.Warehouse Y ActionQty InventoryTransaction.Quantity Y Comment InventoryTransaction.Reference2 N If Comment is empty, will set \"Granite Issue\" Batch InventoryTransaction.Lot.Code N Only applies if InventoryItem is Lot tracked in Evo ExpiryDate InventoryTransaction.Lot.Code N Only applies if InventoryItem Lots are set to expire in Evo Comment InventoryTransaction.OverrideCreditAccount N If Comment is a valid GL Account Code, it will override the default credit account Transaction ID InventoryTransaction.Reference N Prefixed with \"GRANITE ID: \""},{"location":"integration/evo/sdk-provider/#custom-methods-for-clients","title":"Custom Methods for clients","text":""},{"location":"integration/evo/sdk-provider/#ambro_adjustment","title":"AMBRO_ADJUSTMENT","text":"<ul> <li>Complete custom as per customer requirements.</li> </ul>"},{"location":"integration/evo/sdk-provider/#external-resources","title":"External Resources","text":""},{"location":"integration/evo/sdk-provider/#document-profilesagents","title":"Document Profiles/Agents","text":"<p>Video on Document profiles for agents. https://www.youtube.com/watch?v=Y-RUXaGBg9A</p>"},{"location":"integration/omni/sdk-provider/","title":"Omni","text":"<p>Note</p> <p>Requirements for Omni integration need to be assessed carefully before it is offered to any potential clients. The Omni API is limited in the functionality that it offers, and it usually does not behave in the same way that the Omni Desktop application does.</p>"},{"location":"integration/omni/sdk-provider/#setup","title":"Setup","text":"<ol> <li> <p>Copy everything in the <code>Providers\\Omni</code> folder into Integration Service folder (root folder).</p> </li> <li> <p>Ensure <code>SDKProvider.xml</code> setup or copied correctly     <pre><code>&lt;module name=\"Provider\"&gt;\n&lt;bind\n    service=\"Granite.Integration.Contract.IProvider, Granite.Integration.Contract\"\n    to=\"Granite.Integration.OMNI.Provider, Granite.Integration.OMNI\"/&gt;\n&lt;/module&gt;\n</code></pre></p> </li> <li> <p>Configure your connection string and endpoint in the <code>Granite.Integration.Web.exe.config</code> file</p> </li> </ol>"},{"location":"integration/omni/sdk-provider/#settings","title":"Settings","text":"<p>The settings for Omni are configured in the SystemSettings table. The IntegrationService will pick up the settings using the Application name specified in it's <code>.config</code> file: <pre><code>&lt;add key =\"SystemSettingsApplicationName\" value=\"IntegrationOmni\"/&gt;\n</code></pre> If this setting is missing from the config file or left empty, the IntegrationService will default to using <code>IntegrationOmni</code> as the SystemSettingsApplicationName</p> <p>You can browse the IntegrationService's <code>/config</code> page to have the IntegrationService create the default settings in the SystemSettings table for you.</p> <p>The script to insert the default settings is also located in the GraniteDatabase release: <pre><code>~\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingsOmni.sql\n</code></pre></p> <p>Note</p> <p>To pick up any changes to the SystemSettings table, the IntegrationService will need to be restarted.</p>"},{"location":"integration/omni/sdk-provider/#example-systemsettings-in-database","title":"Example SystemSettings in database","text":"Application Key Value Description IntegrationOmni Host Server name or IP of the server where the Omni API is hosted IntegrationOmni Port Port number that the Omni API is running on IntegrationOmni UserName Omni user name that is used to transact via the API IntegrationOmni Password Password for the Omni user IntegrationOmni CompanyName Omni company name to post to IntegrationOmni AdjustmentAccount Account that adjustments will post to IntegrationOmni ScrapAccount Account that scrap transactions will post to IntegrationOmni IntransitWarehouse The intransit warehouse that will be used IntegrationOmni PostDynamicTransferReceipt true or false. Determines whether Omni transfer is auto posted for Granite DynamicTransfers"},{"location":"integration/omni/sdk-provider/#integration-methods","title":"Integration Methods","text":"<p>Note</p> <p>This is the complete list of supported integration methods at present.  There is no support for manufacturing or receiving at this time.</p>"},{"location":"integration/omni/sdk-provider/#adjustment","title":"ADJUSTMENT","text":"<ul> <li>Granite: Transaction type ADJUSTMENT </li> <li>Omni: Stock Journal Entry</li> <li>IntegrationPost:<ul> <li>Not supported, will always post Stock Journal Entry </li> </ul> </li> <li>Supports:<ul> <li>AdjustmentAccount SystemSetting</li> </ul> </li> </ul> Granite Omni API Required Behaviour MasterItem Code stockjournalentry.stock_code Y FromLocation stockjournalentry.warehouse_code Y TransactionDocumentReference stockjournalentry.reference Y Comment stockjournalentry.narrative N ActionQty stockjournalentry.quantity Y AdjustmentAccount SystemSetting stockjournalentry.to_ledger_account Y stockjournalentry.transaction_type Y Will be set to \"Adjustment In\" or \"Adjustment Out\" based on whether the transaction was an increase or decrease in Granite"},{"location":"integration/omni/sdk-provider/#transfer","title":"TRANSFER","text":"<ul> <li>Granite: Transaction type TRANSFER </li> <li>Omni: Warehouse Transfer</li> <li>IntegrationPost:<ul> <li>Not supported</li> </ul> </li> <li>Supports:<ul> <li>IntransitWarehouse SystemSetting</li> </ul> </li> </ul> Granite Omni API Required Behaviour Document inter_warehouse_transfer.req_no Y IntransitWarehouse SystemSetting inter_warehouse_transfer.in_transit_warehouse_code Y User inter_warehouse_transfer.internal_reference Y DocumentDescription inter_warehouse_transfer.delivery_details N LineNumber inter_warehouse_transfer_lines.line_no Y MasterItem Code inter_warehouse_transfer_lines.stock_code Y ActionQty inter_warehouse_transfer_lines.quantity Y"},{"location":"integration/omni/sdk-provider/#transferreceipt","title":"TRANSFERRECEIPT","text":"<p>Note</p> <p>The Omni API does not support partial processing of a transfer. When you post a transfer receipt, it simply completes the transfer in Omni.</p> <p>For this reason, no transaction information is posted to Omni when a transfer receipt is posted.</p> <ul> <li>Granite: Transaction type TRANSFER </li> <li>Omni: Warehouse Transfer</li> <li>IntegrationPost:<ul> <li>Not supported</li> </ul> </li> </ul>"},{"location":"integration/omni/sdk-provider/#transferdynamic","title":"TRANSFERDYNAMIC","text":"<ul> <li>Granite: Transaction type TRANSFERDYNAMIC </li> <li>Omni: Warehouse Requisition</li> <li>IntegrationPost:<ul> <li>If true, processes a warehouse transfer against the created requisition</li> </ul> </li> <li>Supports:<ul> <li>IntransitWarehouse SystemSetting</li> </ul> </li> </ul> Granite Omni API Required Behaviour Document inter_warehouse_transfer.req_no Y FromLocation inter_warehouse_requisition.source_warehouse_code Y ToLocation inter_warehouse_requisition.destination_warehouse_code Y IntransitWarehouse SystemSetting inter_warehouse_requisition.in_transit_warehouse_code Y User inter_warehouse_requisition.internal_reference Y DocumentDescription inter_warehouse_requisition.delivery_details N LineNumber inter_warehouse_requisition_lines.line_no Y MasterItem Code inter_warehouse_requisition_lines.stock_code Y ActionQty inter_warehouse_requisition_lines.quantity Y"},{"location":"integration/omni/sdk-provider/#scrap","title":"SCRAP","text":"<ul> <li>Granite: Transaction type ADJUSTMENT </li> <li>Omni: Stock Journal Entry</li> <li>IntegrationPost:<ul> <li>Not supported, will always post Stock Journal Entry </li> </ul> </li> <li>Supports:<ul> <li>ScrapAccount SystemSetting</li> </ul> </li> </ul> Granite Omni API Required Behaviour stockjournalentry.reference Y Will be set to \"SCRAP\" stockjournalentry.transaction_type Y Will be set to \"Issue\" MasterItem Code stockjournalentry.stock_code Y FromLocation stockjournalentry.warehouse_code Y Comment stockjournalentry.narrative N ActionQty stockjournalentry.quantity Y ScrapAccount SystemSetting stockjournalentry.to_ledger_account Y"},{"location":"integration/omni/sdk-provider/#pick","title":"PICK","text":"<ul> <li>Granite: Transaction type PICK </li> <li>Omni: Delivery Note / Invoice</li> <li>IntegrationPost:<ul> <li>If true, posts an invoice instead of a delivery note</li> </ul> </li> </ul> <p>Delivery note mapping:</p> Granite Omni API Required Behaviour delivery_note.source_type Will be set to \"ORDER\" delivery_note.customer_branch_code Will be set to \"HO\" Document delivery_note.source_reference Y DocumentTradingPartnerCode delivery_note.customer_account_code Y FromLocation delivery_note.warehouse_code Y delivery_note_lines.line_type Will be set to \"Stock\" LineNumber delivery_note_lines.line_no Y MasterItem Code delivery_note_lines.stock_code Y FromLocation delivery_note_lines.warehouse_code Y ActionQty delivery_note_lines.quantity Y <p>Invoice mapping:</p> Granite Omni API Required Behaviour invoice.source_type Will be set to \"ORDER\" Document invoice.source_reference Y DocumentTradingPartnerCode invoice.customer_account_code Y invoice_lines.line_type Will be set to \"Stock\" LineNumber invoice_lines.line_no Y MasterItem Code invoice_lines.stock_code Y ActionQty invoice_lines.quantity Y"},{"location":"integration/quickbooks/native-app/","title":"QuickBooks Desktop","text":"<p>This document contains all of the information needed to install and configure QuickBooks Desktop integration.</p> <p>QuickBooks integration works a bit differently from integration with other ERP systems. Because of the limitations imposed by the QuickBooks Desktop SDK, we cannot use the standard integration service and scheduler as we normally would. Instead, QuickBooks integration is implemented using a native Windows Forms application.</p> <p>Note</p> <p>At the moment only downward integration is supported in the QuickBooks integration application.</p> <p>Currently there are jobs for fetching the following from QuickBooks into Granite:</p> <ul> <li>Master Items</li> <li>Trading Partners</li> <li>Invoices</li> <li>Sales Orders</li> <li>Purchase Orders</li> </ul>"},{"location":"integration/quickbooks/native-app/#setup","title":"Setup","text":"<p>QuickBooks integration must be installed on the same machine as the QuickBooks SDK. It is best to put the integration application on the same machine as the QuickBooks company file, but if this is not possible the company file MUST at least be accessible from the machine you install on.</p> <p>Note</p> <p>You will need the QuickBooks Admin user credentials to allow the integration application to connect to QuickBooks.  You will also need a dedicated QuickBooks user that the integration application can use.</p> <ol> <li> <p>Check if the client's version of QuickBooks is 32bit or 64bit. You can check by opening QuickBooks Desktop and pressing F2:     </p> </li> <li> <p>Ensure you have the matching bitness Granite.Integration.QuickBooks.Native install files from the release folder</p> </li> <li> <p>Paste the folder containing the application into the standard install directory <code>C:\\Program Files (x86)\\Granite WMS\\</code></p> </li> <li> <p>In the <code>Granite.Integration.QuickBooks.Native.exe.config</code> file, configure your connection string to the Granite database: <pre><code>&lt;connectionStrings&gt;\n    &lt;add name=\"CONNECTION\" connectionString=\"Data Source=.\\SQL2019;Initial Catalog=Granite;Persist Security Info=True;User ID=******;Password=*******\" providerName=\"System.Data.SqlClient\" /&gt;\n&lt;/connectionStrings&gt;\n</code></pre></p> </li> <li> <p>Configure the <code>QuickBooksCompanyFile</code> in the SystemSettings table, and enable the scheduled jobs that you want to run.</p> </li> <li> <p>Log in to the QuickBooks company with the <code>Admin</code> user, and then run the integration application.  QuickBooks will pop up a dialog where you need to give permission for the application to connect to QuickBooks, and select a user for it to use:     </p> </li> </ol>"},{"location":"integration/quickbooks/native-app/#settings","title":"Settings","text":"<p>The settings for QuickBooks integration are configured in the SystemSettings table in the Granite database.  You can configure these from the Webdesktop as well if it is already installed.  This section describes each of the settings.</p>"},{"location":"integration/quickbooks/native-app/#quickbookscompanyfile","title":"QuickBooksCompanyFile","text":"<p>This is the file path to the QuickBooks company file that the integration application will connect to.</p>"},{"location":"integration/quickbooks/native-app/#masteritemsyncenable","title":"MasterItemSyncEnable","text":"<p>Enables syncing MasterItems from QuickBooks to Granite</p>"},{"location":"integration/quickbooks/native-app/#masteritemsyncinterval","title":"MasterItemSyncInterval","text":"<p>Interval to sync MasterItems at. Measured in seconds</p>"},{"location":"integration/quickbooks/native-app/#masteritemsyncinventoryitems","title":"MasterItemSyncInventoryItems","text":"<p>Enable or disable syncing Inventory Items</p>"},{"location":"integration/quickbooks/native-app/#masteritemsyncassemblyitems","title":"MasterItemSyncAssemblyItems","text":"<p>Enable or disable syncing Assembly Items</p>"},{"location":"integration/quickbooks/native-app/#masteritemsyncserviceitems","title":"MasterItemSyncServiceItems","text":"<p>Enable or disable syncing Service Items</p>"},{"location":"integration/quickbooks/native-app/#salesordersyncenable","title":"SalesOrderSyncEnable","text":"<p>Enables syncing Sales Orders from QuickBooks to Granite</p>"},{"location":"integration/quickbooks/native-app/#salesordersyncinterval","title":"SalesOrderSyncInterval","text":"<p>Interval to sync Sales Orders at. Measured in seconds</p>"},{"location":"integration/quickbooks/native-app/#salesorderprefix","title":"SalesOrderPrefix","text":"<p>Prefix that will be applied to Sales Order numbers when they are synced to Granite. This setting is not required, but it is useful to avoid conflicts if different document types are using the same prefix (or none at all) in QuickBooks.</p>"},{"location":"integration/quickbooks/native-app/#salesorderafterheadersyncprocedure","title":"SalesOrderAfterHeaderSyncProcedure","text":"<p>Name of stored procedure that will run after each SalesOrder header is synced to Granite.</p> <p><code>See Also</code> After Header Sync Procedures</p>"},{"location":"integration/quickbooks/native-app/#invoicesyncenable","title":"InvoiceSyncEnable","text":"<p>Enables syncing Invoices from QuickBooks to Granite</p>"},{"location":"integration/quickbooks/native-app/#invoicesyncinterval","title":"InvoiceSyncInterval","text":"<p>Interval to sync Invoices at. Measured in seconds</p>"},{"location":"integration/quickbooks/native-app/#invoiceprefix","title":"InvoicePrefix","text":"<p>Prefix that will be applied to Invoice numbers when they are synced to Granite. This setting is not required, but it is useful to avoid conflicts if different document types are using the same prefix (or none at all) in QuickBooks.</p>"},{"location":"integration/quickbooks/native-app/#invoiceafterheadersyncprocedure","title":"InvoiceAfterHeaderSyncProcedure","text":"<p>Name of stored procedure that will run after each Invoice header is synced to Granite</p> <p><code>See Also</code> After Header Sync Procedures</p>"},{"location":"integration/quickbooks/native-app/#purchaseordersyncenable","title":"PurchaseOrderSyncEnable","text":"<p>Enables syncing Purchase Orders from QuickBooks to Granite</p>"},{"location":"integration/quickbooks/native-app/#purchaseordersyncinterval","title":"PurchaseOrderSyncInterval","text":"<p>Interval to sync Purchase Orders at. Measured in seconds</p>"},{"location":"integration/quickbooks/native-app/#purchaseorderprefix","title":"PurchaseOrderPrefix","text":"<p>Prefix that will be applied to Purchase Order numbers when they are synced to Granite. This setting is not required, but it is useful to avoid conflicts if different document types are using the same prefix (or none at all) in QuickBooks.</p>"},{"location":"integration/quickbooks/native-app/#purchaseorderafterheadersyncprocedure","title":"PurchaseOrderAfterHeaderSyncProcedure","text":"<p>Name of stored procedure that will run after each PurchaseOrder header is synced to Granite</p> <p><code>See Also</code> After Header Sync Procedures</p>"},{"location":"integration/quickbooks/native-app/#tradingpartnersyncenable","title":"TradingPartnerSyncEnable","text":"<p>Enables syncing TradingPartners from QuickBooks to Granite</p>"},{"location":"integration/quickbooks/native-app/#tradingpartnersyncinterval","title":"TradingPartnerSyncInterval","text":"<p>Interval to sync TradingPartners at. Measured in seconds</p>"},{"location":"integration/quickbooks/native-app/#how-it-works","title":"How it works","text":"<p>The QuickBooks integration app makes use of the QuickBooks Desktop SDK to connect to the company file and copy data into Granite. This is the method that we use for all data access in QuickBooks</p>"},{"location":"integration/quickbooks/native-app/#document-jobs","title":"Document Jobs","text":"<p>Each time a document sync job runs, it queries QuickBooks for the documents that have been edited on the current date.  The application then checks the Granite <code>IntegrationDocumentQueue</code> table to see if the modified documents have already been integrated or are already queued. It does this by comparing the edited documents <code>ModifiedDate</code> timestamp to the <code>LastUpdateDateTime</code> timestamp and checking the <code>Status</code> field in the <code>IntegrationDocumentQueue</code> table.</p> <p>If the <code>ModifiedDate</code> is newer than the last successfully synced entry in the <code>IntegrationDocumentQueue</code> table, a new entry will be added to the table queuing the document for integration.</p> <p>After entering all of the documents that need to be synced into the <code>IntegrationDocumentQueue</code> table, the application will go through the entries in the table one by one and ensure that each document is copied into Granite.</p> <p>If there is a after header sync procedure configured for the document type, after each Document record is created/updated and before the lines are synced the procedure will fire. </p> <p>Next, all MasterItems specified on the document being synced are inserted if they are missing, or updated if there are any changes.</p> <p>Finally, each document line is inserted if it is missing, or updated if there are any applicable changes.</p>"},{"location":"integration/quickbooks/native-app/#syncing-a-specific-document","title":"Syncing a specific document","text":"<p>It is possible to manually add a record to the <code>IntegrationDocumentQueue</code> table if you need a specific document to sync.  If you have the ERP_id of the document it is best to specify it - but if not, the application should be able to find the document using only the document number and type.</p>"},{"location":"integration/quickbooks/native-app/#after-header-sync-procedures","title":"After Header Sync Procedures","text":"<p>After header sync procedures can be configured for each type of document.  These are SQL stored procedures that allow you to apply any necessary custom logic to documents as they sync.  The stored procedure must take the document ID as an input like this: </p> <pre><code>CREATE PROCEDURE [dbo].[InvoiceAfterHeaderSync] \n    @DocumentID bigint\n    ...\n</code></pre>"},{"location":"integration/quickbooks/native-app/#masteritem-job","title":"MasterItem Job","text":"<p>The MasterItem job can fetch three types of items from QuickBooks:</p> <ul> <li>Inventory Items</li> <li>Assembly Items</li> <li>Service Items</li> </ul> <p>Each of these can be enabled or disabled individually in SystemSettings.</p> <p>When the MasterItem job runs, it will fetch items only from the lists that are enabled in SystemSettings.</p>"},{"location":"integration/quickbooks/native-app/#tradingpartner-job","title":"TradingPartner Job","text":"<p>The TradingPartner job syncs two types of trading partners from QuickBooks:</p> <ul> <li>Customers</li> <li>Vendors</li> </ul>"},{"location":"integration/quickbooks/native-app/#manual-job-execution","title":"Manual Job Execution","text":"<p>If you click the <code>Tools</code> button near the top of the integration application interface, you will see an option to execute a manual sync of each job type. For document jobs, the calendar allows you to select a range of dates to fetch the modified documents from. </p> <p>Note</p> <p>It can be a slow process to fetch multiple days worth of documents. On a moderately busy site it would be advisable to manually sync jobs in batches of 3 to 4 days at a time.</p> <p>The MasterItem and TradingPartner jobs do not make use of the calendar - they will always fetch the full list from QuickBooks for comparison to Granite.</p>"},{"location":"integration/sapb1/sdk-provider/","title":"SAP B1","text":"<p>This document contains all the information needed to setup and configure SAP B1 integration. The Data Interface API (DI API) is part of the SAP Business One Software Development Kit (SDK). </p>"},{"location":"integration/sapb1/sdk-provider/#setup","title":"Setup","text":""},{"location":"integration/sapb1/sdk-provider/#prerequisites","title":"Prerequisites","text":"<ul> <li>The server running the Granite WMS service require the DI API to be locally installed and permissions setup in order for Granite to work.  This should be done by the client or SAP consultant.</li> <li>Granite WMS Integration service should be installed and all settings in regard to database and endpoints setup.</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#sdk-provider","title":"SDK provider","text":"<ol> <li>Copy <code>Granite.Integration.SAPB1.dll</code> into the root folder of the Integration Service</li> <li>Copy <code>SDKProvider.xml</code> into the root folder of the Integration Service</li> </ol> <p>Preview of the  <code>SDKProvider.xml</code> file <pre><code>&lt;module name=\"Provider\"&gt;\n  &lt;bind\n    service=\"Granite.Integration.Contract.IProvider, Granite.Integration.Contract\"\n    to=\"Granite.Integration.SAPB1.Provider, Granite.Integration.SAPB1\"/&gt;\n&lt;/module&gt;\n</code></pre></p>"},{"location":"integration/sapb1/sdk-provider/#application-settings","title":"Application Settings","text":"<p>The following is a list of settings that must be configured in the SystemSettings table. It is advisable to schedule time to obtain these settings from the client or SAP consultant beforehand.</p> <p>You can locate the database script to create these records in the following path: <pre><code>~\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingsSAPB1.sql\n</code></pre></p>"},{"location":"integration/sapb1/sdk-provider/#settings","title":"Settings","text":"Application Key Value Description IntegrationSAPB1 Server Integration provider SAP IntegrationSAPB1 LicenseServer SAP License server address <code>*see note*</code> IntegrationSAPB1 DbUserName Database user name IntegrationSAPB1 DbPassword Database password IntegrationSAPB1 CompanyDB SAP company database name IntegrationSAPB1 DbServerType SQL dialect. dst_MSSQL2012 dst_MSSQL2014 dst_MSSQL2016 dst_MSSQL2017 dst_MSSQL2019 IntegrationSAPB1 UserName SAP application user name IntegrationSAPB1 Password SAP application user password IntegrationSAPB1 InventoryAccountCode TAKEON AccountCode IntegrationSAPB1 BinEntry Greater than 0. The BinEntry will be used by TAKEON, SCRAP and ADJUSTMENT <p>Note</p> <p>LicenseServer address found in <code>C:\\Program Files (x86)\\SAP\\SAP Business One DI API\\Conf\\B1_Local_machine.xml</code></p> <p>Note</p> <p>Once the settings are captured please test the SAP connection by browsing to the <code>/config</code> page on the integration service.</p>"},{"location":"integration/sapb1/sdk-provider/#integration-methods","title":"Integration Methods","text":"<p>Integration Methods refer to the specific functionalities supported for the given provider. This documentation serves as a crucial resource when engaging with a client, providing insights into our supported operations and the manner in which we support them.</p> <p>Integration Methods are predefined values, each corresponding to an operation within SAP B1. These methods are configured at a process level in the database table <code>Process.IntegrationMethod</code>. In cases where the IntegrationMethod in the database is left empty, Granite will automatically use <code>Transaction.Type</code> as the default Integration Method.</p> <p><code>See Also</code> The <code>Integration_Transactions</code> SQL view is responsible for determining the information sent to each operation.</p>"},{"location":"integration/sapb1/sdk-provider/#goodissue","title":"GOODISSUE","text":"<ul> <li>Not supported (future development)</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#goodreceipt","title":"GOODRECEIPT","text":"<ul> <li>Not supported (future development)</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#reclassify","title":"RECLASSIFY","text":"<ul> <li>Not supported (future development)</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#dynamicpick","title":"DYNAMICPICK","text":"<ul> <li>Not supported (future development)</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#takeon","title":"TAKEON","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oInventoryGenEntry</li> <li>Documents object for entering general items to inventory</li> <li> <p>Table: OIGN</p> </li> <li> <p>Supports: </p> <ul> <li>BinAllocations (Appsetting BinEntry)</li> </ul> </li> </ul>"},{"location":"integration/sapb1/sdk-provider/#adjustment","title":"ADJUSTMENT","text":"<ul> <li>Post : SAPbobsCOM.InventoryPostingsServiceDataInterfaces.ipsInventoryPosting</li> <li>The InventoryPostingsService service enables you to add, look up, and update inventory posting transactions.</li> <li>Table: OIQR</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#scrap","title":"SCRAP","text":"<ul> <li>Post :SAPbobsCOM.InventoryPostingsServiceDataInterfaces.ipsInventoryPosting</li> <li>The InventoryPostingsService service enables you to add, look up, and update inventory posting transactions.</li> <li> <p>Table: OIQR</p> </li> <li> <p>Supports: </p> <ul> <li>BinAllocations (Appsetting BinEntry)</li> </ul> </li> </ul>"},{"location":"integration/sapb1/sdk-provider/#replenish","title":"REPLENISH","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oStockTransfer</li> <li>StockTransfer is a business object that represents items to transfer from one warehouse to another. This object is part of the Inventory and Production module.</li> <li> <p>Table: OWTR</p> </li> <li> <p>Supports: </p> <ul> <li>SerialNumbers</li> <li>BatchNumbers</li> </ul> </li> </ul>"},{"location":"integration/sapb1/sdk-provider/#move","title":"MOVE","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oStockTransfer</li> <li>StockTransfer is a business object that represents items to transfer from one warehouse to another. This object is part of the Inventory and Production module.</li> <li> <p>Table: OWTR</p> </li> <li> <p>Supports: </p> <ul> <li>BinAllocations (Appsetting BinEntry)</li> <li>SerialNumbers</li> <li>BatchNumbers</li> </ul> </li> </ul>"},{"location":"integration/sapb1/sdk-provider/#transfer","title":"TRANSFER","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oStockTransfer</li> <li>StockTransfer is a business object that represents items to transfer from one warehouse to another. This object is part of the Inventory and Production module.</li> <li>Table: OWTR</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#transferdraft","title":"TRANSFERDRAFT","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oStockTransferDraft</li> <li>Documents object that represents a draft document</li> <li>Table: ODRF</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#receive","title":"RECEIVE","text":"<ul> <li>Post :oPurchaseOrders -&gt; SAPbobsCOM.BoObjectTypes.oPurchaseDeliveryNotes</li> <li>Documents object that represents a purchase delivery note document</li> <li>Table: OPDN</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#receivingpostmultiple","title":"RECEIVINGPOSTMULTIPLE","text":"<ul> <li>Post :oPurchaseOrders -&gt; SAPbobsCOM.BoObjectTypes.oPurchaseDeliveryNotes</li> <li>Documents object that represents a purchase delivery note document</li> <li>Table: OPDN</li> <li>Note: same as RECEIVING but instead of using Document Number we use all the IntegrationReference as PO Numbers.</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#purchaseorderdraft","title":"PURCHASEORDERDRAFT","text":"<ul> <li>Post :oPurchaseOrders -&gt; SAPbobsCOM.BoObjectTypes.oDrafts</li> <li>Documents object that represents a draft document</li> <li>Table: ODRF</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#purchasecreditnotes","title":"PURCHASECREDITNOTES","text":"<ul> <li>Post :oGoodsReturnRequest -&gt; oPurchaseCreditNotes</li> <li>Documents object that represents a draft of purchase credit note document</li> <li>Table: ORPC</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#pick","title":"PICK","text":"<ul> <li>Post :oOrders -&gt; SAPbobsCOM.BoObjectTypes.oDeliveryNotes</li> <li>Documents object that represents a sales delivery note document</li> <li>Table: ODLN</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#salesorderreturnrequest","title":"SALESORDERRETURNREQUEST","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oReturns -&gt; SAPbobsCOM.BoObjectTypes.oReturnRequest</li> <li>Documents object that represents a sales return document</li> <li>Table: ORDN</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#salesorderinvoice","title":"SALESORDERINVOICE","text":"<ul> <li>Post :oOrders -&gt; SAPbobsCOM.BoObjectTypes.oInvoices</li> <li>Documents object that represents a sales invoice document</li> <li>Table: OINV</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#salesordercreditmemo","title":"SALESORDERCREDITMEMO","text":"<ul> <li>Post : SAPbobsCOM.BoObjectTypes.oInvoices -&gt; SAPbobsCOM.BoObjectTypes.oCreditNotes</li> <li>Documents object that represents a sales Credit Memo</li> <li>Table: OINV</li> <li></li> </ul>"},{"location":"integration/sapb1/sdk-provider/#salesorderdraft","title":"SALESORDERDRAFT","text":"<ul> <li>Post :SAPbobsCOM.BoObjectTypes.oOrders -&gt; SAPbobsCOM.BoObjectTypes.oDrafts</li> <li>Documents object that represents a draft document</li> <li>Table: ODRF</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#sap-table-names","title":"SAP Table Names","text":"<ul> <li>OINV table = Sales A/R &gt; A/R Invoice.</li> <li>ORIN table = Sales A/R &gt; A/R Credit Memo.</li> <li>ODLN table = Sales A/R &gt; Delivery.</li> <li>ORDN table = Sales A/R &gt; Returns.</li> <li>ORDR table = Sales A/R &gt; Order.</li> <li>OQUT table = Sales A/R &gt; Quotation.</li> <li>OPCH table = Purchasing A/P &gt; A/P Invoice.</li> <li>ORPC table = Purchasing A/P &gt; A/P Credit Memo.</li> <li>OPDN table = Purchasing A/P &gt; Goods Receipt PO.</li> <li>ORPD table = Purchasing A/P &gt; Goods Returns.</li> <li>OPOR table = Purchasing A/P &gt; A/R Invoice.</li> <li>OPQT table = Purchasing A/P &gt; Purchase Quotation.</li> <li>OIGN table = Inventory &gt; Inventory Transactions &gt; Goods Receipt. Or, in case of receipt from production, select Production &gt; Receipt from Production (see ProductionOrders).</li> <li>OIGE table = Inventory &gt; Inventory Transactions &gt; Goods Issue. Or, in case of issue for production, select Production &gt; Issue for Production (see ProductionOrders).</li> <li>ODRF table = Sales A/R (or Purchasing - A/P) &gt; Document Draft. Set your selection criteria, and click OK.</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#sap-error-codes","title":"SAP Error Codes","text":"<ul> <li>0     Success.</li> <li>10    Seems to be a generic code. Need to troubleshoot issue to determine exact reason.</li> <li>103   Connection to the company database has failed.</li> <li>104   Connection to the license database has failed.</li> <li>105   The observer.dll init has failed.</li> <li>106   You are not connected to a company.</li> <li>107   Wrong username and/or password.</li> <li>108   Error reading company definitions.</li> <li>109   Error copying dll to temp directory.</li> <li>110   Error opening observer.dll.</li> <li>111   Connection to SBO-Common has failed.</li> <li>112   Error extracting dll from cab.</li> <li>113   Error creating temporary dll folder.</li> <li>114   No server defined.</li> <li>115   No database defined.</li> <li>116   Already connected to a company database.</li> <li>117   Language is not supported.</li> <li>118   Exceeded the number of max concurrent users.</li> <li>125   SAP connection issue, SQL version incorrect. Appsetting DbServerType, version might not be supported in release.</li> <li>132   Cannot connect to SAP, SAP Database names are case-sensitive.</li> <li>111   Similar issue to 125, DbServerType incorrect. Verify DbServerType setting, must be correct 2012, 2014 ect.</li> <li>1001  The field is to small to accept the data.</li> <li>1002  Invalid row.</li> <li>1103  Object not supported.</li> <li>1104  Invalid XML file.</li> <li>1105  Invalid index.</li> <li>1106  Invalid field name.</li> <li>1107  Wrong object state.</li> <li>1108  The transaction is already active.</li> <li>1109  There is no active transaction in progress.</li> <li>1110  Invalid user entered.</li> <li>1111  Invalid file name.</li> <li>1112  Could not save the XML file.</li> <li>1113  Function not implemented.</li> <li>1114  XML validation failed.</li> <li>1115  No XML schema was found to support this object.</li> <li>1120  Ref count for this object is higher then 0.</li> <li>1130  Invalid edit state.</li> <li>2000  SQL native error.</li> <li>2050  No query string entered.</li> <li>2051  No value found.</li> <li>2052  No records found.</li> <li>2053  Invalid object.</li> <li>2054  Either BOF or EOF have been reached.</li> <li>2055  The value entered is invalid.</li> <li>3000  The logged-on user does not have permission to use this object.</li> <li>3001  You do not have a permission to view this fields data.</li> <li>8004  Company connection is dead.</li> <li>8005  Server connection is dead.</li> <li>8006  Error opening language resource.</li> <li>8007  License failure.</li> <li>8008  Error initializing the DB layer.</li> <li>8009  Too many users connected.</li> <li>8010  No valid license is present.</li> <li>8011  Error initializing Business objects layer.</li> <li>8012  Company version mismatch.</li> <li>8013  Error initializing the application environment.</li> <li>8014  Invalid command.</li> <li>8015  Missing parameter.</li> <li>8016  Unsupported object.</li> <li>8017  Invalid command for this object.</li> <li>8018  Internal permission error.</li> <li>8019  DLL is not initialized.</li> <li>8020  Language init error.</li> <li>8021  Timeout encountered.</li> <li>8022  Init error.</li> <li>8023  Wrong user or password.</li> </ul>"},{"location":"integration/sapb1/sdk-provider/#known-issues","title":"Known issues","text":""},{"location":"integration/sapb1/sdk-provider/#integration-slow","title":"Integration Slow","text":"<p>The DI API could slow down due to the number of SAP log files (~b1logger.~.csv). The default path for log files:</p> <p>C:\\ProgramData\\SAP\\SAP Business One\\Log\\SAP Business One</p> <p>The number of files will impact the connection speed to the DI API, and can ultimately cause timeouts. Deleting these files should resolve the issue, but the path will often grew again within a few days. You can schedule a task to clear the path or switch logging off the logging.</p> <p>C:\\Program Files (x86)\\SAP\\SAP Business One DI API\\Conf\\b1LogConfig.xml</p> <p><code>Set Activate = \"0\"</code> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-16\"?&gt;\n&lt;log FolderSize=\"50\"&gt;\n&lt;b1logger Mode=\"A\" MaxFileSize=\"5\" MaxNumOfMsg=\"500\" LogStack=\"0\" Activate = \"0\"&gt;\n</code></pre></p> <p><code>See Also</code>  https://www.youtube.com/watch?v=kGueS8LdF-w</p> <p>If the IIS (app pool) user does not have permissions it can cause issues.</p>"},{"location":"integration/sapb1/sdk-provider/#further-reading","title":"Further Reading","text":"<ul> <li>Complete list of DI API (SDK) Document objects (https://biuan.com/Documents/).</li> <li>SAP Tables https://sap.erpref.com/</li> <li>https://www.sap-business-one-tips.com/</li> <li>https://support.boyum-it.com/hc/en-us/articles/360021794234-SAP-Object-Types</li> </ul>"},{"location":"integration/syspro/sdk-provider/","title":"Syspro","text":""},{"location":"integration/syspro/sdk-provider/#setup","title":"Setup","text":"<ol> <li> <p>Copy everything in the <code>Providers\\Syspro</code> folder into Integration Service folder (root folder).</p> </li> <li> <p>Ensure <code>SDKProvider.xml</code> setup or copied correctly     <pre><code>&lt;module name=\"Provider\"&gt;\n&lt;bind\n    service=\"Granite.Integration.Contract.IProvider, Granite.Integration.Contract\"\n    to=\"Granite.Integration.Syspro.Provider, Granite.Integration.Syspro\"/&gt;\n&lt;/module&gt;\n</code></pre></p> </li> <li> <p>Configure your connection string and endpoint in the <code>Granite.Integration.Web.exe.config</code> file</p> </li> </ol>"},{"location":"integration/syspro/sdk-provider/#settings","title":"Settings","text":"<p>The settings for Syspro are configured in the SystemSettings table. The IntegrationService will pick up the settings using the Application name specified in it's <code>.config</code> file: <pre><code>&lt;add key =\"SystemSettingsApplicationName\" value=\"IntegrationSyspro\"/&gt;\n</code></pre> If this setting is missing from the config file or left empty, the IntegrationService will default to using <code>IntegrationSyspro</code> as the SystemSettingsApplicationName</p> <p>You can browse the IntegrationService's <code>/config</code> page to have the IntegrationService create the default settings in the SystemSettings table for you.</p> <p>The script to insert the default settings is also located in the GraniteDatabase release: <pre><code>~\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingSyspro.sql\n</code></pre></p> <p>Note</p> <p>To pick up any changes to the SystemSettings table, the IntegrationService will need to be restarted.</p>"},{"location":"integration/syspro/sdk-provider/#example-systemsettings-in-database","title":"Example SystemSettings in database","text":"Application Key Value Description IntegrationSyspro SysproWriteXML If true, logs XML that would be posted to C drive instead of posting to Syspro IntegrationSyspro Operator Syspro Operator name IntegrationSyspro OperatorPassword Syspro Operator password IntegrationSyspro CompanyId Syspro CompanyID IntegrationSyspro CompanyPassword Syspro Company password IntegrationSyspro SalesOrderPosting Syspro business object to use for SalesOrder posting (SORTBO or SORTOS or ALL) IntegrationSyspro TransferPosting Syspro integration method for Transfers (GIT or INVT) IntegrationSyspro Instance Syspro Instance to use (empty for default) IntegrationSyspro MultipleBins true or false. Set to true when Syspro has multiple bins enabled IntegrationSyspro SerialNumbers true or false. Set to true when Syspro has SerialNumbers enabled"},{"location":"integration/syspro/sdk-provider/#sysprowritexml","title":"SysproWriteXML","text":"<ul> <li>Instead of posting the transaction write to xml. Output will be in root C:</li> </ul>"},{"location":"integration/syspro/sdk-provider/#operator","title":"Operator","text":"<ul> <li>Syspro operator name</li> </ul>"},{"location":"integration/syspro/sdk-provider/#operatorpassword","title":"OperatorPassword","text":"<ul> <li>Syspro operator password</li> </ul>"},{"location":"integration/syspro/sdk-provider/#companyid","title":"CompanyId","text":"<ul> <li>Syspro company name</li> </ul>"},{"location":"integration/syspro/sdk-provider/#companypassword","title":"CompanyPassword","text":"<ul> <li>Syspro company password</li> </ul>"},{"location":"integration/syspro/sdk-provider/#salesorderposting","title":"SalesOrderPosting","text":"<ul> <li>Options: SORTBO / SORTOS / ALL</li> <li>Used By: PICKING</li> <li>SORTBO: post to business object SORTBO</li> <li>SORTOS: post to business object SORTOS</li> <li>ALL: Clear SORTBO, post SORTBO, post SORTOS</li> </ul>"},{"location":"integration/syspro/sdk-provider/#transferposting","title":"TransferPosting","text":"<ul> <li>Options: INVT / GIT</li> <li>Used By: TRANSFER (TRANSFER / INTRANSIT / RECEIPT)</li> </ul>"},{"location":"integration/syspro/sdk-provider/#instance","title":"Instance","text":"<ul> <li>The instance to use when connecting to Syspro</li> <li>Leave empty for default</li> </ul>"},{"location":"integration/syspro/sdk-provider/#multiplebins","title":"MultipleBins","text":"<ul> <li>Not fully implemented</li> <li>Set to true when Syspro has multiple bins enabled</li> </ul>"},{"location":"integration/syspro/sdk-provider/#serialnumbers","title":"SerialNumbers","text":"<ul> <li>Not fully implemented</li> <li>Set to true when Syspro has SerialNumbers enabled</li> </ul>"},{"location":"integration/syspro/sdk-provider/#integration-methods","title":"Integration Methods","text":""},{"location":"integration/syspro/sdk-provider/#takeon","title":"TAKEON","text":"<ul> <li>INVTMR. Inventory Receipts</li> </ul> <p>INVTMR Parameters:</p> Parameter Name Value TransactionDate DateTime.Now IgnoreWarnings N ApplyIfEntireDocumentValid Y ValidateOnly N ManualSerialTransfersAllowed N ReturnDetailedReceipt N IgnoreAnalysis Y <p>INVTMRDOC Items mapping:</p> Granite Syspro ToLocation Warehouse Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure"},{"location":"integration/syspro/sdk-provider/#adjustment","title":"ADJUSTMENT","text":"<ul> <li>INVTMA. Inventory Adjustments</li> </ul> <p>INVMA Parameters:</p> Parameter Name Value TransactionDate DateTime.Now PhysicalCount N PostingPeriod C IgnoreAnalysis Y IgnoreWarnings N ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMADOC Items mapping:</p> Granite Syspro ToLocation Warehouse Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure"},{"location":"integration/syspro/sdk-provider/#reclassify","title":"RECLASSIFY","text":"<ul> <li>Not implemented/supported</li> </ul>"},{"location":"integration/syspro/sdk-provider/#replenish","title":"REPLENISH","text":"<ul> <li>INVTMO. Inventory Warehouse Transfer</li> </ul> <p>INVTMO Parameters:</p> Parameter Name Value IgnoreWarnings Y CreateDestinationWarehouse N ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMODOC Items mapping:</p> Granite Syspro Behaviour Immediate Set to Y NoDestination Set to N FromLocation FromWarehouse ToLocation ToWarehouse Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure"},{"location":"integration/syspro/sdk-provider/#transfer","title":"TRANSFER","text":"<p>Based on setting TransferPosting (INVT or GIT)</p> <ul> <li>INVT<ul> <li>TRANSFER/INTRANSIT: INVTMO</li> <li>RECEIPT: INVTMI</li> </ul> </li> <li>GIT <ul> <li>TRANSFER/INTRANSIT: SORTBO</li> <li>RECEIPT: INVTMN</li> </ul> </li> </ul> <p>INVTMO Parameters:</p> Parameter Name Value IgnoreWarnings Y CreateDestinationWarehouse N ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMODOC Items mapping:</p> Granite Syspro Behaviour Immediate Set to Y NoDestination Set to N DocumentDescription Reference FromLocation FromWarehouse ToLocation ToWarehouse Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure <p>SORTBO Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>SORTBODOC Item mapping:</p> Granite Syspro N ZeroShipQuantity Item8 OrderStatus Document SalesOrder LineNumber SalesOrderLine Code StockCode ToLocation Warehouse ActionQty Quantity Batch Lot UOM UnitOfMeasure <p>INVTMI Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMIDOC Item mapping</p> Granite Syspro DocumentDescription Reference ToLocation Warehouse Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure <p>INVTMN Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMNDOC Item mapping:</p> Granite Syspro LineNumber Key.LineNumber ToLocation Key.TargetWarehouse FromLocation Key.SourceWarehouse DocumentDescription Key.GtrReference ActionQty Quantity"},{"location":"integration/syspro/sdk-provider/#move","title":"MOVE","text":"<ul> <li>INVTMO. Inventory Warehouse Transfer</li> </ul> <p>INVTMO Parameters:</p> Parameter Name Value IgnoreWarnings Y CreateDestinationWarehouse N ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMODOC Items mapping:</p> Granite Syspro Behaviour Immediate Set to Y NoDestination Set to N FromLocation FromWarehouse ToLocation ToWarehouse Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure"},{"location":"integration/syspro/sdk-provider/#scrap","title":"SCRAP","text":"<ul> <li>INVTMA. Inventory Adjustments</li> </ul> <p>INVMA Parameters:</p> Parameter Name Value TransactionDate DateTime.Now PhysicalCount N PostingPeriod C IgnoreAnalysis Y IgnoreWarnings N ApplyIfEntireDocumentValid Y ValidateOnly N <p>INVTMADOC Items mapping:</p> Granite Syspro Code StockCode ActionQty Quantity Batch Lot UOM UnitOfMeasure ToLocation Warehouse"},{"location":"integration/syspro/sdk-provider/#pick","title":"PICK","text":"<p>Based on setting SalesOrderPosting (SORTBO/SORTOS/ALL)</p> <ul> <li>SORTBO<ul> <li>SORTBO PostSorBackOrderRelease</li> </ul> </li> <li>SORTOS<ul> <li>SORTOS PostSorOrderStatus</li> </ul> </li> <li>ALL<ul> <li>SORTBO PostSorBackOrderRelease Clear (Set qty 0)</li> <li>SORTBO PostSorBackOrderRelease set qty from Granite</li> <li>SORTOS PostSorOrderStatus</li> <li>SORTIC PostSalesOrderInvoice</li> </ul> </li> </ul>"},{"location":"integration/syspro/sdk-provider/#sortbo-setting","title":"SORTBO Setting","text":"<p>SORTBO Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>SORTBODOC Item mapping:</p> Granite Syspro Behaviour ZeroShipQuantity Set to N ReleaseFromShip Set to N OrderStatus Set to Item8 Document SalesOrder LineNumber SalesOrderLine Code StockCode ToLocation Warehouse ActionQty Quantity Batch Lot UOM UnitOfMeasure"},{"location":"integration/syspro/sdk-provider/#sortos-setting","title":"SORTOS Setting","text":"<p>SORTOS Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>SORTOSDOC Item mapping:</p> Granite Syspro Behaviour OrderStatus Set to Item NewOrderStatus Set to Item8 Document SalesOrder"},{"location":"integration/syspro/sdk-provider/#all-setting","title":"ALL Setting","text":"<p>Clear SORTBO Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>Clear SORTBODOC Item mapping:</p> Granite Syspro Behaviour CompleteLine Set to N ReleaseFromMultipleLines Set to N AdjustOrderQuantity Set to N ZeroShipQuantity Set to Y ReleaseFromShip Set to Y OrderStatus Set to N Document SalesOrder LineNumber SalesOrderLine Code StockCode ToLocation Warehouse Quantity Set to 0 Batch Lot UOM UnitOfMeasure <p>SORTBO Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>SORTBODOC Item mapping:</p> Granite Syspro Behaviour ZeroShipQuantity Set to N ReleaseFromMultipleLines Set to N AdjustOrderQuantity Set to N OrderStatus Set to N ReleaseFromShip Set to N AllocateSerialNumbers Set to N Document SalesOrder LineNumber SalesOrderLine Code StockCode ToLocation Warehouse ActionQty Quantity Batch Lot UOM UnitOfMeasure <p>SORTOS Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>SORTOSDOC Item mapping:</p> Granite Syspro Behaviour OrderStatus Set to Item OrderStatus Set to Item8 Document SalesOrder <p>SORTIC Parameters:</p> Parameter Name Value IgnoreWarnings Y ApplyIfEntireDocumentValid Y ValidateOnly N <p>SORTICDOC Item mapping:</p> Granite Syspro Behaviour Document SalesOrder LineNumber SalesOrderLineList Comma separated list of line numbers"},{"location":"integration/syspro/sdk-provider/#receive","title":"RECEIVE","text":"<ul> <li>PORTOR. Purchase Order Receipts</li> </ul> <p>PORTOR Parameters:</p> Parameter Name Value TransactionDate Empty string IgnoreWarnings Y GRNMatchingAction A ApplyIfEntireDocumentValid Y ValidateOnly N ManualSerialTransfersAllowed N IgnoreAnalysis Y <p>PORTORDOC Item mapping:</p> Granite Syspro Behaviour ReceiptFromInspection Set to null ReceiptIntoInspection Set to null Receipt.SwitchOnGRNMatching Set to N Receipt.Units Set to empty string Receipt.Cost Set to empty string Receipt.CostBasis Set to P Receipt.DeliveryNote Set to empty string Document Receipt.PurchaseOrder LineNumber Receipt.PurchaseOrderLine Code Receipt.StockCode ActionQty Receipt.Quantity UOM Receipt.UnitOfMeasure Comment Receipt.Reference ToLocation Receipt.Warehouse Batch Receipt.Lot ExpiryDate Receipt.LotExpiryDate"},{"location":"integration/syspro/sdk-provider/#dynamicpick","title":"DYNAMICPICK","text":"<ul> <li>Not Implemented/supported</li> </ul>"},{"location":"label-printing/bartender/manual/","title":"Bartender","text":"<p>The Bartender LabelPrint service is a Window Service that enables other Granite applications to print Bartender labels.</p> <p>Each type of label that can be printed has a corresponding SQL view that returns the information/data that displays on the label. The application will query this view with a key (Barcode, Item Code, etc) to fetch the relevant information. After that, the application will map the data returned by the SQL view to the matching Named Data Source in the Bartender label format. </p> <p>Supported Bartender Versions:</p> <ul> <li> <p>32 bit versions</p> <ul> <li>10.1 R1, R4</li> <li>2016, R1, R4</li> </ul> </li> <li> <p>64 bit versions</p> <ul> <li>2016 R9</li> <li>2019 R6, R10</li> <li>2020</li> <li>2021, R7 </li> </ul> </li> </ul>"},{"location":"label-printing/bartender/manual/#setup","title":"Setup","text":""},{"location":"label-printing/bartender/manual/#prerequisites","title":"Prerequisites","text":"<ul> <li>Bartender</li> <li>.NET Framework 4.5</li> </ul>"},{"location":"label-printing/bartender/manual/#installation","title":"Installation","text":"<ol> <li> <p>Check the version of Bartender that is currently installed. You can check by opening Bartender Designer, and selecting Help -&gt; About. Take note of the release number ant the bitness as shown here:</p> <p></p> </li> <li> <p>Copy the version of GraniteLabelPrinting that matches the bitness of Bartender that you have installed.</p> </li> <li> <p>In the <code>Granite.LabelPrinting.exe.config</code> file, configure your connection string to the Granite database     <pre><code>&lt;connectionStrings&gt;\n    &lt;add name=\"CONNECTION\" connectionString=\"Data Source=.\\;Initial Catalog=Granite;Persist Security Info=True;User ID=******;Password=****\" providerName=\"System.Data.SqlClient\" /&gt;\n&lt;/connectionStrings&gt;\n</code></pre></p> </li> <li> <p>In the <code>Granite.LabelPrinting.exe.config</code> file, configure your <code>EndPoint</code> setting. This is the address that the LabelPrintService will run on.     <pre><code>&lt;add key=\"EndPoint\" value=\"http://localhost:2077/\"/&gt;\n</code></pre></p> </li> <li> <p>In the <code>Granite.LabelPrinting.exe.config</code> file, ensure that the <code>Provider</code> setting is set to <code>Bartender</code> <pre><code>&lt;add key=\"Provider\" value=\"Bartender\"/&gt; \n</code></pre></p> </li> <li> <p>Run <code>Granite.LabelPrinting.exe</code> and follow the instructions to complete the install. </p> </li> </ol> <p>Note</p> <p>It is advisable to run the service from the console and test print before installing as a service.</p> <p>You may need to run the the Granite Label Printing service as administrator, depending on the permissions yor user account has.</p>"},{"location":"label-printing/bartender/manual/#app-settings","title":"App Settings","text":""},{"location":"label-printing/bartender/manual/#endpoint","title":"EndPoint","text":"<p>The endpoint address of the printing service. Hosted via windows service. <pre><code>&lt;add key=\"EndPoint\" value=\"http://localhost:2077/\"/&gt;\n</code></pre></p>"},{"location":"label-printing/bartender/manual/#provider","title":"Provider","text":"<p>Provider options ZPL OR Bartender. </p> <p><code>Take Note</code> while this service is still capable of printing ZPL labels, it is highly advised to use the new IIS ZPL Label Print Service instead.  ZPL printing via this service will not receive any further support, and will eventually be removed.  If you do choose to use this service to print ZPL labels, nsure that the default labels below is relevant to your provider. The extension and file needs to be setup correctly .zpl or .btw </p> <pre><code>&lt;add key=\"Provider\" value=\"Bartender\"/&gt;  &lt;!--Bartender or ZPL--&gt;\n</code></pre>"},{"location":"label-printing/bartender/manual/#printername","title":"PrinterName","text":"<p>Default printer for the instance of the service, you can override the windows default printer by specifying a printer name. <pre><code>&lt;add key=\"PrinterName\" value=\"\"/&gt;\n</code></pre></p>"},{"location":"label-printing/bartender/manual/#printernameerrorlabel","title":"PrinterNameErrorLabel","text":"<p>Printer name for error label printing. If configured a label with information about the application error will print. This will typical be the error you see on the screen but just printed out. Used to keep track of errors. <pre><code>&lt;add key=\"PrinterNameErrorLabel\" value=\"\"/&gt;\n</code></pre></p>"},{"location":"label-printing/bartender/manual/#defaultlabelpath","title":"DefaultLabelPath","text":"<p>Path to the default labels location <pre><code>&lt;add key=\"DefaultLabelPath\" value=\"C:\\Program Files\\Common Files\\Cradle Technology Services\\Granite\\Labels\\\"/&gt;\n</code></pre></p>"},{"location":"label-printing/bartender/manual/#settings-label-configuration","title":"Settings Label configuration","text":"<p>The tables below documents all the appsettings related to changing the label format and data.  Each Default label is linked to a setting that below that configures the SQL view.</p> <p><code>Settings for label path (.btw or .zpl)</code></p> Key Value Setting name for SQL View DefaultTrackingEntityLabel TrackingEntity.btw ViewTrackingEntityLabel DefaultMasterItemLabel MasterItem.btw ViewMasterItemLabel DefaultLocationLabel Location.btw ViewLocationLabel DefaultUserLabel User.btw ViewUserLabel DefaultPalletLabel Pallet.btw PalletLabel DefaultBoxLabel Box.btw ViewBoxLabel <p><code>Settings for label data (SQL view)</code></p> Key Value (SQl View Name) ViewTrackingEntityLabel Label_TrackingEntity ViewMasterItemLabel Label_MasterItem ViewLocationLabel Label_Location ViewUserLabel Label_Users PalletLabel Label_Pallet ViewBoxLabel Label_Box"},{"location":"label-printing/bartender/manual/#logging","title":"Logging","text":"<p>Logging can be configured in the nlog.config file</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      autoReload=\"true\"\n      internalLogLevel=\"Info\"\n      internalLogFile=\"c:\\temp\\internal-nlog-AspNet.txt\"&gt;\n\n    &lt;!-- enable asp.net core layout renderers --&gt;\n    &lt;extensions&gt;\n        &lt;add assembly=\"NLog.Web\"/&gt;\n    &lt;/extensions&gt;\n\n    &lt;targets&gt;\n    &lt;target xsi:type=\"File\"\n        name=\"applicationLogs\"\n        fileName=\"Granite.LabelPrinting.log\"\n        layout=\"${longdate}|${event-properties:item=EventId:whenEmpty=0}|${level:uppercase=true}|${mdlc:userName}|${logger}|${message} ${exception:format=tostring}\"\n        archiveFileName=\"Granite.LabelPrinting.{#}.log\"\n        archiveNumbering=\"DateAndSequence\"\n        archiveEvery=\"Day\"\n        archiveAboveSize=\"10485760\"\n        archiveDateFormat=\"yyyy-MM-dd\"\n        maxArchiveFiles=\"7\" /&gt;\n        &lt;!-- File Target for own log messages with extra web details using some ASP.NET core renderers --&gt;\n    &lt;target xsi:type=\"File\"\n        name=\"innerWorkingsLogs\"\n        fileName=\"Granite.LabelPrinting-${shortdate}.Inner.log\"\n        layout=\"${longdate}|${event-properties:item=EventId:whenEmpty=0}|${level:uppercase=true}|${logger}|${mdlc:userName}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action}|${callsite}\" /&gt;\n\n    &lt;target xsi:type=\"Console\"\n        name=\"lifetimeConsole\"\n        layout=\"${MicrosoftConsoleLayout}\" /&gt;\n    &lt;/targets&gt;\n    &lt;rules&gt;\n        &lt;!-- minlevel=\"Error\"--&gt;\n        &lt;!-- minlevel=\"Info\"--&gt;\n        &lt;logger name=\"*\" minlevel=\"Error\" writeTo=\"applicationLogs\" /&gt;\n    &lt;/rules&gt;\n&lt;/nlog&gt;\n</code></pre> <p>The minlevel setting near the end of the file is what determines how much information is logged. You can set it to Info or Error</p>"},{"location":"label-printing/zpl/manual/","title":"ZPL","text":""},{"location":"label-printing/zpl/manual/#setup","title":"Setup","text":""},{"location":"label-printing/zpl/manual/#prerequisites","title":"Prerequisites","text":"<ul> <li>IIS</li> </ul>"},{"location":"label-printing/zpl/manual/#installation","title":"Installation","text":"<ul> <li> <p>Ensure that the folder that you have installed GraniteLabelPrintingZPL to has full access enabled for all users. This will ensure that the application log files can be created</p> </li> <li> <p>Add GraniteLabelPrintingZPL to IIS</p> </li> </ul> <p>Note</p> <p>Take note of the new <code>IsPublic</code> setting in the <code>appsettings.json</code> file below. This is used to configure security settings for the site. If set to false you can run GraniteLabelPrintingZPL as http instead of https</p> <p>If you are running GraniteLabelPrintingZPL as https, you can use the same certificate as the WebDesktop</p>"},{"location":"label-printing/zpl/manual/#appsettings","title":"AppSettings","text":"<p>The appsettings.json file is where you configure the application. </p> <p>The Width and Height for each label do not affect the size that the label prints at. These parameters actually set the size that label previews render at</p> <p>If you are running GraniteLabelPrintingZPL as https, AllowedOrigins must specify all addresses that can print to the LabelPrintService. You should include WebApp, Webservice, WebDesktop, and RepoAPI as needed.</p> <pre><code>{\n  \"ConnectionStrings\": {\n    \"CONNECTION\": \"Data Source=.\\\\SQL2019;Initial Catalog=Granite;Persist Security Info=True;User ID=username;Password=password\"\n  },\n  \"IsPublic\":  false,\n  \"AllowedOrigins\": [ \"https://my-pcname:40099\", \"http://my-pcname:40081\", \"http://my-pcname:40086\" ],\n  \"DefaultLabelPath\": \"C:\\\\Program Files (x86)\\\\Granite WMS\\\\Labels\\\\\",\n  \"PrinterName\": \"REC\",\n  \"DefaultTrackingEntityLabel\": {\n    \"ViewName\": \"Label_TrackingEntity\",\n    \"LabelName\": \"TrackingEntity.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"30\"\n  },\n  \"DefaultMasterItemLabel\": {\n    \"ViewName\": \"Label_MasterItem\",\n    \"LabelName\": \"MasterItem.zpl\",\n    \"Width\": \"75\",\n    \"Height\": \"20\"\n  },\n  \"DefaultLocationLabel\": {\n    \"ViewName\": \"Label_Location\",\n    \"LabelName\": \"Location.zpl\",\n    \"Width\": \"80\",\n    \"Height\": \"40\"\n  },\n  \"DefaultUserLabel\": {\n    \"ViewName\": \"Label_Users\",\n    \"LabelName\": \"User.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  },\n  \"DefaultPalletLabel\": {\n    \"ViewName\": \"Label_Pallet\",\n    \"LabelName\": \"Pallet.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  },\n  \"DefaultBoxLabel\": {\n    \"ViewName\": \"Label_Box\",\n    \"LabelName\": \"Box.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  },\n  \"DefaultErrorLabel\": {\n    \"ViewName\": \"\",\n    \"LabelName\": \"ErrorLabel.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  },\n  \"ViewTrackingEntityLabel\": \"Label_TrackingEntity\",\n  \"ViewMasterItemLabel\": \"Label_MasterItem\",\n  \"ViewLocationLabel\": \"Label_Location\",\n  \"ViewUserLabel\": \"Label_Users\",\n  \"ViewPalletLabel\": \"Label_Pallet\",\n  \"ViewBoxLabel\": \"Label_Box\",\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Microsoft.AspNetCore\": \"Warning\"\n    }\n  },\n  \"AllowedHosts\": \"*\"\n}\n</code></pre>"},{"location":"label-printing/zpl/manual/#logging","title":"Logging","text":"<p>Logging can be configured in the nlog.config file</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      autoReload=\"true\"\n      internalLogLevel=\"Info\"\n      internalLogFile=\"c:\\temp\\internal-nlog-AspNet.txt\"&gt;\n\n    &lt;!-- enable asp.net core layout renderers --&gt;\n    &lt;extensions&gt;\n        &lt;add assembly=\"NLog.Web\"/&gt;\n    &lt;/extensions&gt;\n\n    &lt;targets&gt;\n        &lt;target xsi:type=\"File\" \n            name=\"applicationLogs\" \n            fileName=\"GraniteLabelPrintingZPL.log\"\n            layout=\"${longdate}|${event-properties:item=EventId:whenEmpty=0}|${level:uppercase=true}|${mdlc:userName}|${logger}|${message} ${exception:format=tostring}\" \n            archiveFileName=\"GraniteLabelPrintingZPL.{#}.log\"\n            archiveNumbering=\"DateAndSequence\"\n            archiveEvery=\"Day\"\n            archiveAboveSize=\"10485760\"\n            archiveDateFormat=\"yyyy-MM-dd\"\n            maxArchiveFiles=\"7\" /&gt;\n\n        &lt;!-- File Target for own log messages with extra web details using some ASP.NET core renderers --&gt;\n        &lt;target xsi:type=\"File\" \n            name=\"innerWorkingsLogs\" \n            fileName=\"GraniteLabelPrintingZPL-${shortdate}.Inner.log\"\n            layout=\"${longdate}|${event-properties:item=EventId:whenEmpty=0}|${level:uppercase=true}|${logger}|${mdlc:userName}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action}|${callsite}\" /&gt;\n\n        &lt;!--Console Target for hosting lifetime messages to improve Docker / Visual Studio startup detection --&gt;\n        &lt;target xsi:type=\"Console\" name=\"lifetimeConsole\" layout=\"${MicrosoftConsoleLayout}\" /&gt;\n    &lt;/targets&gt;\n    &lt;rules&gt;\n        &lt;!-- minlevel=\"Error\"--&gt;\n        &lt;!-- minlevel=\"Info\"--&gt;\n        &lt;logger name=\"*\" minlevel=\"Error\" writeTo=\"applicationLogs\" /&gt;\n    &lt;/rules&gt;\n&lt;/nlog&gt;\n</code></pre> <p>The minlevel setting near the end of the file is what determines how much information is logged. You can set it to Info or Error</p>"},{"location":"label-printing/zpl/manual/#label-preview","title":"Label Preview","text":""},{"location":"label-printing/zpl/manual/#previewing-a-template","title":"Previewing a template","text":"<p>You can preview a label by browsing to https://[hostname]:[port number]/preview/[Label key] </p> <p>[LabelKey] must be one of the label types from the appsettings.json file:</p> <pre><code>\"DefaultTrackingEntityLabel\": {\n    \"ViewName\": \"Label_TrackingEntity\",\n    \"LabelName\": \"TrackingEntity.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"30\"\n  },\n  \"DefaultMasterItemLabel\": {\n    \"ViewName\": \"Label_MasterItem\",\n    \"LabelName\": \"MasterItem.zpl\",\n    \"Width\": \"75\",\n    \"Height\": \"20\"\n  },\n  \"DefaultLocationLabel\": {\n    \"ViewName\": \"Label_Location\",\n    \"LabelName\": \"Location.zpl\",\n    \"Width\": \"80\",\n    \"Height\": \"40\"\n  },\n  \"DefaultUserLabel\": {\n    \"ViewName\": \"Label_Users\",\n    \"LabelName\": \"User.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  },\n  \"DefaultPalletLabel\": {\n    \"ViewName\": \"Label_Pallet\",\n    \"LabelName\": \"Pallet.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  },\n  \"DefaultBoxLabel\": {\n    \"ViewName\": \"Label_Box\",\n    \"LabelName\": \"Box.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"20\"\n  }\n</code></pre> <p>For example browsing to https://my-pcname:5001/preview/DefaultTrackingEntityLabel will render the TrackingEntity.zpl label using the dimensions specified in appsettings.json:</p> <p></p>"},{"location":"label-printing/zpl/manual/#previewing-with-data","title":"Previewing with data","text":"<p>By making a LabelDataPreviewRequest (see API metadata), you can view a label template populated with actual data from your database</p> <p>Sample request:</p> <p></p> <p>Response:</p> <p></p>"},{"location":"label-printing/zpl/manual/#troubleshooting","title":"Troubleshooting","text":"<p>If you get an error message relating to ASP.Net when browsing GraniteLabelPrintingZPL, ensure that you have the correct hosting bundle installed. The Webdesktop uses version 5, which will not work with GraniteLabelPrintingZPL. You can safely install version 6 alongside version 5</p> <p>If you are running GraniteLabelPrintingZPL as http, be sure that you have allowed InsecureContent on the WebDesktop:    <pre><code> ...\\Dropbox\\Software Installs\\Granite\\Granite V3.4.4\\Documentation\\WebDesktop Browser Insecure Content.docx\n</code></pre></p> <p>Always be sure to check your GraniteLabelPrintingZPL log file</p>"},{"location":"label-printing/zpl/release-notes/","title":"Release notes","text":""},{"location":"label-printing/zpl/release-notes/#zpl-release-notes","title":"ZPL Release Notes","text":""},{"location":"label-printing/zpl/release-notes/#september-2023-4520","title":"September 2023 (4.5.2.0)","text":""},{"location":"label-printing/zpl/release-notes/#new","title":"New","text":"<ul> <li>(RFC-78) Add validation of printer name</li> </ul>"},{"location":"label-printing/zpl/release-notes/#august-2023-4510","title":"August 2023 (4.5.1.0)","text":""},{"location":"label-printing/zpl/release-notes/#change","title":"Change","text":"<ul> <li>Variables in ZPL file must be prefixed with @</li> </ul>"},{"location":"label-printing/zpl/release-notes/#2-june-2023-4500","title":"2 June 2023 (4.5.0.0)","text":""},{"location":"label-printing/zpl/release-notes/#new_1","title":"New","text":"<ul> <li>Print multiple Pallet labels</li> <li>Print multiple Box labels</li> </ul>"},{"location":"label-printing/zpl/release-notes/#changes","title":"Changes","text":"<ul> <li>Switch from Log4Net to NLog</li> <li>Each class uses own logger instead of logger inherited from BaseService</li> <li>Updated to ServiceStack 6.8.0</li> <li>Switch from ImageSharp to ImageMagick</li> </ul>"},{"location":"label-printing/zpl/release-notes/#06-jan-2023-4201","title":"06 Jan 2023 (4.2.0.1)","text":""},{"location":"label-printing/zpl/release-notes/#new_2","title":"New","text":"<ul> <li>LabelDataPreview allows populating a preview with actual data</li> </ul>"},{"location":"label-printing/zpl/release-notes/#changes_1","title":"Changes","text":"<ul> <li>Default labels in appsettings.json settings changed. Take note LabelName replaces Name. ViewName setting added.     <pre><code>  \"DefaultTrackingEntityLabel\": {\n    \"ViewName\": \"Label_TrackingEntity\",\n    \"LabelName\": \"TrackingEntity.zpl\",\n    \"Width\": \"100\",\n    \"Height\": \"30\"\n  }\n</code></pre></li> <li>Reworked inline SQL to limit injection risk</li> <li>Minor cleaning up</li> </ul>"},{"location":"label-printing/zpl/release-notes/#24-may-2022","title":"24 May 2022","text":"<ul> <li>New appsettings.json setting     <pre><code>\"IsPublic\":  false\n</code></pre></li> </ul>"},{"location":"label-printing/zpl/release-notes/#28-feb-2022","title":"28 Feb 2022","text":"<ul> <li>New Label preview functionality</li> </ul>"},{"location":"repository-api/manual/","title":"Repository API","text":"<p>The primary objective of the Repository API is to offer a unified interface for persisting data into Granite. These operations encompass tasks for creating, reading, updating, and deleting data (CRUD).</p> <p>In addition to serving our applications, third parties can utilize this API to retrieve data for integration purposes.</p> <p>The WebDesktop is the sole Granite application using the Repository API by default.</p>"},{"location":"repository-api/manual/#setup","title":"Setup","text":""},{"location":"repository-api/manual/#requirements","title":"Requirements","text":"<ul> <li>.Net Core 6</li> <li>IIS</li> <li>Sufficient permissions for folder and file access and IIS application creation</li> </ul>"},{"location":"repository-api/manual/#iis-settings","title":"IIS settings","text":"<p><code>Take note</code> WebDAVModule is a installed feature/module of IIS. When WebDAVModule is installed and enable it can cause issues with PUT/DELETE operations. The symptoms will be that you cannot delete or edit any data in the WebDesktop.</p> <p><code>The error you would receive is a 405 Method not allowed.</code></p> <p>Open the web.config file and change the following section. <pre><code>&lt;modules runAllManagedModulesForAllRequests=\"true\"&gt;\n    &lt;remove name=\"WebDAVModule\" /&gt;\n&lt;/modules&gt;\n</code></pre></p>"},{"location":"repository-api/manual/#application-settings","title":"Application Settings","text":"<p>The settings below are configured in the <code>appsettings.json</code>.</p>"},{"location":"repository-api/manual/#connectionstrings-connection","title":"ConnectionStrings [CONNECTION]","text":"<p>Granite database connection string.</p> <pre><code> \"ConnectionStrings\": {\n    \"CONNECTION\": \"Data Source=.;Initial Catalog=Granite;Persist Security Info=True;User ID=Granite\"\n  },\n</code></pre>"},{"location":"repository-api/manual/#allowedorigins","title":"AllowedOrigins","text":"<p>The 'allowed origins' is a list of addresses for applications requiring access to the API.  This may also include third parties utilizing the API.  By default, the only address that requires configuration is the Granite WebDesktop address.</p> <p>Example single address <pre><code>\"AllowedOrigins\": [ \"https://192.168.1.10:8081\" ]\n</code></pre> Example multiple <pre><code>\"AllowedOrigins\": [ \"https://192.168.1.10:8081\", \"https://192.168.1.20:3009\" ],\n</code></pre></p>"},{"location":"repository-api/manual/#datetimeformat","title":"DateTimeFormat","text":"<ul> <li>DateTimeFormat: this needs to be the same as in the WebDesktop appsettings.json, </li> <li>Take Note: the WebDesktop requires capital DD/MM/YYYY and the below format as follows dd'/'MM'/'yyyy</li> <li> <p>This is due to the technology used on the frontend compared to backend</p> </li> <li> <p>The date / time format in all returning data.</p> </li> <li>Date and Times is a combination of your SQL query value and the Web Desktop Grid layout. You need to setup in accordance.</li> </ul> <pre><code>\"DateTimeFormat\": \"MM'/'dd'/'yyyy\",\n</code></pre>"},{"location":"repository-api/manual/#usesamesitecookies","title":"UseSameSiteCookies","text":"<p>Same Site Cookies are a good default to use in your Apps which restricts cookies from being sent cross-site in order to prevent against cross-site request forgery (CSRF) attacks. Cookies are typically sent to third parties in cross origin requests. This can be abused to do CSRF attacks.</p> <p>Default set to true. (value type Boolean) <pre><code>  \"UseSameSiteCookies\": true,\n</code></pre> Disable if 3rd parties need access to the API.  <pre><code>  \"UseSameSiteCookies\": false,\n</code></pre></p>"},{"location":"repository-api/manual/#getting-started","title":"Getting Started","text":"<p>The API is fully documented through the swagger and metadata pages.</p> <ul> <li>Swagger UI (https://Your_Address:port/swagger-ui/)</li> <li>MetaData (https://Your_Address:port/json/metadata/)</li> </ul> <p>To communicate with the API you first need to 'sign in' authorize.</p> <ul> <li>Via the Swagger UI navigate to the POST auth operation.</li> </ul> <p><pre><code>auth =&gt; POST = auth/{provider} \n</code></pre> Enter the username and password in the Body and click [Try it out].</p> <pre><code>{\n  \"UserName\": \"UserName\",\n  \"Password\": \"Password\",\n}\n</code></pre> <p>If the Username and Password was valid you should receive a 200 OK response.</p>"},{"location":"scaffold/manual/","title":"Scaffold","text":"<p>Scaffold is a straightforward command line interface that makes it easy to install, setup, and configure Granite WMS.</p>"},{"location":"scaffold/manual/#requirements","title":"Requirements","text":"<p>Before you get started, ensure that you have done the following: </p> <ul> <li> <p>All Granite applications (including Scaffold) that you want to install are copied to the folder where they will be installed.</p> <p>Scaffold looks for applications to install in the parent folder of the Scaffold application.  This means that you need to have everything you want to install already in place before you start Scaffold.</p> </li> <li> <p>The application requires administrative privileges to run.</p> <p>Ensure that you have the necessary permissions. Admin privileges are required to do things like add sites to IIS and change folder permissions for logging.</p> </li> <li> <p>Ensure that a SQL instance is properly configured and you have credentials before starting the installation.</p> <p>Scaffold does not install SQL, but you can use it to run the Granite database create script.  To do this you will need SQL credentials with sysadmin privilege.</p> </li> <li> <p>Ensure that required label printing software (Bartender) and ERP software is already installed.</p> <p>Scaffold does not support installing ERPs or other 3rd party software.</p> </li> </ul>"},{"location":"scaffold/manual/#functionality-menu-options","title":"Functionality (Menu Options)","text":"<ul> <li>View : View existing Granite IIS applications</li> <li>Prerequisites : Check and install prerequisites (IIS, .Net)</li> <li>Database : Create Granite database</li> <li>Install : Install Granite</li> </ul>"},{"location":"scaffold/manual/#view","title":"View","text":"<p>Show all applications currently hosted in IIS. From here you can also easily select sites to remove from IIS.</p>"},{"location":"scaffold/manual/#prerequisites","title":"Prerequisites","text":"<p>Allows you to install and configure IIS and .NET Hosting bundles.</p> <p>Running the IIS install option will install the following components:</p> <ul> <li>IIS-WebServerRole</li> <li>IIS-WebServer</li> <li>IIS-CommonHttpFeatures</li> <li>IIS-HttpErrors</li> <li>IIS-HttpRedirect</li> <li>IIS-ApplicationDevelopment</li> <li>IIS-ManagementConsole</li> <li>NetFx4Extended-ASPNET45</li> <li>IIS-NetFxExtensibility45</li> <li>IIS-ISAPIExtensions</li> <li>IIS-ISAPIFilter</li> <li>IIS-ASPNET45</li> <li>IIS-ApplicationInit</li> <li>URL Rewrite Module</li> </ul> <p>The .NET option will allow you to install the .NET 6 and .NET 8 Hosting bundles. Granite version 5 requires both hosting bundles, but Granite version 6 only requires .NET 8</p>"},{"location":"scaffold/manual/#database","title":"Database","text":"<p>Allows you to run the Granite database create script against a SQL server connection.  This can be useful if SQL Server Management Studio is not yet installed.</p>"},{"location":"scaffold/manual/#install","title":"Install","text":"<p>When you install applications using Scaffold, you will specify an Environment name to install.  The Environment name becomes the prefix for the sites in IIS, this makes it easy to see which applications are connected to each other at a glance - especially when there are multiple installs (e.g. TEST and LIVE).</p> <p>As you progress through the installation process, you will be prompted for SQL connection details, SSL certificate details, and port numbers for each of the applications being installed.</p> <p>Scaffold will configure the connection strings for all of the applications being installed, as well configuring the endpoints in each of the configuration files and SystemSettings table.</p> <p>Any out of the ordinary settings in IIS that are required for specific applications (e.g. the Scheduler app pool settings) will also be configured.</p>"},{"location":"scheduler/manual/","title":"Manual","text":"<p>The Granite Scheduler is an IIS application that can be used to schedule execution of SQL stored procedures, sending emails using the Utility API, and special integration jobs for fetching documents from ERP systems.</p>"},{"location":"scheduler/manual/#setup","title":"Setup","text":""},{"location":"scheduler/manual/#prerequisites","title":"Prerequisites","text":"<ul> <li>IIS</li> <li>.NET 6 Web Hosting bundle</li> <li>Database tables:<ul> <li><code>ScheduledJobs</code></li> <li><code>ScheduledJobsHistory</code></li> <li><code>ScheduledJobInput</code></li> <li><code>SystemSettings</code></li> </ul> </li> </ul>"},{"location":"scheduler/manual/#installation","title":"Installation","text":"<ul> <li> <p>Ensure that your SystemSettings table contains the default settings that GraniteScheduler uses:  <pre><code>INSERT [dbo].[SystemSettings] ([Application], [Key], [Value], [Description], [ValueDataType], [isEncrypted], [isActive], [AuditDate], [AuditUser])\nVALUES  ('GraniteScheduler', 'TimeZone', '', 'The time zone that will be used when scheduling CRON jobs', 'string', 0, 1, GETDATE(), 'AUTOMATION'),\n        ('GraniteScheduler', 'UtilityApiUrl', '', 'The UtilityAPI URL', 'string', 0, 1, GETDATE(), 'AUTOMATION')\n</code></pre></p> </li> <li> <p>Ensure that the folder that you have installed GraniteScheduler to has full access enabled for all users. This will ensure that the application log files can be created</p> </li> <li> <p>Add GraniteScheduler to IIS running as <code>https</code></p> </li> </ul>"},{"location":"scheduler/manual/#appsettings","title":"Appsettings","text":"<p>Configure your database connection in appsettings.json: <pre><code>  \"ConnectionStrings\": {\n    \"GraniteConnection\": \"Server=.\\\\sql2019dev;Database=GraniteLIVE;User ID=username;Password=password;\"\n  }\n</code></pre></p>"},{"location":"scheduler/manual/#iis","title":"IIS","text":"<p>In order for GraniteScheduler to start up when the server boots up, ensure that the IIS Application Initilization module is installed:</p> <p></p> <p>Next, go to Application Pools in IIS, right click the GraniteScheduler application pool and select Advanced Settings.</p> <p>Ensure that you set the Start Mode to AlwaysRunning and the Idle Time-Out to 0:</p> <p></p> <p>Right click the application pool again and select Recycling. Untick the Regular Intervals checkbox:</p> <p></p> <p>Now right click on the GraniteScheduler site in the left pane, go to Manage Website and select Advanced Settings. Change Preload Enabled to true</p> <p></p>"},{"location":"scheduler/manual/#logging","title":"Logging","text":"<p>Logging can be configured in the nlog.config file</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      autoReload=\"true\"\n      internalLogLevel=\"Info\"\n      internalLogFile=\"c:\\temp\\internal-nlog-AspNet.txt\"&gt;\n\n    &lt;!-- enable asp.net core layout renderers --&gt;\n    &lt;extensions&gt;\n        &lt;add assembly=\"NLog.Web\"/&gt;\n    &lt;/extensions&gt;\n\n    &lt;targets&gt;\n    &lt;target xsi:type=\"File\"\n        name=\"applicationLogs\"\n        fileName=\"Granite.Scheduler.log\"\n        layout=\"${longdate}|${event-properties:item=EventId:whenEmpty=0}|${level:uppercase=true}|${mdlc:userName}|${logger}|${message} ${exception:format=tostring}\"\n        archiveFileName=\"Granite.Scheduler.{#}.log\"\n        archiveNumbering=\"DateAndSequence\"\n        archiveEvery=\"Day\"\n        archiveAboveSize=\"10485760\"\n        archiveDateFormat=\"yyyy-MM-dd\"\n        maxArchiveFiles=\"7\" /&gt;\n        &lt;!-- File Target for own log messages with extra web details using some ASP.NET core renderers --&gt;\n    &lt;target xsi:type=\"File\"\n        name=\"innerWorkigsLogs\"\n        fileName=\"Granite.Scheduler-${shortdate}.Inner.log\"\n        layout=\"${longdate}|${event-properties:item=EventId:whenEmpty=0}|${level:uppercase=true}|${logger}|${mdlc:userName}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action}|${callsite}\" /&gt;\n\n    &lt;target xsi:type=\"Console\"\n        name=\"lifetimeConsole\"\n        layout=\"${MicrosoftConsoleLayout}\" /&gt;\n    &lt;/targets&gt;\n    &lt;rules&gt;\n        &lt;!-- minlevel=\"Error\"--&gt;\n        &lt;!-- minlevel=\"Info\"--&gt;\n        &lt;logger name=\"*\" minlevel=\"Error\" writeTo=\"applicationLogs\" /&gt;\n    &lt;/rules&gt;\n&lt;/nlog&gt;\n</code></pre> <p>To configure the level of logging, set the minlevel value for logger name=\"*\" in the rules section.</p>"},{"location":"scheduler/manual/#config-page","title":"Config page","text":"<p>Once you have set up GraniteScheduler as described above, be sure to browse to the <code>/config</code> page to check that everything is configured correctly and that the application is connecting to the Granite database</p> <p>Here is an example of a config page after some jobs have been added to the ScheduledJobs table:</p> <p></p>"},{"location":"scheduler/manual/#how-it-works","title":"How it works","text":"<p>Granite Scheduler picks up jobs from the <code>ScheduledJobs</code> table and executes them based on the configured schedule.  When a job executes, the Scheduler will check for any inputs in the <code>ScheduledJobInputs</code> table.  After the job has executed, an entry is logged in the <code>ScheduledJobsHistory</code> table. Here you can see the result of the execution, as well as what inputs were used when executing the job.</p> <p>For more information on what you can do with job inputs, see the job types section for the details of what each job type can do.</p>"},{"location":"scheduler/manual/#configuring-schedules","title":"Configuring Schedules","text":"<p>In this section we'll take a look at the various ways you can configure recurring jobs, as well as how to configure once off jobs.</p>"},{"location":"scheduler/manual/#interval","title":"Interval","text":"<p>The simplest way to set up your schedule is using a timed interval. To do this, set your <code>IntervalFormat</code> to one of the following:</p> <ul> <li>Seconds</li> <li>Minutes</li> <li>Hours</li> </ul> <p>Then set the <code>Interval</code> column to the number of seconds, minutes, or hours you want the job to recur on.</p> <p>This is how we would set a procedure to execute every ten minutes:</p> ID isActive JobName JobDescription Type StoredProcedure Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 1 True SyncDocuments Fetch documents from ERP STOREDPROCEDURE SyncProcedure 10 MINUTES NULL NULL NULL 2022-05-23 08:35:50.427 0"},{"location":"scheduler/manual/#cron-expressions","title":"CRON Expressions","text":"<p>CRON expressions are what will allow us to schedule jobs to run at a specific time of day and even on specific days of the week. </p> <p>They can be a little tricky to get right, but the basics are that there are 5 places (separated by spaces) where you can specify values, each corresponding to a different measure of time:</p> <p><pre><code>* * * * *\n| | | | |_ day of week\n| | | |___ month\n| | |_____ day of month\n| |_______ hour\n|_________ minute\n</code></pre> So for example if we want to send a mail at 9:30am every Monday we woud use this: <pre><code>30 09 * * 1\n</code></pre> You can also specify ranges. So to run a job every 2nd hour of every weekday between 8am and 5pm we could do this: <pre><code>0 08-17/2 * * 1-5\n</code></pre></p> <p>To use a CRON expression on your job, set your <code>IntervalFormat</code> to CRON and put your expression (with spaces) in the <code>Interval</code> field. For example:</p> ID isActive JobName JobDescription Type StoredProcedure Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 1 True SendMondayReport Job to send reports EMAIL EmailExample 30 09 * * 1 CRON NULL NULL NULL 2022-05-23 08:35:50.427 0 <p>Note</p> <p>There are different implementations of CRON syntax, some have special tags that are not usable outside of that specific software.</p> <p>Your best bet is to use https://crontab.guru/ to work out an expression that works for you while avoiding any tags marked as non-standard</p> <p>Be sure to test your CRON expression before deploying! </p> <p>If your CRON expression is not triggering your job as you'd expect it to, try explicitly setting the timezone for the Scheduler to use in the SystemSettings table:</p> <p></p> List of valid time zones <ul> <li>Dateline Standard Time</li> <li>UTC-11</li> <li>Aleutian Standard Time</li> <li>Hawaiian Standard Time</li> <li>Marquesas Standard Time</li> <li>Alaskan Standard Time</li> <li>UTC-09</li> <li>Pacific Standard Time (Mexico)</li> <li>UTC-08</li> <li>Pacific Standard Time</li> <li>US Mountain Standard Time</li> <li>Mountain Standard Time (Mexico)</li> <li>Mountain Standard Time</li> <li>Yukon Standard Time</li> <li>Central America Standard Time</li> <li>Central Standard Time</li> <li>Easter Island Standard Time</li> <li>Central Standard Time (Mexico)</li> <li>Canada Central Standard Time</li> <li>SA Pacific Standard Time</li> <li>Eastern Standard Time (Mexico)</li> <li>Eastern Standard Time</li> <li>Haiti Standard Time</li> <li>Cuba Standard Time</li> <li>US Eastern Standard Time</li> <li>Turks and Caicos Standard Time</li> <li>Paraguay Standard Time</li> <li>Atlantic Standard Time</li> <li>Venezuela Standard Time</li> <li>Central Brazilian Standard Time</li> <li>SA Western Standard Time</li> <li>Pacific SA Standard Time</li> <li>Newfoundland Standard Time</li> <li>Tocantins Standard Time</li> <li>E. South America Standard Time</li> <li>SA Eastern Standard Time</li> <li>Argentina Standard Time</li> <li>Greenland Standard Time</li> <li>Montevideo Standard Time</li> <li>Magallanes Standard Time</li> <li>Saint Pierre Standard Time</li> <li>Bahia Standard Time</li> <li>UTC-02</li> <li>Mid-Atlantic Standard Time</li> <li>Azores Standard Time</li> <li>Cabo Verde Standard Time</li> <li>Coordinated Universal Time</li> <li>GMT Standard Time</li> <li>Greenwich Standard Time</li> <li>Sao Tome Standard Time</li> <li>Morocco Standard Time</li> <li>W. Europe Standard Time</li> <li>Central Europe Standard Time</li> <li>Romance Standard Time</li> <li>Central European Standard Time</li> <li>W. Central Africa Standard Time</li> <li>GTB Standard Time</li> <li>Middle East Standard Time</li> <li>Egypt Standard Time</li> <li>E. Europe Standard Time</li> <li>Syria Standard Time</li> <li>West Bank Gaza Standard Time</li> <li>South Africa Standard Time</li> <li>FLE Standard Time</li> <li>Jerusalem Standard Time</li> <li>South Sudan Standard Time</li> <li>Russia TZ 1 Standard Time</li> <li>Sudan Standard Time</li> <li>Libya Standard Time</li> <li>Namibia Standard Time</li> <li>Jordan Standard Time</li> <li>Arabic Standard Time</li> <li>Turkey Standard Time</li> <li>Arab Standard Time</li> <li>Belarus Standard Time</li> <li>Russia TZ 2 Standard Time</li> <li>E. Africa Standard Time</li> <li>Volgograd Standard Time</li> <li>Iran Standard Time</li> <li>Arabian Standard Time</li> <li>Astrakhan Standard Time</li> <li>Azerbaijan Standard Time</li> <li>Russia TZ 3 Standard Time</li> <li>Mauritius Standard Time</li> <li>Saratov Standard Time</li> <li>Georgian Standard Time</li> <li>Caucasus Standard Time</li> <li>Afghanistan Standard Time</li> <li>West Asia Standard Time</li> <li>Russia TZ 4 Standard Time</li> <li>Pakistan Standard Time</li> <li>Qyzylorda Standard Time</li> <li>India Standard Time</li> <li>Sri Lanka Standard Time</li> <li>Nepal Standard Time</li> <li>Central Asia Standard Time</li> <li>Bangladesh Standard Time</li> <li>Omsk Standard Time</li> <li>Myanmar Standard Time</li> <li>SE Asia Standard Time</li> <li>Altai Standard Time</li> <li>W. Mongolia Standard Time</li> <li>Russia TZ 6 Standard Time</li> <li>Novosibirsk Standard Time</li> <li>Tomsk Standard Time</li> <li>China Standard Time</li> <li>Russia TZ 7 Standard Time</li> <li>Malay Peninsula Standard Time</li> <li>W. Australia Standard Time</li> <li>Taipei Standard Time</li> <li>Ulaanbaatar Standard Time</li> <li>Aus Central W. Standard Time</li> <li>Transbaikal Standard Time</li> <li>Tokyo Standard Time</li> <li>North Korea Standard Time</li> <li>Korea Standard Time</li> <li>Russia TZ 8 Standard Time</li> <li>Cen. Australia Standard Time</li> <li>AUS Central Standard Time</li> <li>E. Australia Standard Time</li> <li>AUS Eastern Standard Time</li> <li>West Pacific Standard Time</li> <li>Tasmania Standard Time</li> <li>Russia TZ 9 Standard Time</li> <li>Lord Howe Standard Time</li> <li>Bougainville Standard Time</li> <li>Russia TZ 10 Standard Time</li> <li>Magadan Standard Time</li> <li>Norfolk Standard Time</li> <li>Sakhalin Standard Time</li> <li>Central Pacific Standard Time</li> <li>Russia TZ 11 Standard Time</li> <li>New Zealand Standard Time</li> <li>UTC+12</li> <li>Fiji Standard Time</li> <li>Kamchatka Standard Time</li> <li>Chatham Islands Standard Time</li> <li>UTC+13</li> <li>Tonga Standard Time</li> <li>Samoa Standard Time</li> <li>Line Islands Standard Time</li> </ul>"},{"location":"scheduler/manual/#run-once","title":"Run once","text":"<p>You can use the ONCE <code>IntervalFormat</code> to schedule a job to run one time only. This is useful for running ad hoc tasks that might take too long to execute within a prescript, or sending once off mails like a picking complete notification.</p> <p>When the <code>IntervalFormat</code> is set to ONCE, the <code>Interval</code> field is not taken into account - it can be left empty.</p> <p>On completion of a ONCE job, the job will be removed from the <code>ScheduledJobs</code> table. It's inputs will also be removed from the <code>ScheduledJobInput</code> table. These are removed after execution regardless of whether the job was successful. </p> <p>The job's execution can still be viewed in the <code>ScheduledJobsHistory</code> table, and you will be able to see it's inputs in JSON format in the Inputs column.</p>"},{"location":"scheduler/manual/#job-types","title":"Job types","text":"<p>This section shows you the basics of configuring each job type in the <code>ScheduledJobs</code> and <code>ScheduledJobInputs</code> tables. The currenlty supported job types are:</p> <ul> <li>Stored Procedure Jobs</li> <li>Email Jobs</li> <li>Injected Jobs</li> <li>SQL Table Jobs</li> </ul>"},{"location":"scheduler/manual/#stored-procedure-jobs","title":"Stored Procedure Jobs","text":"<p>To schedule a Stored Procedure to run, simply add a row to the <code>ScheduledJobs</code> table. For example:</p> ID isActive JobName JobDescription Type StoredProcedure InjectJob Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 1 True MyJob Test job that executes a stored procedure STOREDPROCEDURE MyProcedure NULL 5 MINUTES NULL NULL NULL 2022-05-23 08:35:50.427 0 <p>If you need to pass values from the <code>ScheduledJobInput</code> table into your stored procedure, you can do so by adding the @input table parameter to your stored procedure like this:</p> <pre><code>CREATE OR ALTER PROCEDURE [MyProcedure]\n    @input dbo.ScriptInputParameters READONLY\n</code></pre> <p>The <code>@input</code> table will contain all of the entries from the <code>ScheduledJobInput</code> table that are configured for your job. </p> <p>If your <code>ScheduledJobInput</code> contains the following:</p> ID JobName Name Value 1 MyJob Category PACK 2 MyJob Location REC <p>Inside <code>[MyProcedure]</code> we can fetch the values from <code>@input</code> like this:</p> <pre><code>CREATE OR ALTER PROCEDURE [MyProcedure]\n    @input dbo.ScriptInputParameters READONLY\n\n    DECLARE @Category varchar(50)\n    DECLARE @Location varchar(50)\n\n    SELECT @Category = [Value] FROM @input WHERE [Name] = 'Category'\n    SELECT @Location = [Value] FROM @input WHERE [Name] = 'Location'\n</code></pre>"},{"location":"scheduler/manual/#email-jobs","title":"Email Jobs","text":"<p>Email jobs make use of the Utility API to send emails. Ensure that the <code>UtilityApiUrl</code> entry in <code>SystemSettings</code> is configured correctly before you try to schedule any emails.</p> <p>To schedule an email to be sent, we add a record to the <code>ScheduledJobs</code> table</p> ID isActive JobName JobDescription Type StoredProcedure InjectJob Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 1 True EmailMorningReports Send daily reports to management EMAIL NULL NULL 0 8 * * 1-5 CRON NULL NULL NULL 2022-05-23 08:35:50.427 0 <p>We also need to add some entries to the <code>ScheduledJobInput</code> table to specify recipients, email content, and any attachments we want to send.</p> <p>The parameters available to Email jobs are as follows:</p> Name Required Description Subject Y The subject line of the email EmailTemplate N The name of the email template you want to use. If EmailTemplate is used, the content of the mail will be the rendered template EmailBody N The content of the email you want to send. Use instead of EmailTemplate to send a simple mail using just the text in EmailBody as the body of the email ToEmailAddresses N Semicolon delimited list of email addresses to send the mail to CcEmailAddresses N Semicolon delimited list of email addresses to CC the mail to BccEmailAddresses N Semicolon delimited list of email addresses to BCC the mail to ReportAttachment N SSRS Report path of the report you want to attach ExcelAttachment N Table or view name that you want to attach as an excel sheet FileAttachment N File path of the file you want to attach. NB this path is relative to wherever the Utility API is installed. <p>Let's add the details we need to send our email to the <code>ScheduledJobInput</code> table:</p> ID JobName Name Value 1 EmailMorningReports Subject Morning reports 2 EmailMorningReports EmailBody Please see attached your daily reports 3 EmailMorningReports ToEmailAddresses manager@warehouse.com;finance@warehouse.com 4 EmailMorningReports ReportAttachment /PickingReport 5 EmailMorningReports ReportAttachment /ReceivingReport <p>As you can see, all of the inputs reference job using <code>JobName</code>. For each of the attachment types you can add multiple entries to attach multiple reports of the same type, as we have done here. </p> <p>Note</p> <p>There is no way to pass parameters to SSRS reports that are to be attached to an email.  You may need to edit your report so that it can be executed without the need to pass parameters. Likewise for Excel attachments, it would be best to create a view that returns only the results you want to attach to your email. </p>"},{"location":"scheduler/manual/#injected-jobs-integration-jobs","title":"Injected Jobs (Integration Jobs)","text":"<p>Injected jobs allow us to run code from an external DLL. At the moment the main reason to use this is for integration jobs. More Injectable jobs may be released in the future as required.</p> <p>For this to work, the DLL and an XML provider file must be copied into the root path of the GraniteScheduler:</p> <p></p> <p>The provider file needs to bind the GraniteScheduler IInjectableJob interface to a specific class within your DLL. See the below example of a provider file:</p> <pre><code>&lt;module name=\"Provider\"&gt;\n    &lt;bind\n      service=\"GraniteScheduler.ServiceModel.Types.IInjectableJob, GraniteScheduler.ServiceModel\"\n      to=\"Granite.Integration.Evo.Job.SalesOrder, Granite.Integration.Evo.Job\"/&gt;\n&lt;/module&gt;\n</code></pre> <p>When you configure an InjectedJob the <code>InjectJob</code> field on the <code>ScheduledJobs</code> table must contain the name of the XML provider file (without the file extension) that you wish to use:</p> ID isActive JobName JobDescription Type StoredProcedure InjectJob Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 1 True SalesOrderSync Sync SOs from Evo using IntegrationDocumentQueue INJECTED NULL Granite.Integration.Evo.Job.SalesOrder 1 HOURS NULL NULL NULL 2022-05-23 08:35:50.427 0 <p>GraniteScheduler will use the XML file to find the DLL file and execute the required code</p>"},{"location":"scheduler/manual/#sql-table-jobs","title":"SQL Table JobsRequired JobInputs","text":"<ul> <li>Archive Table Jobs</li> <li>Delete Table Jobs</li> </ul> <p>The following is the information common to the two jobs above. </p> <p>You can get sql insert scripts for example jobs here.</p> <ul> <li><code>TableName</code> (string): The source table to either Archive or Delete from (e.g. <code>MyBigTable</code>). Avoid special characters like <code>;</code>, <code>--</code>, <code>/*</code>. For Delete Table Jobs specifically, only a limited set of tables is allowed and must be provided as the bare table name without schema; see the safety restrictions under Delete Table Jobs.</li> <li><code>WhereTemplate</code> (string): A SQL predicate that filters rows to either Archive or Delete, using parameter placeholders like <code>@FromDate</code>, <code>@Status</code> (e.g. <code>CreatedOn &lt; @Cutoff AND Status = @Status</code>). Injection characters like <code>;</code>, <code>--</code>, <code>/*</code> are rejected.</li> <li><code>WhereParams</code> (JSON object): Name/value map for parameters referenced in <code>WhereTemplate</code>. Values are parsed into appropriate types when possible (null, bool, numbers, Guid, DateTime/DateTimeOffset). Example: <code>{ \"Cutoff\": \"2024-01-01T00:00:00Z\", \"Status\": \"Closed\" }</code>.</li> </ul> <p>If any parameters referenced in <code>WhereTemplate</code> are missing from <code>WhereParams</code> (or vice versa), the job will not run.</p> Optional JobInputs and defaults <ul> <li><code>BatchSize</code> (int, default 1000, valid 1\u201310000): Number of rows to move per batch. The job loops batches until no rows remain or time limit is reached.</li> <li><code>MaxExecutionMinutes</code> (int, default 30, valid 1\u2013480): Upper limit for a single run. The job stops gracefully when the time limit is reached.</li> <li><code>DryRun</code> (bool, default false): If true, estimates and logs the number of rows matching the filter but does not modify any data.</li> <li><code>OptimizeTable</code> (bool, default false): If true and rows were removed, runs table maintenance on the source table after processing.</li> <li><code>OptimizeMode</code> (string, default <code>Reorganize</code>): Table maintenance mode. Accepted values: <code>Reorganize</code>, <code>Rebuild</code>, <code>Auto</code>.</li> <li><code>OnlineIndexRebuild</code> (bool, default true): Applies when <code>OptimizeMode</code> is <code>Rebuild</code>; attempts an ONLINE rebuild when supported.</li> <li><code>UpdateStatisticsAfterOptimization</code> (bool, default depends on mode): After <code>Reorganize</code> default is true; after <code>Rebuild</code> default is false (since rebuild updates stats).</li> <li><code>UpdateStatisticsFullScan</code> (bool, default false): When updating statistics, use FULLSCAN.</li> <li><code>OptimizationThreshold</code> (int, default 1000): Threshold for deciding whether to optimize after data movement. Note: validated by the system; current archive flow optimizes when rows were archived, independent of this threshold.</li> </ul> Date/Time Tokens for WhereParams <p>You can use dynamic, server-local date/time tokens in <code>WhereParams</code> to filter rows relative to \u201cnow\u201d or \u201ctoday\u201d without hard-coding timestamps.</p> <ul> <li>Where they\u2019re used: Only as values within <code>WhereParams</code> (not inside <code>WhereTemplate</code>).</li> <li>What they produce: A <code>DateTimeOffset</code> value bound as a SQL <code>datetimeoffset</code> parameter.</li> <li>Validation: Tokens are validated before execution. Invalid tokens will fail the job\u2019s input validation.</li> </ul> <p>Syntax</p> <ul> <li><code>${base[offsets][|rounding]}</code><ul> <li><code>base</code> (required): <code>now</code> or <code>today</code><ul> <li><code>now</code> = current server local date/time (DateTimeOffset.Now).</li> <li><code>today</code> = current server local date at 00:00:00.000 (midnight).</li> </ul> </li> <li><code>offsets</code> (optional, repeatable): One or more signed adjustments with a unit. Chaining is allowed.<ul> <li>Format: <code>+Nunit</code> or <code>-Nunit</code> (no spaces), where N is an integer.</li> <li>Units (case-sensitive):<ul> <li><code>s</code> = seconds</li> <li><code>m</code> = minutes</li> <li><code>h</code> = hours</li> <li><code>d</code> = days</li> <li><code>w</code> = weeks (7 days each)</li> <li><code>M</code> = months (uppercase M)</li> <li><code>y</code> = years</li> </ul> </li> <li>Examples: <code>-30d</code>, <code>+2h-15m</code>, <code>-1M+7d</code>, <code>-1y</code></li> </ul> </li> <li><code>rounding</code> (optional, after a single <code>|</code>):<ul> <li><code>startOfDay</code> \u2192 00:00:00.000</li> <li><code>endOfDay</code>   \u2192 23:59:59.9999999</li> <li><code>startOfMonth</code> \u2192 first day of month at 00:00:00.000</li> <li><code>endOfMonth</code>   \u2192 last moment of the month (23:59:59.9999999)</li> </ul> </li> </ul> </li> </ul> <p>Evaluation order 1) Start from <code>base</code> (server local time). 2) Apply all <code>offsets</code> left-to-right. 3) Apply <code>rounding</code> if present.</p> <p>Important notes</p> <ul> <li>Units are case-sensitive: <code>m</code> = minutes, <code>M</code> = months.</li> <li>All calculations use the server's local time zone.</li> <li>Multiple offsets can be chained; they are applied in sequence.</li> </ul> <p>Examples</p> <ul> <li>Rows older than 30 days:<ul> <li>WhereTemplate: <code>CreatedOn &lt; @Cutoff</code></li> <li>WhereParams: <code>{ \"Cutoff\": \"${now-30d}\" }</code></li> </ul> </li> <li>All of yesterday (inclusive):<ul> <li>WhereTemplate: <code>CreatedOn &gt;= @From AND CreatedOn &lt;= @To</code></li> <li>WhereParams: <code>{ \"From\": \"${today-1d|startOfDay}\", \"To\": \"${today-1d|endOfDay}\" }</code></li> </ul> </li> <li>First day of last month at midnight:<ul> <li><code>${today-1M|startOfMonth}</code></li> </ul> </li> <li>End of current month:<ul> <li><code>${now|endOfMonth}</code></li> </ul> </li> <li>Two hours and 15 minutes from now:<ul> <li><code>${now+2h-15m}</code></li> </ul> </li> <li>One year ago, end of that month:<ul> <li><code>${now-1y|endOfMonth}</code></li> </ul> </li> </ul> <p>Sample configuration</p> <ul> <li>Purge rows created before the start of the current day:<ul> <li>WhereTemplate: <code>CreatedOn &lt; @Cutoff</code></li> <li>WhereParams: <code>{ \"Cutoff\": \"${today|startOfDay}\" }</code></li> </ul> </li> <li>Archive rows created on or before the end of last month:<ul> <li>WhereTemplate: <code>CreatedOn &lt;= @Cutoff</code></li> <li>WhereParams: <code>{ \"Cutoff\": \"${now-1M|endOfMonth}\" }</code></li> </ul> </li> </ul> <p>Troubleshooting tokens</p> <ul> <li>If a token is malformed (e.g., unknown base, bad unit, or syntax), the job input validation will fail with a log message indicating the problematic parameter.</li> <li>If you need fixed timestamps instead, provide ISO 8601 strings (e.g., \"2025-08-01T00:00:00Z\") instead of a token.</li> </ul>"},{"location":"scheduler/manual/#archive-table-jobs","title":"Archive Table JobsArchive table specific Optional JobInputs and defaultsBehavior and guaranteesExample configuration","text":"<p>Use this job type to move rows from a source table into an archive table in batches, then delete the moved rows from the source. This helps keep operational tables lean while retaining data in an archive table.</p> <ul> <li>Job <code>Type</code>: <code>ARCHIVETABLE</code></li> <li>Connection: Always uses the <code>GraniteConnection</code> from <code>appsettings.json</code>.</li> <li>Archive table name: <code>archive.&lt;TableName&gt;</code> (created automatically if missing, using <code>SELECT INTO</code> from the source structure). Note that indexes, keys, and constraints are not copied by <code>SELECT INTO</code> and may need to be created manually if required.</li> </ul> <ul> <li><code>OptimizeArchiveTable</code> (bool, default false): If true and rows were archived, also runs table maintenance on the archive table.</li> </ul> <ul> <li>Batching and atomicity: Each batch performs INSERT into the archive table and DELETE from the source within a single transaction. If the DELETE fails, the batch is rolled back.</li> <li>Row selection: Uses a CTE to delete from and insert the output into the archive table.</li> <li>Estimation: Before modifying data, the job estimates the row count matching the filter for logging and dry runs.</li> <li>Time cap: The job respects <code>MaxExecutionMinutes</code> and will pause further work when the limit is reached; subsequent scheduler runs continue from where it left off.</li> </ul> <p><code>ScheduledJobs</code> (example):</p> ID isActive JobName JobDescription Type StoredProcedure InjectJob Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 42 True ArchiveOldOrders Move closed orders older than 180 days ARCHIVETABLE NULL NULL 1 HOURS NULL NULL NULL 2025-08-18 08:00:00.000 admin <p><code>ScheduledJobInputs</code> for <code>ArchiveOldOrders</code>:</p> ID JobName Name Value 1 ArchiveOldOrders TableName dbo.Orders 2 ArchiveOldOrders WhereTemplate CreatedOn &lt; @Cutoff AND Status = @Status 3 ArchiveOldOrders WhereParams { \"Cutoff\": \"${now-180d}\", \"Status\": \"Closed\" } 4 ArchiveOldOrders BatchSize 2000 5 ArchiveOldOrders MaxExecutionMinutes 20 6 ArchiveOldOrders DryRun false 7 ArchiveOldOrders OptimizeTable true 8 ArchiveOldOrders OptimizeArchiveTable false 9 ArchiveOldOrders OptimizeMode Reorganize <p>Notes: - The job runs hourly. Adjust <code>Interval</code>/<code>IntervalFormat</code> as needed, or use a CRON schedule. - <code>WhereParams</code> values are parsed into appropriate types; strings can be used when you want literal comparisons. Token-style values like <code>${...}</code> resolve using server local time (e.g., <code>${now-180d}</code>). - The archive table <code>dbo.OrdersArchive</code> is created automatically if it does not exist.</p>"},{"location":"scheduler/manual/#delete-table-jobs","title":"Delete Table JobsBehaviorExample configuration","text":"<p>Use this job type to delete rows from a table in safe, bounded batches using a parameterized WHERE filter.</p> <ul> <li>Job <code>Type</code>: <code>DELETETABLEDATA</code></li> <li>Connection: Uses the <code>GraniteConnection</code> from <code>appsettings.json</code>.</li> </ul> <ul> <li>Estimation: Before deleting, the job estimates the row count matching the filter for logging and dry runs.</li> <li>Batching: Executes <code>DELETE TOP(@BatchSize) ... WHERE {WhereTemplate}</code> repeatedly until no rows match or the time cap is hit. No explicit ORDER BY; when many rows match, the specific rows deleted per batch are not ordered.</li> <li>Time cap: Respects <code>MaxExecutionMinutes</code> and continues on the next scheduled run.</li> <li>Optimization: When enabled, runs post-delete maintenance on the source table using the configured options.</li> </ul> <p>Warning</p> <p>Safety restrictions: Delete Table Jobs are allowlisted to prevent accidental data loss. Only the following tables are permitted:</p> <ul> <li>ScheduledJobsHistory</li> <li>IntegrationLog</li> <li>LabelPrintQueue</li> <li>IntegrationDocumentQueue</li> <li>EmailLog</li> <li>InventoryDailyBalance</li> </ul> <p>Notes: - Provide <code>TableName</code> as shown above (bare table name, no schema). For example, use <code>IntegrationLog</code>, not <code>dbo.IntegrationLog</code>. - Jobs targeting any other table will fail input validation and will not run.</p> <p><code>ScheduledJobs</code> (example):</p> ID isActive JobName JobDescription Type StoredProcedure InjectJob Interval IntervalFormat Status LastExecutionTime LastExecutionResult AuditDate AuditUser 43 True PurgeOldIntegrationLog Delete IntegrationLog rows older than 7 days DELETETABLEDATA NULL NULL 0 2 * * * CRON NULL NULL NULL 2025-08-18 08:00:00.000 admin <p><code>ScheduledJobInputs</code> for <code>PurgeOldIntegrationLog</code>:</p> ID JobName Name Value 1 PurgeOldIntegrationLog TableName IntegrationLog 2 PurgeOldIntegrationLog WhereTemplate AuditDate &lt; @Cutoff 3 PurgeOldIntegrationLog WhereParams { \"Cutoff\": \"${now-7d}\" } 4 PurgeOldIntegrationLog BatchSize 5000 5 PurgeOldIntegrationLog MaxExecutionMinutes 15 6 PurgeOldIntegrationLog DryRun false 7 PurgeOldIntegrationLog OptimizeTable true 8 PurgeOldIntegrationLog OptimizeMode Reorganize <p>Notes: - The CRON example runs daily at 02:00 (server local time). You can use minutes/hours intervals as well. - <code>TableName</code> must be one of the allowlisted tables and provided as a bare name (e.g., <code>IntegrationLog</code>). - <code>WhereParams</code> values can be typed (dates, numbers, booleans) and token-style values like <code>${now-7d}</code> are resolved relative to server local time. - Optimization is optional and only runs if rows were deleted during this run.</p>"},{"location":"scheduler/manual/#troubleshooting","title":"Troubleshooting","text":"<p>If you get an error message relating to ASP.Net when browsing GraniteScheduler, ensure that you have the correct hosting bundle installed.  The Webdesktop uses version 5, which will not work with GraniteScheduler. You can safely install version 6 alongside version 5</p> <p>Always be sure to check your GraniteScheduler log file for more info. If your job is failing, the log will most likely tell you why</p>"},{"location":"scheduler/manual/#tips-tricks-and-reminders","title":"Tips, tricks, and reminders","text":"<ul> <li>If isActive on the ScheduledJob table is set to False the job will not be scheduled to run.</li> <li>The JobName must be unique, it is the value that links ScheduledJobs to ScheduledJobInput</li> <li>You can have multiple inputs per job in the ScheduledJobInput table</li> <li>Status, LastExecutionTime and LastExecutionResult will be updated automatically by GraniteScheduler</li> <li>The ScheduledJobsHistory table will contain an entry for each execution of a job. Think of it as the Transactions table for jobs</li> </ul>"},{"location":"scheduler/release-notes/","title":"Release Notes","text":""},{"location":"scheduler/release-notes/#5000-tba","title":"5.0.0.0 (TBA)","text":""},{"location":"scheduler/release-notes/#changes","title":"Changes","text":"<ul> <li>Email jobs updated to use new Utility API</li> </ul>"},{"location":"scheduler/release-notes/#4510-september-2023","title":"4.5.1.0 (September 2023)","text":""},{"location":"scheduler/release-notes/#changes_1","title":"Changes","text":"<ul> <li>Improved log file archival</li> </ul>"},{"location":"scheduler/release-notes/#4502-27-july-2023","title":"4.5.0.2 (27 July 2023)","text":""},{"location":"scheduler/release-notes/#changes_2","title":"Changes","text":"<ul> <li>Remove execution timeout for Sql jobs.</li> </ul>"},{"location":"scheduler/release-notes/#4500-31-may-2023","title":"4.5.0.0 (31 May 2023)","text":""},{"location":"scheduler/release-notes/#changes_3","title":"Changes","text":"<ul> <li>New setting for EmailAddress</li> <li>Switch from Log4Net to Nlog</li> <li>Update dependencies<ul> <li>ServiceStack 6.8.0</li> <li>Coravel 4.2.1</li> <li>Mailkit 4.0.0</li> <li>EmailValidation 1.0.9</li> </ul> </li> </ul>"},{"location":"scheduler/release-notes/#4204-08-march-2023","title":"4.2.0.4 (08 March 2023)","text":""},{"location":"scheduler/release-notes/#new","title":"New","text":"<ul> <li>Add TimeZone configuration option for CRON jobs.</li> </ul>"},{"location":"scheduler/release-notes/#4203-22-november-2022","title":"4.2.0.3 (22 November 2022)","text":""},{"location":"scheduler/release-notes/#bug-fix","title":"Bug fix","text":"<ul> <li>Fix only check for @input table if job is of type EMAIL or STOREDPROCEDURE and has inputs</li> <li>Fix handle null AuditDate on ScheduledJobs table when recording an execution to ScheduledJobsHistory</li> <li>Fix handle null Status for ONCE jobs</li> <li>Fix handle null email attachment path</li> <li>Fix set NOT SCHEDULED for non active jobs</li> </ul>"},{"location":"scheduler/release-notes/#changes_4","title":"Changes","text":"<ul> <li>Move SQL queries to OrmLite</li> <li>Update to ServiceStack 6.3.0</li> <li>Move interfaces to ServiceModel.Interfaces</li> <li>Move ScheduledJobs, ScheduledJobInputs, ScheduledJobHistory to GraniteScheduler.Entities</li> </ul>"},{"location":"scheduler/release-notes/#4202-15-september-2022","title":"4.2.0.2 (15 September 2022)","text":""},{"location":"scheduler/release-notes/#bug-fix_1","title":"Bug fix","text":"<ul> <li>Prevent System.InvalidOperationException error when a job is added/removed while application is running</li> </ul>"},{"location":"scheduler/release-notes/#4201-5-september-2022","title":"4.2.0.1 (5 September 2022)","text":""},{"location":"scheduler/release-notes/#bug-fixes","title":"Bug fixes","text":"<ul> <li>Fix injected jobs not getting a reference to application configuration</li> <li>Fix email jobs not getting some values from stored procedure correctly</li> <li>Fix jobs that have status SCHEDULED but are inactive not being set to NOT SCHEDULED</li> <li>Fix /config does not load when connection string is invalid</li> </ul>"},{"location":"scheduler/release-notes/#injected-jobs","title":"Injected Jobs","text":"<ul> <li>Add validation of Injected jobs</li> <li>Update IInjectableJob (Required for new downward integration jobs)</li> </ul>"},{"location":"scheduler/release-notes/#config","title":"/config","text":"<ul> <li>Add Injected jobs validation results to /config</li> </ul>"},{"location":"scheduler/release-notes/#change","title":"Change","text":"<ul> <li>Upgrade to ServiceStack 6.2</li> <li>Change default log level to INFO</li> </ul>"},{"location":"scheduler/release-notes/#4200-29-july-2022","title":"4.2.0.0 (29 July 2022)","text":"<p>Initial release</p>"},{"location":"scheduler/release-notes/#supported-job-types","title":"Supported job types","text":"<ul> <li>StoredProcedure</li> <li>Email</li> <li>Injected</li> </ul>"},{"location":"scheduler/release-notes/#supported-interval-formats","title":"Supported interval formats","text":"<ul> <li>Once</li> <li>Seconds</li> <li>Minutes</li> <li>Hours</li> <li>CRON </li> </ul>"},{"location":"scheduler/exampleJobs/sql-table-job-examples/","title":"SQL Table Job Examples","text":"<p>Use the following to create example jobs for the SQL Table Jobs. </p>"},{"location":"scheduler/exampleJobs/sql-table-job-examples/#archive-table-job","title":"Archive Table Job","text":"<pre><code>INSERT INTO [dbo].[ScheduledJobs] (\n      [isActive]\n    , [JobName]\n    , [JobDescription]\n    , [Type]\n    , [StoredProcedure]\n    , [InjectJob]\n    , [Interval]\n    , [IntervalFormat]\n    , [Status]\n    , [LastExecutionTime]\n    , [LastExecutionResult]\n    , [AuditDate]\n    , [AuditUser]\n)\nVALUES (\n      0                  -- default switch off\n    , 'ArchiveAuditData'\n    , 'Archive Audit data older than 6 months'\n    , 'ARCHIVETABLE'\n    , NULL\n    , NULL\n    , '00 00 * * *'                \n    , 'CRON'           \n    , 'PENDING'          -- initial status\n    , NULL\n    , NULL\n    , GETDATE()\n    , 'SYSTEM'\n);\nGO\n\n-- Table to clean\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'TableName'\n    , 'Audit'\n);\nGO\n\n-- Initial Run as dry run\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'DryRun'\n    , 'true'\n);\nGO\n\n-- Safer, parameterized filter (preferred)\n-- Example: delete rows with Date &lt; @Cutoff\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'WhereTemplate'\n    , 'AuditDate &lt; @Cutoff'\n);\nGO\n\n-- JSON parameters for the template (adjust Cutoff as needed)\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'WhereParams'\n    , '{\"Cutoff\":\"${now-6M}\"}'\n);\nGO\n\n-- Optional: table optimization configuration\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'OptimizeTable'\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'OptimizeArchiveTable'\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'OptimizeMode'                     -- options: Reorganize | Rebuild | Auto\n    , 'Rebuild'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'OnlineIndexRebuild'               -- used if OptimizeMode = Rebuild\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'UpdateStatisticsAfterOptimization' -- default true for Reorganize; false for Rebuild\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'ArchiveAuditData'\n    , 'UpdateStatisticsFullScan'          -- set true to use FULLSCAN on stats\n    , 'false'\n);\nGO\n</code></pre>"},{"location":"scheduler/exampleJobs/sql-table-job-examples/#delete-table-data-job","title":"Delete Table Data Job","text":"<pre><code>INSERT INTO [dbo].[ScheduledJobs] (\n      [isActive]\n    , [JobName]\n    , [JobDescription]\n    , [Type]\n    , [StoredProcedure]\n    , [InjectJob]\n    , [Interval]\n    , [IntervalFormat]\n    , [Status]\n    , [LastExecutionTime]\n    , [LastExecutionResult]\n    , [AuditDate]\n    , [AuditUser]\n)\nVALUES (\n      0                  -- default switch off\n    , 'CleanScheduledJobsHistory'\n    , 'Delete ScheduledJobsHistory older than 3 months'\n    , 'DELETETABLEDATA'\n    , NULL\n    , NULL\n    , '00 00 * * *'                \n    , 'CRON'           \n    , 'PENDING'          -- initial status\n    , NULL\n    , NULL\n    , GETDATE()\n    , 'SYSTEM'\n);\nGO\n\n-- Table to clean\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'TableName'\n    , 'ScheduledJobsHistory'\n);\nGO\n\n-- Initial Run as dry run\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'DryRun'\n    , 'true'\n);\nGO\n\n-- Safer, parameterized filter (preferred)\n-- Example: delete rows with Date &lt; @Cutoff\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'WhereTemplate'\n    , 'Date &lt; @Cutoff'\n);\nGO\n\n-- JSON parameters for the template (adjust Cutoff as needed)\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'WhereParams'\n    , '{\"Cutoff\":\"${now-3M}\"}'\n);\nGO\n\n-- Optional: table optimization configuration\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'OptimizeTable'\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'OptimizeMode'                     -- options: Reorganize | Rebuild | Auto\n    , 'Reorganize'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'OnlineIndexRebuild'               -- used if OptimizeMode = Rebuild\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'UpdateStatisticsAfterOptimization' -- default true for Reorganize; false for Rebuild\n    , 'true'\n);\nGO\n\nINSERT INTO [dbo].[ScheduledJobInput] (\n      [JobName]\n    , [Name]\n    , [Value]\n)\nVALUES (\n      'CleanScheduledJobsHistory'\n    , 'UpdateStatisticsFullScan'          -- set true to use FULLSCAN on stats\n    , 'false'\n);\nGO\n</code></pre>"},{"location":"sqlclr/","title":"SQLCLR","text":"<p>The SQL CLR (Common Language Runtime) integration offers a unique approach by <code>abstracting HTTP</code> technology away from direct SQL manipulation.  This encourages users to interact with our <code>API</code> instead of directly manipulating data within SQL Server. By promoting interaction with the API, this integration enhances security, maintains <code>data integrity</code>, and streamlines data processing workflows, empowering users to leverage our API's full capabilities within the SQL environment.</p> <p>Note</p> <p>SQLCLR will only work consistently on 64bit versions of SQL Server, Please see this error from a 32bit system: Stack Overflow</p>"},{"location":"sqlclr/#currently-supported-operations","title":"Currently supported operations","text":"<ul> <li> <p>Inventory</p> <p>TAKEON, SCRAP, ADJUST, MOVE, PALLETIZE, REPLENISH, RECLASSIFY, TRANSFER</p> </li> <li> <p>Inbound</p> <p>RECEIVE</p> </li> <li> <p>Outbound</p> <p>PICK, PACK</p> </li> <li> <p>Stocktake</p> <p>STOCKTAKECOUNT, STOCKTAKEHOLD, STOCKTAKERELEASE</p> </li> <li> <p>Label Printing</p> <p>TRACKINGENTITY, MASTERITEM, LOCATION</p> </li> <li> <p>Integration</p> <p>POST, POST TO ENDPOINT, UPDATE</p> </li> <li> <p>Utility API</p> <p>REPORT PRINT, REPORT EXPORT, SQL TABLE EXPORT, SIMPLE EMAIL, TEMPLATE EMAIL</p> </li> </ul>"},{"location":"sqlclr/getting-started/","title":"Getting Started","text":"<p>Note</p> <p>The previous scripts and dlls have been replaced with: SQLCLR_Install.sql When opening the SQLCLR_Install.sql it will ask if you want to normalise the endings; select NO. Be sure to replace [GraniteDatabase] with the database in which you wish to create the procedures. </p> <p>Note</p> <p>If you are upgrading from an older version of CLR ensure that you change <code>Application</code> in <code>SystemSettings</code> table from <code>GraniteSQLCLR</code> to <code>SQLCLR</code></p>"},{"location":"sqlclr/getting-started/#install-sqlclr","title":"Install SQLCLR","text":"<p>As of Granite version 5, the default database create script will include the installation of SQLCLR procedures.</p> <p>If you need to manually install SQLCLR version 5, you can find the install script here:</p> <pre><code>todo: final dropbox path.\n</code></pre> <p>Note</p> <p>The create script requires the SQL <code>sysadmin</code> role to execute successfully. If you do not have the necessary permissions, ask the client's IT to run the script.</p> SystemSettings table <p>Once the necessary assemblies and procedures have been created, you will need to ensure that your <code>SystemSettings</code> table includes the necessary entries:</p> Application Key Value Description ValueDataType isEncrypted isActive SQLCLR Webservice http://10.0.0.1:50002 Granite Webservice Address string False True SQLCLR LabelPrintService http://10.0.0.1:50004 Label Print Service Address string False True SQLCLR IntegrationService http://10.0.0.1:50003 Integration Service Address string False True SQLCLR UtilityAPI https://10.0.0.1:50001 UtilityAPI Address string False True"},{"location":"sqlclr/getting-started/#using-the-clr-procedures","title":"Using the CLR ProceduresUsing the CLR Functions","text":"<p>The suggested way to start working with your CLR procedures is to right click the procedure in SSMS and select <code>Script Stored Procedure as</code> -&gt; <code>Execute To</code></p> <p>This will ensure that you have all of the necessary variables declared with correct datatypes, and that all parameters are specified for the EXECUTE statement</p> <p>If you are not specifying a particular value, just set the variable to NULL. The variable must still be supplied as a parameter when executing the CLR procedure.</p> <p>CLR Functions are used to assist with formatting parameters with a more complex structure - typically a json input. Each function is related to a specific CLR procedure parameter. </p> <p>Doing it this way ensures that the complex parameter is properly formatted, without the need to manually manipulate json. This is especially helpful on versions of SQL Server that don't support the newer json related functions.</p> <p>The prefix indicates which of the CLR Procedures it is related to: </p> <ul> <li>\"dbo.report_\" for Reporting Service procedures</li> <li>\"dbo.email_\" for Email Service procedures</li> <li>\"dbo.export\" for SQL Export Service procedures</li> </ul>"},{"location":"sqlclr/reference/","title":"CLR Procedure Reference","text":""},{"location":"sqlclr/reference/#webservice","title":"Webservice","text":"<p>For details of the calls that the CLR procedures make to the WebService visit the metadata page of the WebService that you are going to be calling  (WebServiceUrl)/metadata</p> <p>The following procedures directly map to the WebService request, for details browse to the associated details on the WebService (WebserviceURL + below path)</p> <p></p> <ul> <li>dbo.clr_Adjustment  <pre><code>/json/metadata?op=InventoryAdjustmentRequest\n</code></pre></li> <li>dbo.clr_Move <pre><code>/json/metadata?op=InventoryMoveRequest\n</code></pre></li> <li>dbo.clr_Pack <pre><code>/json/metadata?op=OutboundPackingRequest\n</code></pre></li> <li>dbo.clr_Pick <pre><code>/json/metadata?op=OutboundPickingRequest\n</code></pre></li> <li>dbo.clr_Receive <pre><code>/json/metadata?op=InboundReceivingRequest\n</code></pre></li> <li>dbo.clr_Replenish <pre><code>/json/metadata?op=InventoryReplenishRequest\n</code></pre></li> <li>dbo.clr_Reclassify <pre><code>/json/metadata?op=InventoryReclassifyRequest\n</code></pre></li> <li>dbo.clr_Scrap <pre><code>/json/metadata?op=InventoryScrapRequest\n</code></pre></li> <li>dbo.clr_StockTakeCount <pre><code>/json/metadata?op=StockTakeCountRequest\n</code></pre></li> <li>dbo.clr_StockTakeHold <pre><code>/json/metadata?op=StockTakeHoldRequest\n</code></pre></li> <li>dbo.clr_StockTakeRelease <pre><code>/json/metadata?op=StockTakeReleaseRequest\n</code></pre></li> <li>dbo.clr_Transfer <pre><code>/json/metadata?op=InventoryTransferRequest\n</code></pre></li> </ul> dbo.clr_TakeOn <p>This procedure differs from the WebService call in that it combines the parameters \"AssignTrackingEntityBarcode\" and \"TrackingEntityBarcode\" into @assignTrackingEntityBarcode. This parameter is not required, so leave as a null if not used for the standard TakeOn behavior.</p> <p>The procedure will check if tracking entity exists. If it does exist, then the qty will be assigned to that tracking entity. If not a new tracking entity will be created with the supplied barcode. </p>"},{"location":"sqlclr/reference/#label-printing","title":"Label Printing","text":"dbo.clr_PrintLabel Parameter name Required Description Barcode No The barcode that you want to print. If not specified, you must set the Barcodes parameter Barcodes No A comma separated list of barcodes you want to print. If not specified, you must set the Barcode parameter LabelName No Full name of the label you want to print, including the file extension (.zpl or .btw). If not set, will use the default format configured for the label type. NumberOfLabels No Number of copies of the label to print. Defaults to 1 if not set PrinterName No Name of the printer that you are printing to Type Yes The type of label that you want to print. Valid values are TRACKINGENTITY, MASTERITEM, LOCATION, USER, PALLET or BOX UserID Yes ID of the user that is printing the label"},{"location":"sqlclr/reference/#integration","title":"Integration","text":"dbo.clr_IntegrationPost Parameter name Required Description transactionID No Comma separated list of transaction IDs to post document No Document number to post documents No Comma separated list of documents to post reference No Integration reference of the transactions you want to post transactionType No Transaction type of the transactions being posted processName No Process name of the transactions being posted dbo.clr_IntegrationPostToEndpoint <p>If you have multiple integration services that you need to interact with using the CLR_IntegrationPostToEndpoint procedure,  you will need to add them with a unique name in the Key column:</p> Application Key Value Description ValueDataType isEncrypted isActive SQLCLR MySecondIntegrationService http://10.0.0.1:50006 ERP Company 2 Integration Service string False True <p>The Key \"MySecondIntegrationService\" can now be used when executing the CLR_IntegrationPostToEndpoint procedure  </p> Parameter name Required Description transactionID No Comma separated list of transaction IDs to post document No Document number to post documents No Comma separated list of documents to post reference No Integration reference of the transactions you want to post transactionType No Transaction type of the transactions being posted processName No Process name of the transactions being posted systemSettingsURLKey Yes Key from the SystemSettings table for the url you want to post to dbo.clr_IntegrationUpdate Parameter name Required Description transactionID No Comma separated list of transaction IDs to post document No Document number to post documents No Comma separated list of documents to post reference No Integration reference of the transactions you want to post transactionType No Transaction type of the transactions being posted processName No Process name of the transactions being posted"},{"location":"sqlclr/reference/#utilityapi","title":"UtilityAPI","text":"Report Service <p>The two operations supported are:</p> <ul> <li>Print Report</li> <li>Export Report</li> </ul> dbo.clr_PrintReport <p>Use this procedure to print a SSRS report.</p> Parameter Name Required Description reportPath Yes Path to the report in SSRS (use the report properties in the UtilityAPI to find the report path) printerName Yes Name of the printer to print to (check available printers in UtilityAPI printer statuses ) parameters No List of all parameters required by the report dbo.clr_ReportExportToFile <p>Use this procedure to save a SSRS report to the server where the UtilityAPI is running.</p> Parameter Name Required Description reportPath Yes Path to the report in SSRS (use the report properties in the UtilityAPI to find the report path) fileDestinationPath Yes Where the report will be save to including the file name. filetype Yes File type that you want to save as (PDF, EXCELOPENXML (.xlsx), EXCEL (.xls)) parameters No List of all parameters required by the report dbo.report_AddReportParameters <p>Use this Function to create a report parameter to use with dbo.clr_ReportExport and dbo.clr_PrintReport.</p> Parameter Name Required Description parameters Yes The string that will contain the report parameters name Yes The name of the report parameter value Yes The value of the parameter <ul> <li>Example use (printing)</li> </ul> <pre><code>DECLARE @reportPath varchar(50)\nDECLARE @printerName varchar(50) \nDECLARE @parameters varchar(200)\nDECLARE @responseCode int\nDECLARE @responseJson varchar(max)\n\nSELECT @reportPath = '/Pick Slip - Per Cage'\nSELECT @printerName = 'TestPrinter'\n\nSELECT @parameters = dbo.report_AddReportParameter(@parameters, 'DocumentNumber', 'STV-AVO-000001')\nSELECT @parameters = dbo.report_AddReportParameter(@parameters, 'Cage', 'CAGE D')\n\nEXEC [dbo].[clr_ReportPrint]\n    @reportPath\n    ,@printerName\n    ,@parameters\n    ,@responseCode OUTPUT\n    ,@responseJSON OUTPUT\n\nSELECT @responseCode, @responseJson\n</code></pre> <ul> <li>Example use (export)</li> </ul> <pre><code>DECLARE @reportPath varchar(50)\nDECLARE @fileDestinationPath varchar(50)\nDECLARE @fileType varchar(50) \nDECLARE @parameters varchar(200)\nDECLARE @responseCode int\nDECLARE @responseJson varchar(max)\n\nSELECT @reportPath = N'/Pick Slip - Per Cage'\nSELECT @fileDestinationPath = 'D:\\\\Granite WMS\\\\V5 Demo\\\\PickSlip.pdf'\nSELECT @fileType = 'PDF'\n\nSELECT @parameters = dbo.report_AddReportParameter(@parameters, 'DocumentNumber', 'STV-AVO-000001')\nSELECT @parameters = dbo.report_AddReportParameter(@parameters, 'Cage', 'CAGE D')\n\nEXEC [dbo].[clr_ReportExportToFile]\n    @reportPath\n    ,@fileDestinationPath\n    ,@fileType\n    ,@parameters\n    ,@responseCode OUTPUT\n    ,@responseJson OUTPUT\n\nSELECT @responseCode, @responseJson\n</code></pre> SQL Export Service dbo.clr_TableExport <p>Use this procedure to export data from a SQL Table or View to either a CSV or Excel file. </p> Parameter Name Required Description tableName Yes The name of the sql table or view to export data from filters No The list of filters to be applied to the dataset (see below for details) offset No Number of lines to skip from the dataset limit No Limit the number of rows exported (if left blank it will default to 10000) orderByList No The list of order by criteria to sort the dataset (see below for details) fileDestinationPath Yes Where the report will be save to including the file name. filetype Yes File type that you want to save as (CSV (.csv),  EXCEL (.xlsx)) dbo.export_AddFilter <p>This function allows you to build the filters parameter string.</p> Parameter Name Required Description filters Yes The string containing the list of filters column Yes The name of the column that is being filtered filterType Yes The type of filter being applied (Equal, NotEqual, Like, NotLike, StartsWith, EndsWith, Between, GreaterThan, GreaterThanOrEqual, LessThan, LessThanOrEqual) value Yes The value applied to the filter dbo.export_AddOrderBy <p>This function allows you to build the OrderBy parameter string.</p> Parameter Name Required Description orderByList Yes The string containing the list of orderby parameters column Yes The name of the column that is being order by orderByType Yes The type of filter being applied (ASC or DESC) <ul> <li>Example usage <pre><code>DECLARE @tableName varchar(50) \nDECLARE @offset int\nDECLARE @limit int\nDECLARE @fileDestinationPath varchar(100)\nDECLARE @filetype varchar(20)\nDECLARE @orderByList varchar(200)\nDECLARE @filters varchar(200)\nDECLARE @responseCode int\nDECLARE @responseJson varchar(max)\n\nSELECT @tableName = 'API_QueryStockTotals'\nSELECT @fileDestinationPath = 'D:\\\\Granite WMS\\\\V5 Demo\\\\StockInFreezer.csv'\nSELECT @filetype = 'CSV'\n\nSET @orderByList = dbo.export_AddOrderBy(@OrderByList, 'Type', 'DESC')\nSET @orderByList = dbo.export_AddOrderBy(@OrderByList, 'Code', 'ASC')\nSET @filters = dbo.export_AddFilter(@Filters, 'Category', 'Equal', 'Freezer')\nSET @filters = dbo.export_AddFilter(@Filters, 'Qty', 'GreaterThan', '0')\n\nSET @offset = 0\nSET @limit = 500\n\nEXEC clr_TableExport \n    @tableName\n    ,@filters\n    ,@offset\n    ,@limit\n    ,@orderByList\n    ,@fileDestinationPath \n    ,@fileType\n    ,@responseCode OUTPUT\n    ,@responseJson OUTPUT\n\nSELECT @responseCode, @responseJson\n</code></pre></li> </ul> Email Service <p>Two types of emails can be sent using SQLCLR:</p> <ul> <li>Template Emails</li> <li>Simple Emails</li> </ul> <p>The difference between these two types of emails is where the content of the email body comes from.  Templated emails require an email template that will be used to generate the body of the email.  Simple emails can only contain unformatted text in the body of the email. For more info on these, as well as help with designing your own email templates, see the Utility API manual.</p> <p>Both types of emails have support for the following types of attachments:</p> <ul> <li>SSRS Reports</li> <li>Excel exports of SQL tables</li> <li>File attachments</li> </ul> dbo.clr_TemplateEmail <p>Use this procedure to send an email that uses an Email template to generate the body of the email.</p> Parameter Name Required Description subject Yes The subject of the email templateName Yes The name of the email template to use for the body of this email templateParameters No List of parameters to pass into the email template to render the body of the email toEmailAddresses No Semicolon delimited list of email addresses to address this email to ccEmailAddresses No Semicolon delimited list of email address to CC on this email bccEmailAddresses No Semicolon delimited list of email addresses to BCC on this email reportAttachments No List of SSRS reports to attach to this email excelAttachments No List of excel exports to attach to this email fileAttachments No List of files to attach to this email dbo.email_AddTemplateParameter <p>Use this function to add parameters to the list that will be used to render the email template</p> Parameter Name Required Description templateParameters Yes The list of template parameters parameterName Yes The name of the parameter as it appears in the email template parameterValue Yes The value that you are passing into the parameter <ul> <li>Example usage</li> </ul> <pre><code>DECLARE @subject nvarchar(max)\nDECLARE @templateName nvarchar(max)\nDECLARE @templateParameters nvarchar(max)\nDECLARE @toEmailAddresses nvarchar(max)\nDECLARE @ccEmailAddresses nvarchar(max)\nDECLARE @bccEmailAddresses nvarchar(max)\nDECLARE @reportAttachments nvarchar(max)\nDECLARE @excelAttachments nvarchar(max)\nDECLARE @fileAttachments nvarchar(max)\nDECLARE @responseCode int\nDECLARE @responseJSON nvarchar(max)\n\nSET @subject = 'Test Clr Mail'                                                                          \nSET @templateName = 'PickingNotification'                                                               -- Use the email template named PickingNotification\nSET @templateParameters = dbo.email_AddTemplateParameter(@templateParameters, 'documentNumber', 'SO000123') -- Add a parameter to be passed to the email template. The parameter name is documentNumber, and value is SO000123\nSET @toEmailAddresses = 'email1@gmail.com;email2@gmail.com'                                     \n\nEXECUTE [dbo].[clr_TemplateEmail] \n   @subject\n  ,@templateName\n  ,@templateParameters\n  ,@toEmailAddresses\n  ,@ccEmailAddresses\n  ,@bccEmailAddresses\n  ,@reportAttachments\n  ,@excelAttachments\n  ,@fileAttachments\n  ,@responseCode OUTPUT\n  ,@responseJSON OUTPUT\n\n  SELECT @responseCode, @responseJSON\n</code></pre> dbo.clr_SimpleEmail Parameter Name Required Description subject Yes The subject of the email body Yes The string content that will make up the body of the email toEmailAddresses No Semicolon delimited list of email addresses to address this email to ccEmailAddresses No Semicolon delimited list of email address to CC on this email bccEmailAddresses No Semicolon delimited list of email addresses to BCC on this email reportAttachments No List of SSRS reports to attach to this email excelAttachments No List of excel exports to attach to this email fileAttachments No List of files to attach to this email <ul> <li>Example usage</li> </ul> <pre><code>DECLARE @subject nvarchar(max)\nDECLARE @body nvarchar(max)\nDECLARE @toEmailAddresses nvarchar(max)\nDECLARE @ccEmailAddresses nvarchar(max)\nDECLARE @bccEmailAddresses nvarchar(max)\nDECLARE @reportAttachments nvarchar(max)\nDECLARE @excelAttachments nvarchar(max)\nDECLARE @fileAttachments nvarchar(max)\nDECLARE @responseCode int\nDECLARE @responseJSON nvarchar(max)\n\nSET @subject = 'Test Clr Mail' \nSET @body = 'Test mail'\nSET @toEmailAddresses = 'email1@gmail.com;email2@gmail.com'\n\nEXECUTE [dbo].[clr_SimpleEmail] \n   @subject\n  ,@body\n  ,@toEmailAddresses\n  ,@ccEmailAddresses\n  ,@bccEmailAddresses\n  ,@reportAttachments\n  ,@excelAttachments\n  ,@fileAttachments\n  ,@responseCode OUTPUT\n  ,@responseJSON OUTPUT\n\n  SELECT @responseCode, @responseJSON\n</code></pre> Attachments <p>Attachments can have lots of different parameters that need to be sent along with the request to generate the files that end up being attached. To assist with this we have a set of sql functions that help to build up the request JSON in the correct format.</p> Report Attachments <ul> <li>dbo.email_CreateReportAttachment</li> </ul> ParameterName Required Description reportPath Yes The path to this report in SSRS. You can find the report path by browsing the UtilityAPI's reports page fileType Yes The file type that the report should be exported to. Valid values are PDF, EXCELOPENXML, or EXCEL <ul> <li>dbo.email_AddReportParameter</li> </ul> ParameterName Required Description reportAttachment Yes The report attachment that you are adding the parameter to. This must be created using the CreateReportAttachment function parameterName Yes The name of the SSRS report parameter you want to set parameterValue Yes The value that you want to set the SSRS report parameter to <ul> <li>dbo.email_AddReportAttachment</li> </ul> ParameterName Required Description reportAttachments Yes The variable that contains the list of report attachments that you are going to send reportAttachmentToAdd Yes The variable that contains the report that you want to add to the list of reports that you are going to send <ul> <li>Example</li> </ul> <pre><code>DECLARE @subject nvarchar(max)\nDECLARE @body nvarchar(max)\nDECLARE @toEmailAddresses nvarchar(max)\nDECLARE @ccEmailAddresses nvarchar(max)\nDECLARE @bccEmailAddresses nvarchar(max)\nDECLARE @reportAttachments nvarchar(max)\nDECLARE @excelAttachments nvarchar(max)\nDECLARE @fileAttachments nvarchar(max)\nDECLARE @responseCode int\nDECLARE @responseJSON nvarchar(max)\nDECLARE @PickingReport varchar(max)\n\nSET @PickingReport = dbo.email_CreateReportAttachment('/PickingReport', 'PDF')                  -- Creating the report that we want to attach. The reportPath is /PickingReport, and fileType is PDF\nSET @PickingReport = dbo.email_AddReportParameter(@PickingReport, 'documentNumber', 'SO0001')       -- Adding a parameter that will be used to call the SSRS report. The parameter named 'documentNumber' will be set to 'SO0001'\nSET @reportAttachments = dbo.email_AddReportAttachment(@reportAttachments, @PickingReport)      -- Lastly, we add the picking report to the list of report attachments. \nSET @subject = 'Test Clr Mail' \nSET @toEmailAddresses = 'email1@gmail.com;email2@gmail.com'\n\nEXECUTE [dbo].[clr_SimpleEmail] \n   @subject\n  ,@body\n  ,@toEmailAddresses\n  ,@ccEmailAddresses\n  ,@bccEmailAddresses\n  ,@reportAttachments\n  ,@excelAttachments\n  ,@fileAttachments\n  ,@responseCode OUTPUT\n  ,@responseJSON OUTPUT\n\n  SELECT @responseCode, @responseJSON\n</code></pre> Excel Attachments <ul> <li>dbo.email_CreateExcelAttachment</li> </ul> ParameterName Required Description tableName Yes The name of the table or view that you want to export results from fileType Yes The file type that the data should be exported to. Valid values are CSV or EXCEL <ul> <li>dbo.email_AddExcelAttachmentFilter</li> </ul> ParameterName Required Description excelAttachment Yes The excel attachment you are adding a filter to. The variable passed in must be created using the CreateExcelAttachment function filterColumn Yes The column that you want to filter on filterType Yes The filter operation you want to perform. Valid values are Equal, NotEqual, Like, NotLike, StartsWith, EndsWith, Between, GreaterThan, GreaterThan, GreaterThanOrEqual, LessThan, LessThanOrEqual filterValue Yes The value you want to filter by <ul> <li>dbo.email_AddExcelAttachmentOrderBy</li> </ul> ParameterName Required Description excelAttachment Yes The excel attachment you are adding a filter to. The variable passed in must be created using the CreateExcelAttachment function orderByColumn Yes The column that you want to order by orderByType Yes Order by ascending or descending. Valid values are ASC or DESC <ul> <li>dbo.email_AddExcelAttachment</li> </ul> ParameterName Required Description excelAttachments Yes The variable that contains the list of excel attachments that you are going to send excelAttachmentToAdd Yes The variable that contains the excel attachment that you want to add to the list of attachments that you are going to send <ul> <li>Example</li> </ul> <pre><code>DECLARE @subject nvarchar(max)\nDECLARE @body nvarchar(max)\nDECLARE @toEmailAddresses nvarchar(max)\nDECLARE @ccEmailAddresses nvarchar(max)\nDECLARE @bccEmailAddresses nvarchar(max)\nDECLARE @reportAttachments nvarchar(max)\nDECLARE @excelAttachments nvarchar(max)\nDECLARE @fileAttachments nvarchar(max)\nDECLARE @responseCode int\nDECLARE @responseJSON nvarchar(max)\n\nDECLARE @ConsumablesExport varchar(max)\n\nSET @ConsumablesExport = dbo.email_CreateExcelAttachment('CustomView_MasterItem', 'CSV')                                -- Create the excel attachment. The view we will pull from is CustomView_MasterItem, and it will export to a csv file \nSET @ConsumablesExport = dbo.email_AddExcelAttachmentFilter(@ConsumablesExport, 'Category', 'Equal', 'CONSUMABLE')  -- Add a filter on the Category column of the view, fetch results where Category is equal to CONSUMABLE\nSET @ConsumablesExport = dbo.email_AddExcelAttachmentOrderBy(@ConsumablesExport, 'Description', 'ASC')              -- Order the results of the export using the Description column in ascending order\nSET @excelAttachments = dbo.email_AddExcelAttachment(@excelAttachments, @ConsumablesExport)                         -- Lastly, we add the export to the list of excel attachments\n\nSET @subject = 'Test Clr Mail' \nSET @toEmailAddresses = 'email1@gmail.com;email2@gmail.com'\n\nEXECUTE [dbo].[clr_SimpleEmail] \n   @subject\n  ,@body\n  ,@toEmailAddresses\n  ,@ccEmailAddresses\n  ,@bccEmailAddresses\n  ,@reportAttachments\n  ,@excelAttachments\n  ,@fileAttachments\n  ,@responseCode OUTPUT\n  ,@responseJSON OUTPUT\n\n  SELECT @responseCode, @responseJSON\n</code></pre> File Attachments <ul> <li>dbo.email_AddFileAttachment</li> </ul> ParameterName Required Description fileAttachments Yes The variable that contains all the file attachment paths that will be sent with the email fileToAttach Yes The path to the file that you want to add as an attachment <ul> <li>Example</li> </ul> <pre><code>DECLARE @subject nvarchar(max)\nDECLARE @body nvarchar(max)\nDECLARE @toEmailAddresses nvarchar(max)\nDECLARE @ccEmailAddresses nvarchar(max)\nDECLARE @bccEmailAddresses nvarchar(max)\nDECLARE @reportAttachments nvarchar(max)\nDECLARE @excelAttachments nvarchar(max)\nDECLARE @fileAttachments nvarchar(max)\nDECLARE @responseCode int\nDECLARE @responseJSON nvarchar(max)\n\nSET @fileAttachments = dbo.email_AddFileAttachment(@fileAttachments, 'C:\\logexport.txt')        -- Add a file to the list of file attachments\n\nSET @subject = 'Test Clr Mail' \nSET @toEmailAddresses = 'email1@gmail.com;email2@gmail.com'\n\nEXECUTE [dbo].[clr_SimpleEmail] \n   @subject\n  ,@body\n  ,@toEmailAddresses\n  ,@ccEmailAddresses\n  ,@bccEmailAddresses\n  ,@reportAttachments\n  ,@excelAttachments\n  ,@fileAttachments\n  ,@responseCode OUTPUT\n  ,@responseJSON OUTPUT\n\n  SELECT @responseCode, @responseJSON\n</code></pre>"},{"location":"sqlclr/reference/#troubleshooting","title":"Troubleshooting","text":"<p>To run the create scripts you will need sysadmin permissions on the SQL instance that you are installing on</p> <p>Be sure that you are executing the procedure using ALL of the parameters. Set them to null if they are not being used</p>"},{"location":"sqlclr/reference/#examples","title":"Examples","text":""},{"location":"sqlclr/reference/#integration_1","title":"Integration","text":"<p>https://stackoverflowteams.com/c/granitewms/questions/349</p>"},{"location":"sqlclr/release-notes/","title":"Release Notes","text":""},{"location":"sqlclr/release-notes/#granitesqlclr-tba-5000","title":"Granite.SQLCLR (TBA) 5.0.0.0","text":""},{"location":"sqlclr/release-notes/#new","title":"New","text":"<ul> <li>UtilityAPI<ul> <li>Report Print</li> <li>Report Export</li> <li>SQL Table Export</li> <li>Template Email</li> <li>Simple Email</li> </ul> </li> </ul>"},{"location":"sqlclr/release-notes/#changes","title":"Changes","text":"<ul> <li>Update error handling to show more detailed messages when SystemSettings is incorrect</li> <li>Add manufactureDate to TakeOn procedure</li> <li>The SQLCLR_Install.sql has now been included in the standard GraniteDatabase_Create.sql script. </li> </ul>"},{"location":"sqlclr/release-notes/#granitesqlclr-15-august-2023-4502","title":"Granite.SQLCLR (15 August 2023) 4.5.0.2","text":""},{"location":"sqlclr/release-notes/#new_1","title":"New","text":"<ul> <li>Webservice<ul> <li>Packing</li> <li>Reclassify</li> </ul> </li> </ul>"},{"location":"sqlclr/release-notes/#changes_1","title":"Changes","text":"<ul> <li>Previous scripts and dlls have been replace with SQLCLR_Install.sql</li> <li>Script can now be run from any server that has the SSMS connected to the required SQL server instance.</li> </ul>"},{"location":"sqlclr/release-notes/#granitesqlclr-27-june-2023-4501","title":"Granite.SQLCLR (27 June 2023) 4.5.0.1","text":""},{"location":"sqlclr/release-notes/#changes_2","title":"Changes","text":"<ul> <li>Endpoints are now always fetched from the SystemSettings table. No need to run create scripts after making changes</li> <li>Integration<ul> <li>Fix bug preventing transactions from being posted using ID.</li> </ul> </li> </ul>"},{"location":"sqlclr/release-notes/#granitesqlclr-01-june-2023-4500","title":"Granite.SQLCLR (01 June 2023) 4.5.0.0","text":""},{"location":"sqlclr/release-notes/#new_2","title":"New","text":"<ul> <li>Webservice<ul> <li>Picking</li> <li>Receiving</li> </ul> </li> <li>Integration<ul> <li>Post to specified URL</li> </ul> </li> </ul>"},{"location":"sqlclr/release-notes/#changes_3","title":"Changes","text":"<ul> <li>Takeon<ul> <li>Fix bug where @assignTrackingEntityBarcode only works for new TrackingEntities</li> </ul> </li> <li>Split Types into separate files</li> <li>Create scripts added as .sql files and removed from manual</li> </ul>"},{"location":"ssrs/getting-started/","title":"SSRS","text":""},{"location":"ssrs/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>SQL Server needs to be installed and accessible from server where you are installing SSRS</li> </ul>"},{"location":"ssrs/getting-started/#install","title":"Install","text":"<p>Note</p> <p>If your customer is using the server as a Domain Controller, SSRS will NOT install.  To get around this, try the following: </p> <ul> <li>With customer\u2019s permission, remove DC rule, install SSRS, and reapply DC rule.</li> <li>Customer to provide and alternative server / PC to run SSRS (must be within same network and be accessible from user\u2019s PCs, i.e. can browse to the SSRS report url).</li> </ul> <p>To install:</p> <ul> <li>Run SQLServerReportingServices(2019) from the dropbox folder \"/Software Installs/Granite/Granite Reports/SQL Server Reporting Services\"</li> </ul> <p>OR </p> <ul> <li>Download the installer from SSRS 2019</li> </ul> <p>Follow the install prompts, selecting Developer as the edition to install. </p> <p>Once the install completes, select the option to \"Configure report server\". </p>"},{"location":"ssrs/getting-started/#configuration","title":"Configuration","text":"Web Service URL <p>Once Report Server Configuration Manager has launched, in the left panel, select \"Web Service URL\". </p> <p>Edit only the TCP Port. In this example 40071 was used but you can use any unreserved port. Select apply and you should see the following:</p> <p></p> Database <p>Next select the \"Database\" in the left panel.</p> <p>Here select \"Change Database\" and in the new window do the following:</p> <ol> <li> <p>Create a new report server database \"Next\"</p> </li> <li> <p>Connect to SQL Server Instance with SQL Server Account Authentication Type \"Next\"</p> </li> <li> <p>Specify Database Name (the default was used for this install) \"Next\"</p> </li> <li> <p>Change Authentication Type to SQL Server Credentials and specify Sql Username and Password \"Next\"</p> </li> <li> <p>On Summary \"Next\"</p> </li> <li> <p>\"Finish\"</p> </li> </ol> <p></p> Web Portal URL <p>Next select the \"Web Portal URL\" in the left panel.</p> <p>Select \"Apply\" and you should see the following:</p> <p></p> <p>Click the link to go to the Web Portal</p> <p>If your are prompted to sign in, the login details are the windows credentials (domain\\username or Administrator depending on what server login details have been provided) like below:</p> <p></p>"},{"location":"ssrs/getting-started/#granite-branding","title":"Granite Branding","text":"<p>To apply the Granite Branding go to site setting &gt; branding and upload the zipped file located in dropbox at \"\\Software Installs\\Granite\\Granite Reports\\SQL Server Reporting Services\\Granite Branding\"</p> <p></p>"},{"location":"ssrs/getting-started/#adding-barcodes","title":"Adding Barcodes","text":"<p>Barcodes are rendered as images within SSRS, so to be able to produce a barcode on a report, the value to be printed must be passed through an image generator and displayed on the report as an image.</p> <p>To set this up on the SSRS running server, the following needs to be in setup and configured:</p> BarcodeLib.ddl <p>Copy the \"BarcodeLib.dll\" from dropbox \"\\Software Installs\\Granite\\Granite Reports\\SQL Server Reporting Services\\Barcodes on SSRS reports\" to the following locations:</p> <ul> <li>For Standalone version of SSRS: \"C:\\Program Files\\Microsoft SQL Server Reporting Services\\SSRS\\ReportServer\\bin\"</li> <li>For full SQL version installation: \"C:\\Program Files\\Microsoft SQL Server\\MSRS10_50.MSSQLSERVER\\Reporting Services\\ReportServer\\bin\\\" -\u2981  For development / report builder: \"C:\\Program Files (x86)\\Microsoft Report Builder\"</li> </ul> <p>Note</p> <p>Ensure that \"BarcodeLib.dll\" is not blocked. Go to the properties of the file and select Unblock if necessary.</p> <p></p> Microsoft Report Builder <p>In report properties:</p> <ol> <li> <p>Add References to \u201cBarcodeLib.dll\u201d and \u201cSystem.Drawing.dll\u201d from the following:</p> <ul> <li>BarcodeLib.dll (use server folder from above, i.e. standalone / full server)</li> <li>System.Drawing.dll (C:\\Windows\\Microsoft.NET\\Framework\\v2.0.50727\\System.Drawing.dll)</li> </ul> </li> <li> <p>Insert the code: </p> <ul> <li> <p>For Code 3of9 barcode: <pre><code>    Public Function Convert(Text As String) As Byte()\n        Dim b As System.Drawing.Bitmap\n        bar.Alignment = BarcodeLib.AlignmentPositions.LEFT\n        bar.IncludeLabel = False\n        bar.RotateFlipType = Drawing.RotateFlipType.RotateNoneFlipNone\n        b = bar.Encode(BarcodeLib.TYPE.CODE39Extended, Text, 200, 15)\n        Dim bitmapData As Byte() = Nothing\n        Using ms As New System.IO.MemoryStream()\n            b.Save(ms, System.Drawing.Imaging.ImageFormat.Bmp)\n            bitmapData = ms.ToArray()\n        End Using\n        Return bitmapData\n    End Function\n</code></pre></p> </li> <li> <p>For Code128 barcode: <pre><code>    Public Function Convert128(Text As String) As Byte()\n        Dim b As System.Drawing.Bitmap\n        bar.Alignment = BarcodeLib.AlignmentPositions.LEFT\n        bar.IncludeLabel = False\n        bar.RotateFlipType = Drawing.RotateFlipType.RotateNoneFlipNone\n        b = bar.Encode(BarcodeLib.TYPE.CODE128, Text, 400, 50)\n        Dim bitmapData As Byte() = Nothing\n        Using ms As New System.IO.MemoryStream()\n            b.Save(ms, System.Drawing.Imaging.ImageFormat.Bmp)\n            bitmapData = ms.ToArray()\n        End Using\n        Return bitmapData\n    End Function\n</code></pre></p> </li> </ul> <p></p> </li> </ol> <p>In image properties:</p> <ul> <li>Use an Image with the following settings:<ul> <li>For Code3of9 Barcode:     Image source: Database     Expression: =Code.Convert(\"\" &amp; Fields!DocumentNumber.Value &amp; \"\")     MIME Type: image/bmp     Size: Fit Proportional</li> <li>For Code128 Barcode:     Image source: Database     Expression: =Code.Convert(Fields!DocumentNumber.Value)     MIME Type: image/bmp     Size: Fit Proportional</li> </ul> </li> </ul> <p></p>"},{"location":"third-party-integration/GettingStarted/","title":"GettingStarted","text":""},{"location":"third-party-integration/GettingStarted/#getting-started","title":"Getting Started","text":""},{"location":"third-party-integration/GettingStarted/#integration-to-granite","title":"Integration to Granite:","text":"<p>This document details the tools and information needed to integrate with Granite WMS.</p> <p>What will be covered:</p> <ul> <li>Granite's APIs</li> <li>Detailing business objects</li> <li>Relationships between the business objects</li> <li>Instruction on authentication to make calls</li> <li>An example of a GET, POST, and  DELETE on one of the business objects. </li> </ul>"},{"location":"third-party-integration/GettingStarted/#granite-apis","title":"Granite APIs:","text":"<p>Granite operates using two APIs:  - Webservice API: handles the business processes E.g picking or moving stock - Repository API : handles the CRUD functionality of the business objects. </p> <p>For the purposes of integration with Granite, i.e maintaining documents , masteritems, locations, and trading partners,  the Repository API will cover 99% of use cases and, as such, shall be the only API detailed in this document. </p> <p>Detailing all of the Repository API calls will not be covered here as there is full Swagger documentation to reference for each call. To view the swagger documentation please go to  localRepoAPIaddress/swagger-ui/  e.g. (https://granite.com:40196/swagger-ui/)</p>"},{"location":"third-party-integration/GettingStarted/#business-objects","title":"Business objects:","text":"<p>Granite makes use of six core business objects. While there are other business objects used in Granite, these six represent the core functionality.</p> <ul> <li> <p>Locations: are uniquely identified by a Barcode. Used to identify something as specific as a shelf or as general as an area in a warehouse. E.g Name: Cage A Shelf  3 Row 2 Barcode: A-3-2 or Name: Dispatch Code: DIS </p> </li> <li> <p>MasterItems: are the identities of specific products and are uniquely identified using a Code. E.g. Code: ABCLZZ110 Product: KL371X ABRASIVE CLOTH 230 x 280mm</p> </li> <li> <p>TradingPartners: are any parties that will be listed on a document as either a customer or supplier. Trading partners are set up per Document type and are uniquely identified with a Code. E.g. Code: AVO15 Name: Avondale Confectionary </p> </li> <li> <p>Documents: are the objects that represent sales orders, purchase orders, transfers, or manufacturing documents (documents are generic in Granite and represent any of the previously listed types). They can be considered the documents Header and are uniquely represented by a Number. E.g. A sales order for trading partner AVO15 Number: SO001263</p> </li> <li> <p>DocumentDetails: are the lines of the document and are uniquely assigned to a specific Document. E.g. There are multiple documentdetail entries that are assigned to SO001263 that detail the contents of the order. </p> </li> <li> <p>TrackingEntities: represent the stock/physical goods in the system and are uniquely identified with a Barcode. A single tracking entity can represent only one masteritem. E.g. Barcode: T00000124 represents a quantity of 5 sheets of master item ABCLZZ110.</p> </li> </ul>"},{"location":"third-party-integration/GettingStarted/#business-object-relationships","title":"Business object relationships","text":""},{"location":"third-party-integration/GettingStarted/#example-calls","title":"Example calls:","text":"<p>Following are a few examples of calls made to the repository API to provide some initial context. The calls for all the other objects are very similar so will not be detailed as their calls can be found in the swagger documention.  </p>"},{"location":"third-party-integration/GettingStarted/#authenticate","title":"Authenticate:","text":"<p>The first call is /auth to authenticate for all following calls. The security uses cookies so if the same client is used this will only have to be called once per set of calls. The format for the examples use json but xml, jsv, and csv are also supported  If any other call is made without calling authorisation first it will return: 401 Unauthorized <pre><code>POST https://granite.com:40196/auth HTTP/1.1\nAccept: application/json\nContent-Type: application/json\nContent-Length: length\n\n{\"UserName\":\"username\",\"Password\":\"password\"}\n</code></pre></p>"},{"location":"third-party-integration/GettingStarted/#locations","title":"Locations:","text":"<p>Following are examples of GET, POST, DELETE calls on the Location business object: <pre><code>GET https://granite.com:40196/Locations/{Barcode}?Barcode=DIS HTTP/1.1\nAccept: application/json\n</code></pre></p> <p><pre><code>POST https://granite.com:40196/Locations HTTP/1.1\nAccept: application/json\nContent-Type: application/json\nContent-Length: length\n\n{\"Body\":{\"Name\":\"ExampleLocation\",\"Barcode\":\"EL123\",\"Site\":\"\",\"isActive\":True,\"NonStock\":false,\"ERPLocation\":\"ERP1\",\"Category\":\"\",\"Type\":\"\",\"Status\":\"\",\"Width\":0,\"Length\":0,\"Height\":0,\"MaximumWeight\":0,\"ERPIdentification\":\"ERPid123\",\"AuditDate\":\"05/05/2023\",\"AuditUser\":\"ErpSystem\",\"Version\":0}}\n</code></pre> The same call can be used to modify the location by providing the granite id as part of the call: <pre><code>POST https://granite.com:40196/Locations HTTP/1.1\nAccept: application/json\nContent-Type: application/json\nContent-Length: length\n\n{\"Body\":{\"ID\":6064,\"Name\":\"NewName\",\"Barcode\":\"EL123\",\"Site\":\"\",\"isActive\":True,\"NonStock\":false,\"ERPLocation\":\"ERP1\",\"Category\":\"\",\"Type\":\"\",\"Status\":\"\",\"Width\":0,\"Length\":0,\"Height\":0,\"MaximumWeight\":0,\"ERPIdentification\":\"ERPid123\",\"AuditDate\":\"05/05/2023\",\"AuditUser\":\"ErpSystem\",\"Version\":0}}\n</code></pre> <pre><code>DELETE https://granite.com:40196/Locations/{Barcode}?Barcode=EL123 HTTP/1.1\nAccept: application/json\n</code></pre></p>"},{"location":"tools/","title":"Tools","text":"<p>Here you can find recommended tools and tutorials that can help you work more efficiently.</p>"},{"location":"tools/jam/","title":"Jam.dev","text":"<p>Jam.dev is an awesome tool that can help you communicate more efficiently with the dev team. </p> <p>It's a chrome extension that allows you to capture a video of the end user action, as well as the browser dev tools output - in a matter of seconds.</p>"},{"location":"tools/jam/#tutorial-video","title":"Tutorial Video","text":"<p>Get Jam here: https://jam.dev/ \ud83c\udf53</p>"},{"location":"updates/release-notes/","title":"Release Notes","text":""},{"location":"updates/release-notes/#april-2024-new-release-5000","title":"April 2024 New Release : 5.0.0.0","text":"<p>Note</p> <ul> <li>Database changes required</li> </ul>"},{"location":"updates/release-notes/#database","title":"Database","text":""},{"location":"updates/release-notes/#database-tables","title":"Database Tables","text":"<ul> <li><code>new</code> table Migration</li> <li><code>new</code> table OptionalFieldValues_Document</li> <li><code>new</code> table OptionalFieldValues_DocumentDetail</li> <li><code>new</code> table SystemTransientData</li> <li><code>new</code> table Email</li> <li><code>new</code> table EmailLog</li> <li><code>new</code> table EmailTemplate</li> <li><code>fix</code> table OptionalFieldValues_Location</li> <li><code>change</code> table Users</li> <li><code>change</code> table SystemSettings</li> <li><code>change</code> table Process</li> <li><code>change</code> table ProcessMembers</li> <li><code>change</code> table ProcessStep</li> <li><code>change</code> table Transaction</li> <li><code>change</code> table ProcessStepLookup</li> <li><code>change</code> table ProcessStepLookupDynamic</li> </ul>"},{"location":"updates/release-notes/#stored-procedures","title":"Stored Procedures","text":"<ul> <li><code>remove</code> stored procedure EmailTemplate</li> </ul>"},{"location":"updates/release-notes/#database-data","title":"Database Data","text":"<ul> <li><code>new</code> Table Migration: Default migration data</li> <li><code>new</code> Table EmailTemplate: IntegrationError template</li> <li><code>new</code> Table SystemSettings: UtilityApi and Custodian settings</li> <li><code>fix</code> Table Users: User 0 has all permissions</li> <li><code>fix</code> Table DataGrid: Add missing fields to Document grids</li> <li><code>change</code> Table SystemSettings: All password settings are encrypted by default</li> <li><code>remove</code> Table SystemSettings: Email related settings removed</li> <li><code>remove</code> Table DataGrid: SystemSettings grid</li> </ul>"},{"location":"updates/release-notes/#sqlclr","title":"SQLCLR","text":"<ul> <li><code>new</code> support for UtilityAPI operations<ul> <li>Report Print</li> <li>Report Export</li> <li>SQL Table Export</li> <li>Template Email</li> <li>Simple Email</li> </ul> </li> <li><code>change</code> CLR procedures are now deployed with database create, no need to install separately</li> <li><code>change</code> improved error handling to show more detailed messages when SystemSettings is incorrect</li> <li><code>change</code> add manufactureDate to TakeOn procedure</li> <li><code>change</code> add NoEntities to clr_Replenish</li> </ul>"},{"location":"updates/release-notes/#accpac-integration","title":"Accpac Integration","text":"<ul> <li><code>fix</code> view Integration_Accpac_AutoSimplyMODetail </li> <li><code>fix</code> view Integration_Accpac_InternalUsageDetail </li> <li><code>fix</code> view Integration_Accpac_IntransitDetail </li> <li><code>fix</code> view Integration_Accpac_PurchaseOrderDetail </li> <li><code>fix</code> view Integration_Accpac_ReceiptDetail </li> <li><code>fix</code> view Integration_Accpac_SalesOrderDetail </li> <li><code>fix</code> view Integration_Accpac_TransferDetail </li> <li><code>fix</code> view MasterItemAlias_View</li> </ul>"},{"location":"updates/release-notes/#evo-integration","title":"Evo Integration","text":"<ul> <li><code>new</code> view Integration_Evolution_InterBranchRequisitionHeader</li> <li><code>new</code> view Integration_Evolution_InterBranchRequisitionDetail</li> <li><code>new</code> trigger TriggerGraniteInterBranchRequisition</li> </ul>"},{"location":"updates/release-notes/#webdesktop","title":"Webdesktop","text":"<ul> <li><code>fix</code> wrong document displaying when selected from grid<ul> <li>https://granitewms.canny.io/bugs/p/webdesktop-document-selection</li> </ul> </li> <li><code>fix</code> prevent action qty being overridden when editing document line<ul> <li>https://granitewms.canny.io/bugs/p/document-line-edit-overiding-action-qty</li> </ul> </li> <li><code>fix</code> stocktake recommendations when counts have been reset<ul> <li>https://granitewms.canny.io/bugs/p/stock-take-count-reset-and-recommendations</li> </ul> </li> <li><code>change</code> additional fields for pickslip documents<ul> <li>https://granitewms.canny.io/bugs/p/pickslip-document-fields</li> </ul> </li> <li><code>change</code> only show active master items in document edit<ul> <li>https://granitewms.canny.io/request/p/show-only-active-masteritems-in-dropdown</li> </ul> </li> <li><code>change</code> improve error message when executing function without selected record<ul> <li>https://granitewms.canny.io/bugs/p/webdesktop-functions-no-record-select-error</li> </ul> </li> <li><code>change</code> improve document management user experience</li> <li><code>new</code> optional fields support for Document</li> <li><code>new</code> optional fields support for DocumentDetail</li> <li><code>new</code> prescript preview functionality</li> <li><code>new</code> SystemSettings encryption functionality</li> <li><code>new</code> database migration support</li> </ul>"},{"location":"updates/release-notes/#processapp-webservice","title":"ProcessApp &amp; Webservice","text":"<ul> <li><code>fix</code> Document display issue<ul> <li>https://granitewms.canny.io/bugs/p/process-app-documentprogress-display-issue</li> </ul> </li> <li><code>fix</code> Error creating new pallet when label print service is not configured<ul> <li>https://granitewms.canny.io/bugs/p/pallet-label-print-error-with-no-print-service</li> </ul> </li> <li><code>new</code> Number of Entities functionality for replenish<ul> <li>https://granitewms.canny.io/request/p/replenish-to-multiple-tes</li> </ul> </li> <li><code>new</code> Unlimited step 200s</li> <li><code>new</code> Debug mode</li> </ul>"},{"location":"updates/release-notes/#evo-integration_1","title":"Evo integration","text":""},{"location":"updates/release-notes/#sdk-provider","title":"SDK Provider","text":"<ul> <li><code>new</code> Map DocumentReference to Message1 on Evo SalesOrder post<ul> <li>https://granitewms.canny.io/request/p/evo-integration-sales-order-post-update-message-lines-on-sales-order</li> </ul> </li> <li><code>new</code> Support for encrypted SystemSettings</li> </ul>"},{"location":"updates/release-notes/#injected-jobs","title":"Injected jobs","text":"<ul> <li><code>new</code> Support for Inter Branch Requisition<ul> <li>https://granitewms.canny.io/request/p/evo-inter-branch-requisition-document-sync-job</li> </ul> </li> <li><code>fix</code> Performance issue causing sql timeout on document jobs</li> <li><code>change</code> Use UtilityAPI for email notifications</li> </ul>"},{"location":"updates/release-notes/#accpac-integration_1","title":"Accpac Integration","text":""},{"location":"updates/release-notes/#sdk-provider_1","title":"SDK Provider","text":"<ul> <li><code>new</code> Support for encrypted SystemSettings</li> </ul>"},{"location":"updates/release-notes/#injected-jobs_1","title":"Injected jobs","text":"<ul> <li><code>change</code> Use UtilityAPI for email notifications</li> </ul>"},{"location":"updates/release-notes/#omni-integration","title":"Omni Integration","text":""},{"location":"updates/release-notes/#sdk-provider_2","title":"SDK Provider","text":"<ul> <li><code>new</code> Support for encrypted SystemSettings</li> </ul>"},{"location":"updates/release-notes/#sapb1-integration","title":"SAPB1 Integration","text":""},{"location":"updates/release-notes/#sdk-provider_3","title":"SDK Provider","text":"<ul> <li><code>new</code> Support for encrypted SystemSettings</li> </ul>"},{"location":"updates/release-notes/#syspro-integration","title":"Syspro Integration","text":""},{"location":"updates/release-notes/#sdk-provider_4","title":"SDK Provider","text":"<ul> <li><code>new</code> Support for encrypted SystemSettings</li> </ul>"},{"location":"updates/release-notes/#label-printing-bartender","title":"Label Printing Bartender","text":"<ul> <li><code>change</code> Logging provider to Nlog</li> </ul>"},{"location":"updates/release-notes/#scheduler","title":"Scheduler","text":"<ul> <li><code>change</code> email jobs now use Utility API - support for old implementation removed</li> </ul>"},{"location":"updates/release-notes/#january-2024-product-update-4530","title":"January 2024 Product Update : 4.5.3.0","text":"<p>Note</p> <ul> <li>Database change required</li> <li>Release was done on 16 Jan for ProcessApp and Webdesktop / Repo Api on 23 Jan</li> </ul>"},{"location":"updates/release-notes/#database-24-jan-2024","title":"Database (24 Jan 2024)","text":"<ul> <li><code>new</code> Table OptionalFieldValues_Location</li> </ul>"},{"location":"updates/release-notes/#webdesktop-23-jan-2024","title":"Webdesktop (23 Jan 2024)","text":"<ul> <li> <p><code>fix</code> delete stock take session when no record selected</p> <ul> <li>https://stackoverflowteams.com/c/granitewms/questions/348</li> </ul> </li> <li> <p><code>new</code> grid menu options to clear selection and filters</p> <ul> <li>https://granitewms.canny.io/request/p/webdesktop-grid-menu-option-clear</li> </ul> </li> <li> <p><code>new</code> add optional field support for Locations</p> <ul> <li>https://granitewms.canny.io/request/p/optional-fields-location</li> <li>https://granitewms.canny.io/request/p/additional-fields-for-locations</li> </ul> </li> </ul>"},{"location":"updates/release-notes/#repo-api-23-jan-2024","title":"Repo API (23 Jan 2024)","text":"<ul> <li>fix error when importing documents<ul> <li>https://granitewms.canny.io/bugs/p/webdesktop-document-import</li> </ul> </li> </ul>"},{"location":"updates/release-notes/#processapp-16-jan-2024","title":"ProcessApp (16 Jan 2024)","text":"<ul> <li><code>fix</code> Layout issues on various screens <ul> <li>https://granitewms.canny.io/bugs/p/processapp-receiving-screen-issue</li> <li>https://granitewms.canny.io/bugs/p/processapp-layout-issues-picking</li> <li>https://granitewms.canny.io/bugs/p/stocktake-scanner-detail-values-not-adjacent-to-description</li> </ul> </li> </ul>"},{"location":"updates/release-notes/#september-2023-product-update-4520","title":"September 2023 Product Update : 4.5.2.0","text":""},{"location":"updates/release-notes/#webdesktop_1","title":"WebDesktop","text":"<ul> <li><code>fix</code> Document Detail stock on hand lookup did not return<ul> <li>https://granitewms.canny.io/bugs/p/stock-on-hand-button-on-document-screens</li> </ul> </li> <li><code>new</code> Add support for user sites in Datagrid (enquiry). Filter grid data based on user that is currently logged in.</li> <li><code>new</code> CSS Datagrid styling. Add CSS style classes to use with datagrid. fontGreen , fontBlue , fontRed , backgroundRed ,backgroundBlue ,backgroundGreen <ul> <li>https://granitewms.canny.io/request/p/webdesktop-datagrid-styling</li> </ul> </li> <li><code>fix</code> Document grids with status CANCELLED not apply correct CSS style<ul> <li>https://granitewms.canny.io/bugs/p/webdesktop-document-grids-status-not-showing-correctly</li> </ul> </li> <li><code>fix</code> Saving customize application grids used incorrect GroupName for the grid. </li> <li><code>fix</code> Saving customize application grids caused the GridName to duplicate the prefix word Custom.</li> </ul>"},{"location":"updates/release-notes/#processapp","title":"ProcessApp","text":"<ul> <li><code>fix</code> Confirmation and error sound not playing</li> <li><code>fix</code> Documents with larger text fields render incorrectly. <ul> <li>https://granitewms.canny.io/bugs/p/processapp-document-display-issue</li> </ul> </li> </ul>"},{"location":"updates/release-notes/#labelprintservice","title":"LabelPrintService","text":"<ul> <li><code>new</code> Add validation of printer name</li> </ul>"},{"location":"updates/release-notes/#august-2023-product-update-4510","title":"August 2023 Product Update : 4.5.1.0","text":""},{"location":"updates/release-notes/#webdesktop-repository-api","title":"WebDesktop / Repository API","text":"<ul> <li><code>fix</code> Print label not working with illegal characters in MasterItem Code</li> <li><code>fix</code> Functions scripts returning null in Valid (field) threw error.</li> <li><code>fix</code> Functions for document screen fixed. Selected records not being passed on to function.</li> <li><code>fix</code> Grid definition for application grids, show the name and audit information correctly.</li> <li><code>fix</code> Data Import: various issues causing the import to not import or show records in grid.</li> <li><code>fix</code> TrackingEntity Import: Remove override of Barcode. Expiry and manufacture date column rename.</li> <li><code>fix</code> Pickslip grid not showing data.</li> <li><code>fix</code> Application grids update isCustomGrid value for grid entry   </li> <li><code>new</code> Datagrid StockAvailable (include new SQL view)</li> </ul>"},{"location":"updates/release-notes/#processapp_1","title":"ProcessApp","text":"<ul> <li><code>fix</code> New Pallet ignore casing of word New</li> <li><code>fix</code> Add web template support for Posting processes.</li> <li><code>fix</code> Expand / Collapse of trackingentity information on Pallet did not work.</li> <li><code>fix</code> When trying to open Transfer Post page was not found.</li> <li><code>new</code> Prefix all web template errors to clarify origin of error.</li> <li><code>change</code> Default config for logging <code>nlog.log</code> set to Info and included archive setting on size limit.</li> </ul>"},{"location":"updates/release-notes/#database_1","title":"Database","text":""},{"location":"updates/release-notes/#database-views","title":"Database Views","text":"<ul> <li><code>fix</code> API_QueryDocumentProgress</li> <li><code>fix</code> API_QueryTransactionsPickReversal (exclude pack transactions)</li> <li><code>new</code> DataGrid_StockAvailable</li> </ul>"},{"location":"updates/release-notes/#database-data_1","title":"Database Data","text":"<ul> <li><code>fix</code> Table Datagrid: OrderDocumentProgress, ReceivingDocumentProgress, TransferDocumentProgress, WorkOrderDocumentProgress</li> <li><code>fix</code> Table Datagrid: entry ImportTrackingEntity. Fix layout. Also see Tracking Entity Import on Webdesktop fix.</li> <li><code>fix</code> Table Datagrid: entry Document / PickslipDocument. Fix layout. </li> <li><code>new</code> Table Datagrid: Grid for DataGrid_StockAvailable.</li> <li><code>new</code> Table Snippets: various snippets added to showcase standard Granite </li> </ul>"},{"location":"updates/release-notes/#accpac-database","title":"Accpac Database","text":"<ul> <li><code>fix</code> MasterItemAlias_View add union on join</li> <li><code>change</code> IntegrationProcessTransfer, IntegrationProcessSalesOrder, IntegrationProcessTransfer. Use ExpectedDate instead of ActionDate</li> </ul>"},{"location":"updates/release-notes/#scheduler_1","title":"Scheduler","text":"<ul> <li><code>change</code> Remove execution timeout for SQL jobs</li> </ul>"},{"location":"updates/release-notes/#accpac-injected-jobs","title":"Accpac Injected jobs","text":"<ul> <li><code>fix</code> Scheduler gets stuck when document line's MasterItem_ERPIdentification does not appear in Integration_Accpac_MasterItem view</li> </ul>"},{"location":"updates/release-notes/#evo-injected-jobs","title":"Evo Injected jobs","text":"<ul> <li><code>fix</code> not validating changes before updating document lines</li> </ul>"},{"location":"updates/release-notes/#zpl-labelprinting","title":"ZPL LabelPrinting","text":"<ul> <li><code>change</code> Variables in ZPL label templates now need to be prefixed with <code>@</code></li> </ul>"},{"location":"updates/release-notes/#accpac","title":"Accpac","text":"<ul> <li><code>new</code> Support for Accpac 2023 version 7.0</li> </ul>"},{"location":"updates/whats-new/","title":"Granite WMS What's New V 5.0","text":""},{"location":"updates/whats-new/#new-applications-overview","title":"New Applications Overview","text":"<ul> <li>Process Catalog - A process catalogue that allows you to easily share your process configurations with the team</li> <li>Utility API - A brand new API, home to our new SSRS Reporting Service and Email Service</li> </ul>"},{"location":"updates/whats-new/#webdesktop-changes-overview","title":"WebDesktop Changes Overview","text":"<ul> <li>Document - Document capture enhancements</li> <li>Optional Fields Location - Support for Optional Fields for Locations</li> <li>Optional Fields Document - Support for Optional Fields for Document</li> <li>Optional Fields DocumentDetail - Support for Optional Fields for Document Detail</li> <li>Pre-Script preview - Preview Pre-Scripts in WebDesktop</li> <li>System Settings Encryption - Allow encryption of sensitive data stored in System settings</li> <li>Database Migration - Easy migration / upgrade of version 4.5 to 5.0 via webdesktop.</li> </ul>"},{"location":"updates/whats-new/#process-changes-overview","title":"Process Changes Overview","text":"<ul> <li>Silent Steps - Unlimited silent steps</li> <li>Debug Mode - Use by technical team to view webtemplates, scripts while executing a process</li> </ul>"},{"location":"updates/whats-new/#process-catalog","title":"Process Catalog","text":"<p><code>Functionality not intended for end-user.</code></p> <p>Introducing new functionality that empowers consultants to seamlessly share Processes as Templates and securely store them in the cloud.  Moreover, this update enables users to conveniently access all shared templates from the central store and deploy them to production environments with ease</p> <p>Webdesktop Publish Process</p> <p>An easy to follow wizard to publish any Process as a template.   </p> <p>Webdesktop Process Catalog</p> <p>Search, preview and deploy templates with an easy to understand UI.</p> <p></p>"},{"location":"updates/whats-new/#utility-api","title":"Utility API","text":"<p>The Granite Utility API is a brand new API that will be home to various services that enhance Granite's capabilities.</p> <p>The first two services that the Utility API will launch with are a SSRS Reporting Service to provide easy ways of interacting with SSRS from SQLCLR, and a new Email Service that is intended to replace the emailing currently built into the Scheduler. The new Email Service will also support the SSRS Reporting Service from the get go, allowing you to seamlessly attach SSRS Reports when sending emails.</p>"},{"location":"updates/whats-new/#email-service","title":"Email Service","text":"<p>This new Email Service aims to make sending emails simpler, and at the same time far more powerful. We've achieved this by introducing Email Templates, which are based on the same technology as the ProcessApp's Web Templates. In addition to Email Templates, the new Email Service is fully supported by SQLCLR, which means no more inserting directly into tables to send once off emails!</p> <p>Sending emails with attachments is also now simpler than it's ever been. When you request an email to be sent, you can specify parameters for the SSRS Reporting Service which will render your reports, save them to disk and attach them to the email - all in a single request.</p>"},{"location":"updates/whats-new/#email-templates","title":"Email Templates","text":"<p>Email templates allow you to create good looking responsive emails without the hassle of writing out all that html. This is done by keeping things simple - we use markdown for text formatting, and a standard layout that can be built upon. You can customize templates using script methods similar to the ones you're already familiar with from WebTemplates.</p> <p>A templated email without any further customization looks like this:</p> <p></p> <p>And with just a few script methods you can build it into this:</p> <p></p>"},{"location":"updates/whats-new/#attachments","title":"Attachments","text":"<p>To attach an SSRS report to an email, we simply add the report path, file type and report parameters that we want to use to generate the attachment when we create our email:</p> <pre><code>DECLARE @subject nvarchar(max)\nDECLARE @body nvarchar(max)\nDECLARE @toEmailAddresses nvarchar(max)\nDECLARE @ccEmailAddresses nvarchar(max)\nDECLARE @bccEmailAddresses nvarchar(max)\nDECLARE @reportAttachments nvarchar(max)\nDECLARE @excelAttachments nvarchar(max)\nDECLARE @fileAttachments nvarchar(max)\nDECLARE @responseCode int\nDECLARE @responseJSON nvarchar(max)\nDECLARE @PickingReport varchar(max)\n\nSET @PickingReport = dbo.email_CreateReportAttachment('/PickingReport', 'PDF')                  \n-- Creating the report that we want to attach. The reportPath is /PickingReport, and fileType is PDF\nSET @PickingReport = dbo.email_AddReportParameter(@PickingReport, 'documentNumber', 'SO0001')       \n-- Adding a parameter that will be used to call the SSRS report. The parameter named 'documentNumber' will be set to 'SO0001'\nSET @reportAttachments = dbo.email_AddReportAttachment(@reportAttachments, @PickingReport)      \n-- Lastly, we add the picking report to the list of report attachments. \nSET @subject = 'Example Clr Mail' \nSET @toEmailAddresses = 'email1@gmail.com;email2@gmail.com'\n\nEXECUTE [dbo].[clr_SimpleEmail] \n   @subject\n  ,@body\n  ,@toEmailAddresses\n  ,@ccEmailAddresses\n  ,@bccEmailAddresses\n  ,@reportAttachments\n  ,@excelAttachments\n  ,@fileAttachments\n  ,@responseCode OUTPUT\n  ,@responseJSON OUTPUT\n\n  SELECT @responseCode, @responseJSON\n</code></pre>"},{"location":"updates/whats-new/#ssrs-reporting-service","title":"SSRS Reporting Service","text":"<p>The SSRS Reporting Service adds some new functionality to Reporting 'tool-box' by enabling saving of reports to either PDF or EXCEL from a SQLCLR procedure. Printing SSRS reports has been improved and moved to this service. It is now allows for printing reports with multiple parameters and is far simpler to set up and execute with SQLCLR calls. </p>"},{"location":"updates/whats-new/#sql-export-service","title":"SQL Export Service","text":"<p>The last piece of functionality being added with the Utility API is the SQL Export service. This service allows for exporting of data from Tables and Views to either Excel or CSV. Supporting filtering, order by, offset, limit, and shipping from the start with SQLCLR calls, this service aims to make it easier than ever to get data out of the Granite Database. </p>"},{"location":"updates/whats-new/#webdesktop-changes","title":"WebDesktop Changes","text":""},{"location":"updates/whats-new/#document","title":"Document","text":"<p>Several small changes was made to reduce errors and to facilitate a better experience when capturing documents.</p> <ul> <li>Open the item dialog when user click new line.</li> <li>If a from, to or intransit location is captured in the previous line it will carry over to the next.</li> </ul> <p></p> <ul> <li>Disable the edit of the header of the document when user is busy with line editing.</li> </ul>"},{"location":"updates/whats-new/#optionalfields","title":"Optionalfields","text":"<p>We have introduced support for optional fields in Locations, Documents, and Document Details.</p> <p><code>Example showcasing an optional field at the line level.</code></p> <p></p>"},{"location":"updates/whats-new/#prescript-preview","title":"Prescript Preview","text":"<p>Easily preview the prescript of a ProcessStep in a readonly view.</p> <p><code>Example: Icon displayed next to the prescript name trigger for a preview.</code></p> <p></p>"},{"location":"updates/whats-new/#systemsettings-encryption","title":"Systemsettings Encryption","text":"<p><code>To ensure safety across the board, we have implemented encryption in our System Settings for storing sensitive information.</code> These values can never be viewed, and are securely stored with encryption keys.</p> <p><code>Take Note</code> We require all current system settings to migrate sensitive setting in version 5 as part of the upgrade procedure.</p> <p></p>"},{"location":"updates/whats-new/#grid-menu-clear-options","title":"Grid menu clear options","text":"<p>Options to clear selection and filters.</p> <p></p>"},{"location":"updates/whats-new/#silent-steps","title":"Silent Steps","text":"<p>We're excited to announce our support for silent steps within the range of 200-299. This enhancement grants users the flexibility to set up an unlimited number of silent steps within this range. The motivation behind this update is to meet the growing demands related to tasks such as sending emails or generating reports.</p> <p>We highly recommend segregating these new silent steps from your regular ones, as it enhances clarity and simplifies support processes.</p> <p>It's important to note that silent step 200 will halt execution if validation fails, preventing any subsequent silent steps from running. However, starting from step 201 onwards, execution will proceed regardless of validation status.</p>"},{"location":"updates/whats-new/#debug-mode","title":"Debug Mode","text":"<p><code>Functionality not intended for end-user.</code></p> <p>When accessing the Debug Mode within the ProcessApp, users gain invaluable insights into each Business Process setup and configuration.  This specialized mode enables users to examine prescripts and web template syntax, as well as analyze the current state of the application in detail.</p> <p>Debug Mode facilitates a systematic walkthrough of each process step, empowering users to thoroughly review their setup and identify potential issues with precision. </p> <p>By offering a comprehensive view of the application's internal processes, Debug Mode enhances efficiency in debugging, enabling users to streamline problem-solving and optimization efforts effectively.</p>"},{"location":"updates/whats-new/#application-state","title":"Application State","text":""},{"location":"updates/whats-new/#prescript-syntax","title":"Prescript syntax","text":""},{"location":"updates/whats-new/#webtemplate-syntax","title":"WebTemplate syntax","text":""},{"location":"utility-api/","title":"Utility API","text":"<p>The Utility API is home to various services that enhance Granite's capabilities.</p> <p>At the moment it is comprised of:</p> <ul> <li> <p>Reporting Service </p> <p>Provides easy ways of interacting with SSRS.</p> </li> <li> <p>SQL Export Service</p> <p>Enables simpler excel exports from SQL tables and views.</p> </li> <li> <p>Email Service </p> <p>Replaces the emailing previously built into the Scheduler, and has built in support for Reporting Service and SQL Export Service as sources of attachments.</p> </li> </ul>"},{"location":"utility-api/email-service/","title":"Email Service","text":""},{"location":"utility-api/email-service/#configuration","title":"Configuration","text":"<p>Google shutting down access to sending mails via SMTP</p> <p>As of January 2025, the Utility API will not be able to send emails using SMTP.</p> <p>If you are using a Gmail address to send emails, you will need to switch over to the new Gmail provider</p> <p>Settings for the Email Service are configured in the <code>SystemSettings</code> table. You can find the insert script for the settings in the GraniteDatabase install folder:</p> <pre><code>\"...\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingsUtilityAPI.sql\"\n</code></pre> <p>You should have the following settings after running the script:</p> Application Key Value Description ValueDataType isEncrypted isActive Granite.Utility UserName Username for the account that will be used to send email string False True Granite.Utility Password Password for the account that will be used to send email string True True Granite.Utility Host smtp.gmail.com The address of the SMTP server string False True Granite.Utility Port 587 Port number to be used when accessing the SMTP server int False True Granite.Utility EnableSsl true Use SSL when accessing the SMTP server. True or False bool False True Granite.Utility From Email address that will be used to send mail string False True Granite.Utility FromName The sender name that will display to users who receive emails string False True Granite.Utility RetryInterval 30 Number of seconds to wait before retrying processing an email int False True Granite.Utility MaxNumberOfRetries 3 Maximum number of times to retry processing an email. int False True Granite.Utility EmailAttachmentFolder Full filepath to folder to export email attachments to. Leave empty to use the Utility API install folder string False True Granite.Utility EmailProvider Provider to use for sending emails. If empty, we will use the SMTP provider. string False True <p>Password isEncrypted is True</p> <p>You will only be able to change the value of this setting from the Webdesktop System Settings page</p>"},{"location":"utility-api/email-service/#email-providers","title":"Email Providers","text":"<p>Email Providers allow us to configure the way that we send emails for different types of email accounts. At the moment we support sending email using a SMTP server directly, or using the Gmail API.</p> <p>Note that as of January 2025, Gmail no longer allows sending emails using their SMTP server directly. This is why configuring the UtilityApi to send email via a Gmail account works slightly differently.</p> <p>To configure the <code>EmailProvider</code>, set the name of the provider you want to use in SystemSettings. If the <code>EmailProvider</code> setting is empty, it will default to using the SMTP provider.</p>"},{"location":"utility-api/email-service/#smtp","title":"SMTP","text":"<p>Sending email via SMTP is quite straightforward, all you need is the credentials of the account that you are using to send email, and the details of the server that you are using to send email. These get configured in the <code>System Settings</code></p>"},{"location":"utility-api/email-service/#required-system-settings","title":"Required System Settings","text":"<ul> <li>UserName - User name to use when connecting to the SMTP server</li> <li>Password - Password to use when connecting to the SMTP server</li> <li>Host - The host address of the SMTP server (server name or IP)</li> <li>Port - The port number to use when accessing the SMTP server</li> <li>EnableSsl - Use SSL when accessing the SMTP server. True or False</li> <li>From - The email address that you are sending mail from</li> <li>FromName - The sender name that will display to users who receive emails</li> </ul>"},{"location":"utility-api/email-service/#gmail","title":"Gmail","text":"<p>Since Gmail has blocked access to SMTP, sending email via a Gmail account involves more set up.</p> <p>Note</p> <p>If you are updating in order to continue using the GraniteWMS Info to send email, all you need to do is the following:</p> <ol> <li> <p>Deploy the new Utility API (V 5.0.1.1 or newer)</p> </li> <li> <p>Run the SQL script at <code>...\\Granite Releases\\Granite Info Gmail Auth\\UtilityApiSystemSettings.sql</code></p> </li> <li> <p>Copy the GmailTokens folder <code>...\\Granite Releases\\Granite Info Gmail Auth\\GmailTokens</code> into the GraniteUtilityAPI folder</p> </li> </ol> <p>To send email via Gmail, you will first need to enable Gmail API access for the account you're using and obtain the <code>Client ID</code> and <code>Client secret</code>. These are the UserName and Password that you will need to set in <code>SystemSettings</code>.</p> <p>Next, you will need to place the API token file in the <code>...\\GraniteUtilityAPI\\GmailTokens</code> folder. If you have the token file for the account you are using already, you can simply paste it in. Otherwise, you will need to run the Gmail Authenticator to obtain the token file.</p>"},{"location":"utility-api/email-service/#required-system-settings_1","title":"Required System Settings","text":"<ul> <li>UserName - The Client ID used to connect to the Gmail API</li> <li>Password - The Client secret used to connect to the Gmail API</li> <li>From - The email address that you are sending mail from</li> <li>FromName - The sender name that will display to users who receive emails</li> </ul>"},{"location":"utility-api/email-service/#allow-gmail-account-api-access","title":"Allow Gmail account API access","text":"<p>Note</p> <p>This configuration has already been completed for the GraniteWMS Info account, it does not need to be performed again.</p> <p>If you are using the GraniteWMS Info account, use the script in Dropbox to update your SystemSettings and then run the GmailAuthenticator app to log in.</p> <p>To allow UtilityAPI access to the Gmail account in order to send email, we will need to configure some settings on the Gmail account.</p> <p>Browse to https://console.cloud.google.com and log in with the account that you want to use, then follow the steps below.</p> <ol> <li> <p>Click the <code>Select a project</code> button on the top left</p> <p></p> </li> <li> <p>Click the <code>New Project</code> button on the top right of the box.</p> <p></p> </li> <li> <p>Give the new project a name e.g. <code>GraniteUtilityAPI</code>. You shouldn't need to change the Location/Organization. Just keep the default and click <code>CREATE</code></p> <p></p> </li> <li> <p>Click the hamburger menu on the top left and select <code>Enabled APIs &amp; services</code> from the menu</p> <p></p> </li> <li> <p>Click the <code>Enable APIs and Services</code> button</p> <p></p> </li> <li> <p>Search for \"gmail\", click on the Gmail API entry and then click the <code>Enable</code> button</p> <p></p> </li> <li> <p>Once the Gmail API is enabled, select the <code>OAuth consent screen</code> from the menu on the left</p> <p></p> </li> <li> <p>On the OAuth consent screen, select User Type <code>Internal</code> and click <code>Create</code></p> <p></p> </li> <li> <p>Select the Application type <code>Web application</code>.  Enter an App name e.g. <code>Granite.Utility.Api</code>, a user support email address and a developer contact email address.  You can set both of the email addresses to the email address that you are using to send email. Click the <code>Save and Continue</code> button once you've entered the required fields.</p> <p></p> </li> <li> <p>Click the <code>Add or Remove Scopes</code> button</p> <p></p> </li> <li> <p>Filter the list of scopes by <code>Gmail API</code> and select the scope <code>https://mail.google.com</code>.  Scroll to the bottom of the page and click <code>Update</code></p> <p></p> </li> <li> <p>Now that the scope has been added, scroll down to the bottom of the page and click <code>Save and Continue</code></p> <p></p> </li> <li> <p>Select <code>Credentials</code> from the menu on the left</p> <p></p> </li> <li> <p>Click the <code>Create Credentials</code> button at the top and select <code>OAuth client ID</code></p> <p></p> </li> <li> <p>Give the client ID a name, e.g. <code>Granite.Utility.Api</code>.  Under Authorized redirect URIs add both <code>http://localhost/authorize/</code> and <code>http://127.0.0.1/authorize/</code> Then click the <code>Create</code> button at the bottom</p> <p></p> </li> <li> <p>Take note of the <code>Client ID</code> and the <code>Client secret</code>.  These are the <code>UserName</code> and <code>Password</code> that you will need for SystemSettings</p> <p></p> </li> <li> <p>Set the <code>Client ID</code> and <code>Client secret</code> as your <code>UserName</code> and <code>Password</code> in SystemSettings.  While you are in SystemSettings, also ensure that you have the <code>EmailProvider</code> setting and that the value is set to <code>GMAIL</code></p> <p>Note</p> <p>The <code>Client secret</code> must be encrypted. Ensure that you save it through the Webdesktop so that it is not stored in plaintext.</p> </li> </ol>"},{"location":"utility-api/email-service/#gmail-authenticator","title":"Gmail Authenticator","text":"<p>The Gmail Authenticator connects to the Gmail API using the Client ID and Client secret from System Settings, and fetches tokens that allow the Utility API to connect to the Gmail API. This is a once off set up, once you have authenticated, the Utility API will be able to send email via Gmail.</p> <ol> <li> <p>Open a browser window that is either signed in with the Gmail account you are planning to use, or not signed in to any Gmail account. The Guest mode in Chrome works well for this.</p> </li> <li> <p>Browse to the folder where you have installed the UtilityAPI, and into the <code>GmailAuthenticator</code> folder.  Run the <code>Granite.Email.GmailAuthenticator.exe</code>.</p> <p>Note</p> <p>Granite.Email.GmailAuthenticator.exe uses the UtilityApi's appSettings.json file.  Make sure that it is configured before trying to authenticate the Gmail account.</p> </li> <li> <p>A new browser tab will open asking you to log in to authorize the Utility API.  Log in with the Gmail account that you are going to use to send emails.  Log in with the normal username and password - NOT the Client ID and Client secret</p> </li> </ol> <p>After signing in via the browser, Gmail Authenticator will place the received token file into the <code>...\\GraniteUtilityAPI\\GmailTokens</code> folder</p>"},{"location":"utility-api/email-service/#email-templates","title":"Email Templates","text":"<p>Email templates use MARKDOWN for text formatting - HTML is not supported.  If you're not familiar with markdown, take a look at the syntax cheat-sheet.</p> <p>To embed images and tables in the body of your email, Email Templates use Script Methods similar to the Web Template's Script Methods.</p>"},{"location":"utility-api/email-service/#template-manager","title":"Template Manager","text":"<p>The Template Manager is how you design and preview your email templates before using them.  It has full auditing, so you can see which user has made changes to the Email Templates, as well as what has changed.</p> <p>To copy an existing template, select it from the dropdown and then select New Template.  When you save the template you will be prompted to give your new template a name.</p>"},{"location":"utility-api/email-service/#script-methods","title":"Script Methods","text":"<p>Script methods are the building blocks of your emails.  You can use these to add images, tables, and more to the body of your email.</p> <p>Each currently available Script Method is described below:</p>"},{"location":"utility-api/email-service/#headerimage","title":"headerImage()","text":"<p>The headerImage() script method allows you to add an image as a header to the top of your email.</p> <p>Available parameters:</p> ParameterName Data Type Required Description imageUrl string Yes The url of the image that you want in your header imageAltText string No Text that will display in place of image if link is broken backgroundColor string No Solid block of color behind the image. Can be hexcode or word <p>Code example:</p> <pre><code>{{\n    headerImage(\n    {\n      imageUrl:'https://raw.githubusercontent.com/GraniteWMS/GraniteBrandAssets/main/Granite_WMS_Reversed.png',\n      imageAltText:'GraniteWMS logo',\n      backgroundColor:'#182026'\n    })\n}}\n</code></pre>"},{"location":"utility-api/email-service/#table","title":"table()","text":"<p>The <code>table()</code> script method works together with the <code>dbSelect()</code> method to take a SQL string as an input and return the result as a table.</p> ParameterName Data Type Required Description sumColumns string[] No Comma separated list of columns to sum in the table footer backgroundColor string No Background color for the table's header and footer textColor string No Text color for the table's header and footer text <p>Code example:</p> <pre><code>{{    \n    'SELECT * FROM EmailTemplate_OrderDetail WHERE DocumentNumber = @documentNumber'\n    | dbSelect({documentNumber})\n    | table({backgroundColor: '#182026', textColor: 'white', sumColumns:['Qty','Price']})\n}}\n</code></pre>"},{"location":"utility-api/email-service/#footerblock-and-footeritem","title":"footerBlock() and footerItem()","text":"<p>The <code>footerItem()</code> script method can be chained together with more <code>footerItem()</code>'s which are then passed into the <code>footerBlock()</code> to add a footer to your email.</p> <p>FooterItem parameters:</p> ParameterName Data Type Required Description imageUrl string No Url of the image to include in this footer item imageWidth int No Width of the image in pixels. Height will scale automatically text string No Text to include in this footer item url string No Url to link to if this footer item is clicked on <p>FooterBlock parameters:</p> ParameterName Data Type Required Description textColor string No Color of the text in the footerBlock backgroundColor string No Color of the background block for the whole footerBlock <p>Code example:</p> <pre><code>{{\n    footerItem(\n    { \n        imageUrl:'https://cdn1.iconfinder.com/data/icons/logotypes/32/square-facebook-1024.png',\n        imageWidth: 50,\n        url:'https://www.facebook.com/StarWarsAfrica/'\n    })\n    | footerItem(\n    { \n        imageUrl:'https://cdn2.iconfinder.com/data/icons/social-icons-33/128/Instagram-1024.png',\n        imageWidth: 50,\n        url:'https://www.instagram.com/starwars'\n    })\n    | footerBlock({backgroundColor:'#182026', textColor:'lightgray' })\n}}\n</code></pre>"},{"location":"utility-api/email-service/#sending-an-email","title":"Sending an Email","text":"<p>When you make a request to send an email, the email is immediately entered into the <code>Email</code> table in the database. If your email is a templated email, the template is rendered just before the entry is created in the <code>Email</code> table. The Email Service will give you a response as soon as the email is queued in the table.  From there, the email is passed to background services to fetch any attachments.  Once the attachments have been gathered, the email will be sent.</p> <p>If any of the background services are unable to complete their job,  whether that be fetching an attachment or actually sending the mail, they will retry until the task succeeds or the  <code>MaxNumberOfRetries</code> configured in SystemSettings is reached.</p> <p>When the <code>MaxNumberOfRetries</code> is reached, the mail's status is set to FAILED and will not be retried without manual intervention.</p> <p>See the API Documentation page for more info on sending emails using the API.  For sending mails using SQLCLR, see the SQLCLR manual.</p>"},{"location":"utility-api/email-service/#attachments","title":"Attachments","text":"<p>When you send an email with attachments, copies of those attachments are saved to the <code>EmailAttachmentFolder</code> specified in SystemSettings.  The attachments for any given email will be placed in a subfolder named with the <code>ID</code> of the email in the <code>Email</code> database table. This allows you to go back at any point to check the contents of the files that were sent as attachments.</p>"},{"location":"utility-api/email-service/#ssrs-reports","title":"SSRS Reports","text":"<p>To attach SSRS reports, ensure the Reporting Service is configured correctly and working.</p> <p>Attaching an SSRS report works very similarly to printing or exporting the report directly from the Reporting Service.  The difference is that the Email Service will make the request to fetch the report after the email has been queued in the database.</p> <p>Browse the API's documentation page (<code>/metadata</code>) for details on the properties needed to attach an SSRS report.  The details can be found on the TemplateEmail or SimpleEmail requests.</p>"},{"location":"utility-api/email-service/#sql-table-exports","title":"SQL Table exports","text":"<p>To attach SQL Table exports, ensure the SQLExport Service is configured correctly and working.</p> <p>Attaching an excel export works very similarly to exporting the data directly from the SQLExport Service.  The difference is that the Email Service will make the request to export the data after the email has been queued in the database.</p> <p>Browse the API's documentation page (<code>/metadata</code>) for details on the properties needed to attach a SQL Table Export.  The details can be found on the TemplateEmail or SimpleEmail requests.</p>"},{"location":"utility-api/email-service/#file-attachments","title":"File attachments","text":"<p>File attachments allow you to specify a file path to the file that you want to attach. When fetching this attachment type, the Email Service will copy the file into the email attachment folder configured in the SystemSettings table. This is to ensure that a copy is kept for future reference in case the original is ever moved or deleted.</p> <p>Browse the API's documentation page (<code>/metadata</code>) for details on the properties needed to attach a File Attachment.  The details can be found on the TemplateEmail or SimpleEmail requests.</p>"},{"location":"utility-api/getting-started/","title":"Getting Started","text":""},{"location":"utility-api/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>IIS</li> <li>ASP.NET Core 8 Hosting Bundle</li> </ul>"},{"location":"utility-api/getting-started/#install","title":"Install","text":"<ol> <li> <p>Configure the connection string to the Granite database in the <code>appsettings.json</code> file</p> <pre><code>{\n\"ConnectionStrings\": {\n    \"GRANITE\": \"Server=.\\\\sql2019;Database=GraniteDatabase;User ID=Granite;Password=******;Persist Security Info=False;\"\n},\n\"AllowedOrigins\": [ \"https://:40099\" ],\n\"Logging\": {\n    \"LogLevel\": {\n    \"Default\": \"Information\",\n    \"Microsoft.AspNetCore\": \"Warning\"\n    }\n},\n\"AllowedHosts\": \"*\"\n}\n</code></pre> <p>Note</p> <p>You cannot use wildcards like <code>*</code> in the <code>AllowedOrigins</code> setting for the UtilityAPI.</p> <p>It should contain only the WebDesktop address.</p> </li> <li> <p>Add the site to IIS, be sure to run as https and select a valid certificate</p> </li> <li>Configure the settings for each service that you are going to make use of<ul> <li>Email Service Configuration</li> <li>Reporting Service Configuration</li> <li>SqlExport Service Configuration</li> </ul> </li> </ol>"},{"location":"utility-api/release-notes/","title":"Release Notes","text":""},{"location":"utility-api/release-notes/#5000","title":"5.0.0.0","text":"<p>Initial release</p>"},{"location":"utility-api/reporting-service/","title":"Reporting Service","text":"<p>The reporting service accesses the reports by directly calling SQL Server Reporting Service's API. Once it has received the report back from the API it either prints or exports the report depending on the call.</p>"},{"location":"utility-api/reporting-service/#prerequisites","title":"Prerequisites","text":"<ul> <li>SQL Server Reporting Service</li> </ul>"},{"location":"utility-api/reporting-service/#configuration","title":"Configuration","text":"<p>Settings for the Reporting Service element of the UtilityAPI are configured in the <code>SystemSettings</code> table. You can find the insert script for the settings in the GraniteDatabase install folder:</p> <pre><code>\"...\\GraniteDatabase\\Data\\SystemSettings\\SystemSettingsUtilityAPI.sql\"\n</code></pre> <p>You should have the following settings after running the script:</p> Application Key Value Description ValueDataType isEncrypted isActive Granite.Utility SSRSWebServiceUrl Url of the reporting service string False True <p>The SSRS Web Service Url should look something like this: http://10.0.0.1/ReportServer</p> <p>You can find it on the Report Server Configuration Manager under the web service url tab. Check the configuration page (<code>/config</code>) and ensure that <code>Report Service URL Valid</code> and <code>Report Execution Service URL Valid</code> are both <code>true</code>.</p>"},{"location":"utility-api/reporting-service/#iis-application-pool","title":"IIS Application Pool","text":"<p>In order for the UtilityAPI to access SSRS, the Identity of the Application pool needs to be changed to LocalSystem. </p> <p>To do this, go to the advanced settings of the application pool associated with the UtilityAPI and change from ApplicationPoolIdentity to LocalSystem as you can see below.</p> <p></p>"},{"location":"utility-api/reporting-service/#report-properties","title":"Report Properties","text":"<p>Report Properties on the UtilityAPI homepage allows you to see all of the report paths and parameters. </p> <p>If the parameter Name is ERROR you will need to check that the report is working in SSRS. The most common errors are a missing stored procedure or the report being pointed to a data source that does not exist.</p>"},{"location":"utility-api/reporting-service/#printer-statuses","title":"Printer Statuses","text":"<p>Printer Statuses on the UtilityAPI homepage allows you to see all of the Printers visible to the UtilityAPI and their statuses. The report service does not check the status of the printer before sending a print job. The status is purely useful to diagnose issues printing.</p>"},{"location":"utility-api/reporting-service/#reportfileexport","title":"ReportFileExport","text":"<p>This process calls SSRS and saves the report to the specified file path. The file path has to be on the server where the UtilityAPI is running. To get the file from the server, the easiest option is to send it as an email attachment.</p> <p>Supported file types are PDF and EXCEL, both the new .xlsx and the old .xls. If you are unsure which to use, go for .xlsx</p> <p>See the API Documentation for more details on how to export a report using the API. See the SQLCLR documentation for how to export a report using SQLCLR.</p>"},{"location":"utility-api/reporting-service/#reportprint","title":"ReportPrint","text":"<p>This process calls SSRS and sends the report to a print queue. Check Printer Statues on the UtilityAPI homepage to see the list of available printers.</p> <p>See the API Documentation for more details on how to print a report using the API. See the SQLCLR documentation for how to print a report using SQLCLR.</p>"},{"location":"utility-api/sql-export-service/","title":"SqlExport Service","text":""},{"location":"utility-api/sql-export-service/#configuration","title":"Configuration","text":"<p>The only setup required is to configure the connection string to the Granite database in the <code>appsettings.json</code> file.</p>"},{"location":"utility-api/sql-export-service/#table-export","title":"Table Export","text":"<p>This process saves data from either a table or a view to the specified file path. The file path has to be on the server where the UtilityAPI is running. To get the file from the server, the easiest option is to send it as an email attachment.</p> <p>Supported file types are EXCEL (.xlsx) AND CSV (.csv).</p> <p>Table Export supports filters (Equal, GreaterThan, ect..), order by, offset, and limit.</p> <ul> <li>Filters require the column name, the filter type, and filter value. (For a full list of supported filter types, see the API documentation)</li> <li>OrderBy requires a column name and an order by type (ASC or DESC). The order in which the order bys are submitted determines the order in which they are applied. </li> <li>Offset determines how many rows from the start of the data are skipped. If not set it will default to 0.</li> <li>Limit determines the number of rows returned from the data. If not set it will default to 10000. </li> </ul> <p>See the API documentation for more details on how to export a table or view using the API. See the SQLCLR documentation for how to export a table or view using SQLCLR.</p>"},{"location":"webdesktop/manual/","title":"WebDesktop","text":"<p>The Granite WebDesktop is constructed on a thick client architecture, where the software application operates primarily on the user's device (like a computer or mobile device) and conducts a substantial amount of processing locally. This approach minimizes reliance on server processing and data retrieval for enhanced efficiency.</p> <p>The central functionality of the system revolves around data maintenance and enquiry. This relies on various Granite APIs to efficiently perform these tasks.</p>"},{"location":"webdesktop/manual/#setup","title":"Setup","text":""},{"location":"webdesktop/manual/#requirements","title":"Requirements","text":"<ul> <li>IIS</li> <li>Sufficient permissions for folder and file access and IIS application creation</li> </ul>"},{"location":"webdesktop/manual/#customization","title":"Customization","text":""},{"location":"webdesktop/manual/#grids","title":"Grids","text":"<p>Our system empowers users to customize numerous grids according to their preferences and requirements. Determine whether a grid is configurable by right-clicking on it and selecting the Show Grid Definition option from the context menu.</p> <p></p> <p>In addition to displaying the JSON definition, the dialog provides visibility into both the API operation and the SQL syntax linked with the data source. Modify the JSON layout directly within this dialog interface for seamless customization.</p> <p></p> <p>The Datagrid table is responsible to store the grid information. When a grid is customized, its name will be prefixed with Custom and the column isCustomGrid will be set accordingly. The column isApplicationGrid serves as an indicator that the grid is integrated into the WebDesktop and forms an integral part of the application. These grids are preconfigured and we do not configure the SQL view (empty). Conversely, when isApplicationGrid is set to false, it signifies that the grid is designated as an Enquiry grid, allowing for further customization.</p> <p></p>"},{"location":"webdesktop/manual/#grid-data-columns","title":"Grid Data Columns","text":"<p>The WebDesktop mandates a minimum set of columns to be present in both the SQL data and grid. These typically include the primary key fields such as Document.Number, MasterItem.Code, etc. To verify the necessary columns, access the API operation.</p> <p></p> <p>If you navigate to the API operation documentation, you can observe that we document the SQL view name and the essential columns required for its proper functionality.</p> <p></p> <p>In the example provided above, ID, Code, and isActive are explicitly designated as required columns.</p>"}]}